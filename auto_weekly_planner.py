"""
ìë™ ì£¼ê°„ê³„íš ìƒì„±ê¸° - ì‹¤ì‹œê°„ íŠ¸ë Œë“œì™€ ìˆ˜ìµë¥  ë°ì´í„° ê¸°ë°˜ ì£¼ê°„ê³„íš ìë™ ìƒì„±
"""

import os
import json
import random
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from src.utils.trend_collector import TrendCollector
from src.utils.postgresql_database import PostgreSQLDatabase
from src.generators.content_generator import ContentGenerator
from src.utils.high_traffic_keyword_manager import HighTrafficKeywordManager
from src.utils.profit_keyword_manager import ProfitKeywordManager
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ProfitWeeklyPlanner:
    """ìë™ ì£¼ê°„ê³„íš ìƒì„±ê¸°"""
    
    def __init__(self):
        self.trend_collector = TrendCollector()
        self.db = PostgreSQLDatabase()
        self.content_generator = ContentGenerator()
        self.high_traffic_manager = HighTrafficKeywordManager()
        self.profit_manager = ProfitKeywordManager()
        
        # ì‚¬ì´íŠ¸ë³„ ì„ í˜¸ ì¹´í…Œê³ ë¦¬
        self.site_preferences = {
            'unpre': ['ê¸°ìˆ ', 'AI/ë¨¸ì‹ ëŸ¬ë‹', 'í”„ë¡œê·¸ë˜ë°', 'ìŠ¤íƒ€íŠ¸ì—…', 'íˆ¬ì'],
            'untab': ['ë¼ì´í”„ìŠ¤íƒ€ì¼', 'ì—¬í–‰', 'ìŒì‹', 'ê±´ê°•', 'ì·¨ë¯¸'],
            'skewese': ['ë¹„ì¦ˆë‹ˆìŠ¤', 'ë§ˆì¼€íŒ…', 'ìê¸°ê³„ë°œ', 'ê²½ì œ', 'íŠ¸ë Œë“œ'],
            'tistory': ['ì¼ë°˜', 'í›„ê¸°', 'ì •ë³´', 'íŒ', 'ê°€ì´ë“œ']
        }
        
    def get_trending_topics(self) -> List[Dict]:
        """ğŸ”¥ 2025ë…„ ì‹¤ì‹œê°„ ê²€ìƒ‰ íŠ¸ë Œë“œ + SEO ìµœì í™” í‚¤ì›Œë“œ ìˆ˜ì§‘"""
        all_topics = []

        try:
            # 1. ìµœê³  ìˆ˜ìµì„± + íŠ¸ë Œë“œ í‚¤ì›Œë“œ (2025 ê²€ìƒ‰ íŠ¸ë Œë“œ ë°˜ì˜)
            ultra_profit_keywords = self.profit_manager.get_ultra_profit_keywords(15)
            for kw in ultra_profit_keywords:
                all_topics.append({
                    'title': kw['keyword'],
                    'category': 'ultra_profit',
                    'score': kw['profit_score'],
                    'source': 'ultra_profit',
                    'volume': kw['volume'],
                    'cpc': kw['cpc'],
                    'profit_score': kw['profit_score']
                })
            logger.info(f"2025 íŠ¸ë Œë“œ í‚¤ì›Œë“œ {len(ultra_profit_keywords)}ê°œ ìˆ˜ì§‘ (í‰ê·  ê²€ìƒ‰ëŸ‰: {sum([kw['volume'] for kw in ultra_profit_keywords])//len(ultra_profit_keywords)//1000}K)")
            
            # 2. ì‹¤ì‹œê°„ ê²€ìƒ‰ ê¸‰ìƒìŠ¹ í‚¤ì›Œë“œ (í˜„ì¬ ì›” íŠ¹í™”)
            month_profit_keywords = self.profit_manager.get_current_month_profit_keywords(10)
            for kw in month_profit_keywords:
                all_topics.append({
                    'title': kw['keyword'],
                    'category': 'trending_monthly',
                    'score': kw['profit_score'],
                    'source': 'monthly_trending',
                    'volume': kw['volume'],
                    'cpc': kw['cpc'],
                    'profit_score': kw['profit_score']
                })
            logger.info(f"1ì›” íŠ¸ë Œë“œ í‚¤ì›Œë“œ {len(month_profit_keywords)}ê°œ ìˆ˜ì§‘")
            
            # 3. ë¡­í…Œì¼ í‚¤ì›Œë“œ + ì œíœ´ ê°€ëŠ¥ ìƒí’ˆ
            for category in ['ê¸ˆìœµ', 'ì‡¼í•‘', 'ì—¬í–‰', 'êµìœ¡']:
                affiliate_keywords = self.profit_manager.get_affiliate_keywords_by_category(category, 3)
                for kw in affiliate_keywords:
                    all_topics.append({
                        'title': kw['keyword'],
                        'category': 'longtail_seo',
                        'score': min(99, kw['total_profit'] // 1000),
                        'source': f'longtail_{category}',
                        'volume': kw['volume'],
                        'cpc': kw['cpc'],
                        'commission': kw.get('commission', 0),
                        'profit_score': min(99, kw['total_profit'] // 1000)
                    })
            logger.info(f"ë¡­í…Œì¼ SEO í‚¤ì›Œë“œ ì¶”ê°€ ì™„ë£Œ")
            
            # 4. Google/ë„¤ì´ë²„ ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë³‘í•©
            try:
                trends = self.trend_collector.collect_all_trends()
                for trend in trends[:10]:  # ì‹¤ì‹œê°„ íŠ¸ë Œë“œ í™œìš©
                    # íŠ¸ë Œë“œì— SEO í‚¤ì›Œë“œ ê²°í•©
                    seo_title = self._enhance_with_seo_keywords(trend.title)
                    all_topics.append({
                        'title': seo_title,
                        'category': 'realtime_trend',
                        'score': 85,  # ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ì ìˆ˜
                        'source': 'realtime_search',
                        'volume': 200000,  # íŠ¸ë Œë“œ ê¸°ë³¸ ê²€ìƒ‰ëŸ‰
                        'profit_score': 85
                    })
                logger.info(f"ì‹¤ì‹œê°„ íŠ¸ë Œë“œ {len(trends[:10])}ê°œ ì¶”ê°€")
            except:
                logger.warning("ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì‹¤íŒ¨")
            
            # ğŸ”¥ SEO ì ìˆ˜ + ê²€ìƒ‰ëŸ‰ ê¸°ì¤€ ì •ë ¬ (ì‹¤ì œ íŠ¸ë˜í”½ ì˜ˆìƒ)
            all_topics.sort(key=lambda x: (x.get('profit_score', 0) * 0.7 + min(x.get('volume', 0)/10000, 100) * 0.3), reverse=True)
            logger.info(f"ì´ {len(all_topics)}ê°œ ì£¼ì œ SEO ìµœì í™” ì •ë ¬ ì™„ë£Œ")

            # ì¤‘ë³µ ì œê±° í›„ ìƒìœ„ 30ê°œ ì„ íƒ
            unique_topics = []
            seen_keywords = set()
            for topic in all_topics:
                base_keyword = topic['title'].split()[0]
                if base_keyword not in seen_keywords:
                    unique_topics.append(topic)
                    seen_keywords.add(base_keyword)
                    if len(unique_topics) >= 30:
                        break

            return unique_topics
            
        except Exception as e:
            logger.error(f"ìˆ˜ìµì„± í‚¤ì›Œë“œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return self._get_profit_fallback_topics()
    
    def _get_profit_fallback_topics(self) -> List[Dict]:
        """2025ë…„ ê¸°ë³¸ SEO í‚¤ì›Œë“œ (ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ìš©)"""
        return [
            {'title': 'ë¬´ì§ì ëŒ€ì¶œ ê°€ëŠ¥í•œ ê³³ TOP 10', 'category': 'seo', 'score': 92, 'volume': 850000, 'profit_score': 92},
            {'title': 'ë¶€ì—… ì¶”ì²œ ìˆœìœ„ 2025 ì›” 100ë§Œì›', 'category': 'seo', 'score': 95, 'volume': 920000, 'profit_score': 95},
            {'title': 'ChatGPT í™œìš©ë²• ëˆë²„ëŠ” ë°©ë²•', 'category': 'seo', 'score': 90, 'volume': 780000, 'profit_score': 90},
            {'title': 'í…ŒìŠ¬ë¼ ì£¼ì‹ ì „ë§ 2025 ë§¤ìˆ˜íƒ€ì´ë°', 'category': 'seo', 'score': 88, 'volume': 650000, 'profit_score': 88},
            {'title': 'ë‹¤ì´ì–´íŠ¸ ë³´ì¡°ì œ ìˆœìœ„ íš¨ê³¼ ìˆëŠ”', 'category': 'seo', 'score': 85, 'volume': 540000, 'profit_score': 85},
        ]
    
    def _get_fallback_topics(self) -> List[Dict]:
        """íŠ¸ë Œë“œ ìˆ˜ì§‘ ì‹¤íŒ¨ì‹œ ëŒ€ì²´ ì£¼ì œ"""
        current_month = datetime.now().month
        current_day = datetime.now().day
        
        fallback_topics = [
            {'title': f'2025ë…„ {current_month}ì›” ì£¼ëª©í•´ì•¼ í•  ê¸°ìˆ  íŠ¸ë Œë“œ', 'category': 'ê¸°ìˆ ', 'score': 100},
            {'title': 'ì„±ê³µí•˜ëŠ” ì‚¬ëŒë“¤ì˜ ì•„ì¹¨ ë£¨í‹´ 5ê°€ì§€', 'category': 'ìê¸°ê³„ë°œ', 'score': 95},
            {'title': f'{current_month}ì›” ì œì²  ìŒì‹ìœ¼ë¡œ ê±´ê°• ì±™ê¸°ê¸°', 'category': 'ê±´ê°•', 'score': 90},
            {'title': 'ë¶€ë™ì‚° íˆ¬ì ì´ˆë³´ìë¥¼ ìœ„í•œ ê°€ì´ë“œ', 'category': 'íˆ¬ì', 'score': 85},
            {'title': 'ì¬íƒê·¼ë¬´ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ë°©ë²•', 'category': 'ë¼ì´í”„ìŠ¤íƒ€ì¼', 'score': 80},
            {'title': 'ì¸ê³µì§€ëŠ¥ ì‹œëŒ€, ì‚´ì•„ë‚¨ëŠ” ì§ì—…ë“¤', 'category': 'AI', 'score': 75},
        ]
        
        return fallback_topics
    
    def categorize_topic_for_site(self, topic: Dict, site: str) -> str:
        """ì‚¬ì´íŠ¸ì— ë§ëŠ” ì¹´í…Œê³ ë¦¬ë¡œ ë³€í™˜"""
        topic_category = topic.get('category', 'ì¼ë°˜').lower()
        site_prefs = self.site_preferences.get(site, ['ì¼ë°˜'])
        
        # ì¹´í…Œê³ ë¦¬ ë§¤í•‘
        category_mapping = {
            'technology': 'ê¸°ìˆ ',
            'tech': 'ê¸°ìˆ ', 
            'ai': 'AI/ë¨¸ì‹ ëŸ¬ë‹',
            'business': 'ë¹„ì¦ˆë‹ˆìŠ¤',
            'lifestyle': 'ë¼ì´í”„ìŠ¤íƒ€ì¼',
            'health': 'ê±´ê°•',
            'food': 'ìŒì‹',
            'travel': 'ì—¬í–‰',
            'finance': 'íˆ¬ì',
            'programming': 'í”„ë¡œê·¸ë˜ë°'
        }
        
        mapped_category = category_mapping.get(topic_category, topic_category)
        
        # ì‚¬ì´íŠ¸ ì„ í˜¸ë„ì— ë§ëŠ” ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
        for pref in site_prefs:
            if pref in mapped_category or mapped_category in pref:
                return pref
                
        return site_prefs[0]  # ê¸°ë³¸ê°’
    
    def generate_weekly_plan(self, start_date: datetime = None, target_week: str = 'current') -> Dict:
        """ì£¼ê°„ê³„íš ìƒì„± - ì—ëŸ¬ ë°©ì§€ ê°•í™”"""
        try:
            if start_date is None:
                start_date = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
                
            # ì´ë²ˆ ì£¼ ë˜ëŠ” ë‹¤ìŒì£¼ ì›”ìš”ì¼ ê³„ì‚° (ì—ëŸ¬ ë°©ì§€)
            try:
                if target_week == 'next':
                    # ë‹¤ìŒì£¼ ì›”ìš”ì¼ ê³„ì‚°
                    days_since_monday = start_date.weekday()
                    days_to_next_monday = 7 - days_since_monday
                    start_date = start_date + timedelta(days=days_to_next_monday)
                else:
                    # ì´ë²ˆ ì£¼ ì›”ìš”ì¼ ê³„ì‚°
                    days_since_monday = start_date.weekday()
                    start_date = start_date - timedelta(days=days_since_monday)
                    
                logger.info(f"ê³„íš ìƒì„± ëŒ€ìƒì£¼: {target_week}, ì‹œì‘ì¼: {start_date.strftime('%Y-%m-%d')}")
            except Exception as date_calc_error:
                logger.error(f"ë‚ ì§œ ê³„ì‚° ì—ëŸ¬: {date_calc_error}")
                raise ValueError(f"ë‚ ì§œ ê³„ì‚° ì‹¤íŒ¨: {date_calc_error}")
        except Exception as init_error:
            logger.error(f"ì£¼ê°„ê³„íš ì´ˆê¸°í™” ì‹¤íŒ¨: {init_error}")
            raise
        
        logger.info(f"ì£¼ê°„ê³„íš ìƒì„± ì‹œì‘: {start_date.strftime('%Y-%m-%d')} ~ {(start_date + timedelta(days=6)).strftime('%Y-%m-%d')}")
        
        # íŠ¸ë Œë”© ì£¼ì œ ìˆ˜ì§‘ (ê°•ë ¥í•œ ì—ëŸ¬ ë°©ì§€)
        try:
            trending_topics = self.get_trending_topics()
            if not trending_topics:
                logger.warning("íŠ¸ë Œë”© ì£¼ì œê°€ ì—†ìŒ, ê¸°ë³¸ ìˆ˜ìµì„± ì£¼ì œ ì‚¬ìš©")
                trending_topics = self._get_profit_fallback_topics()
            logger.info(f"{len(trending_topics)}ê°œ íŠ¸ë Œë”© ì£¼ì œ ìˆ˜ì§‘ ì™„ë£Œ")
        except Exception as trend_error:
            logger.error(f"íŠ¸ë Œë”© ì£¼ì œ ìˆ˜ì§‘ ì‹¤íŒ¨: {trend_error}")
            logger.info("ê¸°ë³¸ ìˆ˜ìµì„± ì£¼ì œë¡œ ëŒ€ì²´")
            trending_topics = self._get_profit_fallback_topics()
        
        sites = ['unpre', 'untab', 'skewese', 'tistory']
        weekly_plan = {
            'week_start': start_date.strftime('%Y-%m-%d'),
            'week_end': (start_date + timedelta(days=6)).strftime('%Y-%m-%d'),
            'generated_at': datetime.now().isoformat(),
            'plans': []
        }
        
        # ìš”ì¼ë³„ ê³„íš ìƒì„± (ì›”-ì¼, 7ì¼) - ê°•ë ¥í•œ ì—ëŸ¬ ë°©ì§€
        topic_idx = 0
        successful_plans = 0
        
        try:
            for day_offset in range(7):
                try:
                    current_date = start_date + timedelta(days=day_offset)
                    day_names = ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼']
                    day_name = day_names[day_offset] if day_offset < len(day_names) else f'Day_{day_offset}'
                    
                    # í•˜ë£¨ì— ëª¨ë“  ì‚¬ì´íŠ¸(4ê°œ)ì— í¬ìŠ¤íŒ…
                    sites_for_day = sites  # ëª¨ë“  ì‚¬ì´íŠ¸ì— ë§¤ì¼ í¬ìŠ¤íŒ…
                    
                    for site in sites_for_day:
                        try:
                            # ğŸ”¥ SEO ìµœì í™” ì£¼ì œ ì„ íƒ (ëª¨ë“  ì‚¬ì´íŠ¸ ê³µí†µ)
                            if topic_idx >= len(trending_topics):
                                topic_idx = 0  # ì£¼ì œ ìˆœí™˜

                            topic = trending_topics[topic_idx]

                            # SEO ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ê²€ìƒ‰ íŠ¸ë Œë“œ ë°˜ì˜)
                            if 'realtime' in topic.get('source', ''):
                                category = 'trending_now'
                            elif topic.get('profit_score', 0) >= 90:
                                category = 'top_search'
                            elif topic.get('profit_score', 0) >= 80:
                                category = 'popular'
                            else:
                                category = 'seo_optimized'

                            logger.info(f"{site} SEO ì£¼ì œ ì ìš© (ê²€ìƒ‰ëŸ‰: {topic.get('volume', 0)//1000}K): {topic['title'][:50]}...")

                            # SEO ìµœì í™” ì œëª© ìƒì„±
                            try:
                                title = self._create_profit_optimized_title(topic['title'], topic.get('profit_score', 0))
                            except Exception as title_error:
                                logger.warning(f"ì œëª© ìƒì„± ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {title_error}")
                                title = topic['title']
                            
                            try:
                                keywords = self._extract_keywords(title)
                            except Exception as keyword_error:
                                logger.warning(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {keyword_error}")
                                keywords = [topic['title'][:20]]
                            
                            plan_item = {
                                'date': current_date.strftime('%Y-%m-%d'),
                                'day_name': day_name,
                                'site': site,
                                'title': title,
                                'category': category,
                                'original_topic': topic.get('title', 'Unknown Topic'),
                                'trend_score': topic.get('score', 0),
                                'profit_score': topic.get('profit_score', 0),
                                'cpc': topic.get('cpc', 0),
                                'volume': topic.get('volume', 0),
                                'source': topic.get('source', 'Unknown'),
                                'keywords': keywords,
                                'status': 'planned',
                                'priority': 'ultra' if topic.get('profit_score', 0) >= 90 else ('high' if topic.get('profit_score', 0) >= 80 else 'medium')
                            }
                            
                            weekly_plan['plans'].append(plan_item)
                            successful_plans += 1
                            topic_idx += 1
                            
                        except Exception as site_error:
                            logger.error(f"{site} ì‚¬ì´íŠ¸ ê³„íš ìƒì„± ì‹¤íŒ¨: {site_error}")
                            continue  # ë‹¤ìŒ ì‚¬ì´íŠ¸ë¡œ ê³„ì†
                            
                except Exception as day_error:
                    logger.error(f"{day_name} ê³„íš ìƒì„± ì‹¤íŒ¨: {day_error}")
                    continue  # ë‹¤ìŒ ë‚ ë¡œ ê³„ì†
                    
        except Exception as main_loop_error:
            logger.error(f"ì£¼ê°„ê³„íš ìƒì„± ë£¨í”„ ì‹¤íŒ¨: {main_loop_error}")
            
        # ìµœì†Œ ê³„íš ê²€ì¦
        if successful_plans == 0:
            logger.error("ì£¼ê°„ê³„íš ìƒì„± ì™„ì „ ì‹¤íŒ¨, ê¸°ë³¸ ê³„íš ìƒì„±")
            # ê¸°ë³¸ ê³„íšì´ë¼ë„ ë§Œë“¤ì–´ì•¼ í•¨
            for i in range(7):
                try:
                    basic_date = start_date + timedelta(days=i)
                    basic_plan = {
                        'date': basic_date.strftime('%Y-%m-%d'),
                        'day_name': ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼'][i],
                        'site': 'unpre',
                        'title': f'ìˆ˜ìµì„± í‚¤ì›Œë“œ ê¸°ë³¸ ê³„íš {basic_date.strftime("%mì›” %dì¼")}',
                        'category': 'profit_optimized',
                        'original_topic': 'ê¸°ë³¸ ìˆ˜ìµì„± ì£¼ì œ',
                        'profit_score': 70,
                        'status': 'planned',
                        'priority': 'medium'
                    }
                    weekly_plan['plans'].append(basic_plan)
                    successful_plans += 1
                except:
                    continue
        
        logger.info(f"ì£¼ê°„ê³„íš ìƒì„± ì™„ë£Œ: {len(weekly_plan['plans'])}ê°œ ì•„ì´í…œ")
        return weekly_plan
    
    def _translate_to_korean(self, title: str) -> str:
        """ì˜ì–´ ì œëª©ì„ í•œêµ­ì–´ë¡œ ë³€í™˜"""
        # ìì£¼ ë‚˜ì˜¤ëŠ” ì˜ì–´ í‚¤ì›Œë“œë“¤ì„ í•œêµ­ì–´ë¡œ ë§¤í•‘
        translations = {
            'AI': 'AI',
            'artificial intelligence': 'ì¸ê³µì§€ëŠ¥',
            'machine learning': 'ë¨¸ì‹ ëŸ¬ë‹',
            'blockchain': 'ë¸”ë¡ì²´ì¸',
            'cryptocurrency': 'ì•”í˜¸í™”í',
            'bitcoin': 'ë¹„íŠ¸ì½”ì¸',
            'technology': 'ê¸°ìˆ ',
            'startup': 'ìŠ¤íƒ€íŠ¸ì—…',
            'business': 'ë¹„ì¦ˆë‹ˆìŠ¤',
            'marketing': 'ë§ˆì¼€íŒ…',
            'finance': 'ê¸ˆìœµ',
            'investment': 'íˆ¬ì',
            'health': 'ê±´ê°•',
            'lifestyle': 'ë¼ì´í”„ìŠ¤íƒ€ì¼',
            'travel': 'ì—¬í–‰',
            'food': 'ìŒì‹',
            'programming': 'í”„ë¡œê·¸ë˜ë°',
            'development': 'ê°œë°œ',
            'web': 'ì›¹',
            'mobile': 'ëª¨ë°”ì¼',
            'cloud': 'í´ë¼ìš°ë“œ',
            'data': 'ë°ì´í„°',
            'security': 'ë³´ì•ˆ',
            'productivity': 'ìƒì‚°ì„±',
            'remote work': 'ì¬íƒê·¼ë¬´',
            'social media': 'ì†Œì…œë¯¸ë””ì–´',
            'ecommerce': 'ì „ììƒê±°ë˜',
            'education': 'êµìœ¡',
            'learning': 'í•™ìŠµ',
            'tips': 'íŒ',
            'guide': 'ê°€ì´ë“œ',
            'tutorial': 'íŠœí† ë¦¬ì–¼',
            'review': 'ë¦¬ë·°',
            'news': 'ë‰´ìŠ¤',
            'trend': 'íŠ¸ë Œë“œ',
            'future': 'ë¯¸ë˜',
            'innovation': 'í˜ì‹ ',
            'digital': 'ë””ì§€í„¸'
        }
        
        # ì˜ì–´ê°€ í¬í•¨ëœ ì œëª©ì¸ ê²½ìš° í•œêµ­ì–´ë¡œ ë³€í™˜ ì‹œë„
        korean_title = title.lower()
        for eng, kor in translations.items():
            korean_title = korean_title.replace(eng, kor)
            
        # ì²« ê¸€ì ëŒ€ë¬¸ìë¡œ ë³µì› ë° ì •ë¦¬
        korean_title = korean_title.capitalize()
        
        # ì˜ì–´ ì œëª©ì´ë©´ í•œêµ­ì–´ ìŠ¤íƒ€ì¼ë¡œ ì¬ì‘ì„±
        if not any(ord(char) >= 0xAC00 and ord(char) <= 0xD7A3 for char in title):
            # ì™„ì „ ì˜ì–´ ì œëª©ì¸ ê²½ìš° í•œêµ­ì–´ ì£¼ì œë¡œ ë³€í™˜
            korean_topics = [
                f"2025ë…„ ì£¼ëª©í•´ì•¼ í•  {korean_title} íŠ¸ë Œë“œ",
                f"{korean_title} ì™„ë²½ ê°€ì´ë“œ",
                f"{korean_title}ë¡œ ì„±ê³µí•˜ëŠ” ë°©ë²•",
                f"{korean_title} ì´ˆë³´ìë¥¼ ìœ„í•œ ì‹¤ì „ íŒ",
                f"{korean_title}ì˜ ëª¨ë“  ê²ƒ",
                f"{korean_title} ì „ë¬¸ê°€ê°€ ë˜ëŠ” 5ë‹¨ê³„"
            ]
            import random
            return random.choice(korean_topics)
            
        return korean_title.strip()

    def get_today_profit_topics(self):
        """ì˜¤ëŠ˜ì˜ ìˆ˜ìµ ìµœìš°ì„  ì£¼ì œ ë°˜í™˜"""
        today = datetime.now().date()
        
        # ì´ë²ˆ ì£¼ ê³„íš ê°€ì ¸ì˜¤ê¸°
        weekday = today.weekday()  
        week_start = today - timedelta(days=weekday)
        
        # ì´ë²ˆ ì£¼ ê³„íš ì°¾ê¸° ë˜ëŠ” ìƒì„±
        weekly_plan = self.generate_weekly_plan(week_start)
        
        # ì˜¤ëŠ˜ ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” ê³„íšë“¤ í•„í„°ë§
        today_str = today.strftime('%Y-%m-%d')
        today_topics = []
        
        for plan in weekly_plan.get('plans', []):
            if plan.get('date') == today_str:
                today_topics.append({
                    'site': plan.get('site'),
                    'title': plan.get('title'),
                    'category': plan.get('category', 'profit_optimized'),
                    'keywords': plan.get('keywords', []),
                    'trend_score': plan.get('profit_score', 0)
                })
        
        return today_topics
    
    def _adjust_title_for_site(self, original_title: str, site: str) -> str:
        """ì‚¬ì´íŠ¸ë³„ ì œëª© ì¡°ì •"""
        # ë¨¼ì € í•œêµ­ì–´ë¡œ ë³€í™˜
        title = self._translate_to_korean(original_title)
        
        if site == 'unpre':
            # ê¸°ìˆ /ìŠ¤íƒ€íŠ¸ì—… ìŠ¤íƒ€ì¼
            if not any(word in title for word in ['ê¸°ìˆ ', 'ê°œë°œ', 'AI', 'ìŠ¤íƒ€íŠ¸ì—…', 'IT']):
                return f"{title}ì´ IT ì—…ê³„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥"
        elif site == 'untab':
            # ë¼ì´í”„ìŠ¤íƒ€ì¼ ìŠ¤íƒ€ì¼  
            if 'ë°©ë²•' not in title and 'ê°€ì´ë“œ' not in title and 'íŒ' not in title:
                return f"{title}, ì•Œì•„ì•¼ í•  5ê°€ì§€"
        elif site == 'skewese':
            # ë¹„ì¦ˆë‹ˆìŠ¤ ìŠ¤íƒ€ì¼
            if 'ë¹„ì¦ˆë‹ˆìŠ¤' not in title and 'ì „ëµ' not in title and 'ì„±ê³µ' not in title:
                return f"{title}ë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒ ì°¾ê¸°"
        elif site == 'tistory':
            # ì¼ë°˜ ë¸”ë¡œê·¸ ìŠ¤íƒ€ì¼
            if 'ë°©ë²•' not in title and 'ê°€ì´ë“œ' not in title:
                return f"{title} ì™„ë²½ ì •ë¦¬"
                
        return title
    
    def _create_profit_optimized_title(self, keyword: str, profit_score: int) -> str:
        """ğŸ”¥ SEO ìµœì í™” ì œëª© ìƒì„± - 2025ë…„ ê²€ìƒ‰ íŠ¸ë Œë“œ ë°˜ì˜"""

        # ì´ˆê³ ìˆ˜ìµ í‚¤ì›Œë“œìš© SEO ìµœì í™” ì œëª© (profit_score 90+)
        if profit_score >= 90:
            ultra_templates = [
                f"{keyword} TOP 10 ìˆœìœ„ (ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸) ê¼­ ì•Œì•„ì•¼ í•  íŒ",
                f"{keyword} ìµœì‹  ì •ë³´ 2025ë…„ 1ì›” ë²„ì „ (ì „ë¬¸ê°€ ê²€ì¦)",
                f"{keyword} ê°€ê²©ë¹„êµ ì´ì •ë¦¬ | ìµœëŒ€ 90% í• ì¸ë°›ëŠ” ë°©ë²•",
                f"{keyword} ì‹¤ì‚¬ìš© í›„ê¸° ëª¨ìŒ (ì¥ë‹¨ì  ë¹„êµë¶„ì„) 2025",
                f"{keyword} ì™„ë²½ê°€ì´ë“œ | 10ë¶„ë§Œì— ì´í•´í•˜ëŠ” í•µì‹¬ì •ë¦¬",
                f"{keyword} ì¶”ì²œìˆœìœ„ BEST 7 | ì‹¤íŒ¨ì—†ëŠ” ì„ íƒë²•",
            ]
            return random.choice(ultra_templates)
        
        # ê³ ìˆ˜ìµ í‚¤ì›Œë“œìš© SEO ì œëª© (profit_score 80-89)
        elif profit_score >= 80:
            high_templates = [
                f"{keyword} ë¹„êµë¶„ì„ 2025 | ê°€ì„±ë¹„ 1ìœ„ëŠ”?",
                f"{keyword} ì™„ë²½ì •ë¦¬ | ì´ˆë³´ìë„ ì´í•´í•˜ëŠ” A to Z",
                f"{keyword} ì¶”ì²œ TOP 5 (ì‹¤íŒ¨ì—†ëŠ” ì„ íƒ) 2025ë…„",
                f"{keyword} ì´ì •ë¦¬ | ì¥ì  ë‹¨ì  ì†”ì§í•œ ë¹„êµ",
                f"{keyword} ê°€ì´ë“œ 2025 | 5ë¶„ë§Œì— ë§ˆìŠ¤í„°í•˜ê¸°",
            ]
            return random.choice(high_templates)
        
        # ì¤‘ê°„ ìˆ˜ìµ í‚¤ì›Œë“œìš© SEO ì œëª© (profit_score 70-79)
        elif profit_score >= 70:
            medium_templates = [
                f"{keyword} ì •ë¦¬ | ê¼­ ì•Œì•„ì•¼ í•  í•µì‹¬ 5ê°€ì§€",
                f"{keyword} ë¹„êµ 2025 | ì–´ë–¤ê²Œ ì„ íƒí•˜ë©´ ì¢‹ì„ê¹Œ?",
                f"{keyword} ê°€ì´ë“œ | ì²˜ìŒì´ë¼ë©´ ì´ê²ƒë§Œ ì•Œì•„ë„ OK",
                f"{keyword} ì¶”ì²œ 2025 | ì‹¤íŒ¨í•˜ì§€ ì•ŠëŠ” íŒ",
            ]
            return random.choice(medium_templates)
        
        # ê¸°ë³¸ ìˆ˜ìµì„± í‚¤ì›Œë“œìš© SEO ì œëª© (profit_score 70 ë¯¸ë§Œ)
        else:
            basic_templates = [
                f"{keyword} ê¸°ì´ˆê°€ì´ë“œ | ì²˜ìŒ ì‹œì‘í•˜ëŠ” ë¶„ë“¤ì„ ìœ„í•´",
                f"{keyword} ì •ë³´ 2025 | ê¼­ ì•Œì•„ì•¼ í•  ê²ƒë“¤",
                f"{keyword} ì´í•´í•˜ê¸° | 5ë¶„ ìš”ì•½ì •ë¦¬",
                f"{keyword} ì‹¤ì „ê°€ì´ë“œ | ë°”ë¡œ ì ìš©í•˜ëŠ” íŒ",
            ]
            return random.choice(basic_templates)
    
    def _extract_keywords(self, title: str) -> List[str]:
        """SEO ìµœì í™” í‚¤ì›Œë“œ ì¶”ì¶œ"""
        import re
        words = re.findall(r'[ê°€-í£a-zA-Z0-9]+', title)

        # SEO í•µì‹¬ í‚¤ì›Œë“œ ìš°ì„  ì¶”ì¶œ
        seo_keywords = []
        priority_words = ['2025', 'TOP', 'BEST', 'ìˆœìœ„', 'ë¹„êµ', 'ì¶”ì²œ', 'ê°€ì´ë“œ', 'í›„ê¸°', 'ì •ë¦¬']

        # ìš°ì„  í‚¤ì›Œë“œ ë¨¼ì € ì¶”ê°€
        for word in words:
            if word in priority_words:
                seo_keywords.append(word)

        # ë‚˜ë¨¸ì§€ ì£¼ìš” í‚¤ì›Œë“œ
        stopwords = ['ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì˜', 'ì—', 'ì™€', 'ê³¼', 'ë¡œ', 'ìœ¼ë¡œ', 'ì€', 'ëŠ”']
        for word in words:
            if len(word) > 1 and word not in stopwords and word not in seo_keywords:
                seo_keywords.append(word)

        return seo_keywords[:7]  # SEO í‚¤ì›Œë“œ 7ê°œ
    
    def _enhance_with_seo_keywords(self, title: str) -> str:
        """SEO í‚¤ì›Œë“œë¡œ íƒ€ì´í‹€ ê°•í™”"""
        seo_enhancers = ['2025', 'ìµœì‹ ', 'ì‹¤ì‹œê°„', 'ì—…ë°ì´íŠ¸', 'ì´ì •ë¦¬']

        # ì´ë¯¸ SEO í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
        has_seo = any(enhancer in title for enhancer in seo_enhancers)

        if not has_seo:
            # SEO í‚¤ì›Œë“œ ì¶”ê°€
            import random
            enhancer = random.choice(['2025 ìµœì‹ ', 'ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸', '2025ë…„ 1ì›”'])
            return f"{title} {enhancer}"

        return title

    def save_weekly_plan(self, weekly_plan: Dict) -> bool:
        """ì£¼ê°„ê³„íšì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ - ê°•ë ¥í•œ ì—ëŸ¬ ë°©ì§€"""
        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                conn = self.db.get_connection()
                if not conn:
                    raise Exception("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
                
                with conn.cursor() as cursor:
                    # 1. ê¸°ì¡´ ê°™ì€ ì£¼ì°¨ ê³„íšì´ ìˆëŠ”ì§€ í™•ì¸
                    try:
                        cursor.execute('''
                        SELECT id FROM blog_automation.weekly_plans 
                        WHERE week_start = %s
                        ''', (weekly_plan['week_start'],))
                        
                        existing = cursor.fetchone()
                    except Exception as check_error:
                        logger.warning(f"ê¸°ì¡´ ê³„íš ì²´í¬ ì‹¤íŒ¨: {check_error}")
                        existing = None
                    
                    # 2. JSON ë°ì´í„° ê²€ì¦
                    try:
                        plan_json = json.dumps(weekly_plan, ensure_ascii=False, indent=2)
                        if len(plan_json) > 1000000:  # 1MB ì œí•œ
                            logger.warning("ê³„íš ë°ì´í„°ê°€ ë„ˆë¬´ í¼, ì••ì¶•")
                            # í•„ìš”í•œ ë°ì´í„°ë§Œ ì €ì¥
                            compressed_plan = {
                                'week_start': weekly_plan['week_start'],
                                'week_end': weekly_plan['week_end'],
                                'generated_at': weekly_plan['generated_at'],
                                'plans': weekly_plan['plans'][:28]  # ìµœëŒ€ 28ê°œ ê³„íšë§Œ
                            }
                            plan_json = json.dumps(compressed_plan, ensure_ascii=False)
                    except Exception as json_error:
                        logger.error(f"JSON ë³€í™˜ ì‹¤íŒ¨: {json_error}")
                        return False
                    
                    # 3. ì €ì¥ ì‹¤í–‰
                    if existing:
                        logger.info(f"ê¸°ì¡´ ì£¼ê°„ê³„íš ì—…ë°ì´íŠ¸: {weekly_plan['week_start']}")
                        cursor.execute('''
                        UPDATE blog_automation.weekly_plans 
                        SET plan_data = %s, updated_at = CURRENT_TIMESTAMP
                        WHERE week_start = %s
                        ''', (plan_json, weekly_plan['week_start']))
                    else:
                        logger.info(f"ìƒˆ ì£¼ê°„ê³„íš ìƒì„±: {weekly_plan['week_start']}")
                        cursor.execute('''
                        INSERT INTO blog_automation.weekly_plans (week_start, week_end, plan_data, created_at)
                        VALUES (%s, %s, %s, CURRENT_TIMESTAMP)
                        ''', (weekly_plan['week_start'], weekly_plan['week_end'], plan_json))
                    
                    conn.commit()
                    logger.info(f"âœ… ì£¼ê°„ê³„íš ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ ({len(weekly_plan['plans'])}ê°œ í•­ëª©)")
                    return True
                    
            except Exception as e:
                retry_count += 1
                logger.error(f"ì£¼ê°„ê³„íš ì €ì¥ ì‹¤íŒ¨ (ì‹œë„ {retry_count}/{max_retries}): {e}")
                
                if retry_count == 1:
                    # ì²« ì‹¤íŒ¨ì‹œ í…Œì´ë¸” ìƒì„± ì‹œë„
                    try:
                        logger.info("í…Œì´ë¸” ìƒì„± ì‹œë„")
                        self._create_weekly_plans_table()
                        continue  # ì¬ì‹œë„
                    except Exception as table_error:
                        logger.error(f"í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {table_error}")
                
                if retry_count < max_retries:
                    import time
                    time.sleep(2)  # 2ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
                    continue
                else:
                    logger.error("ì£¼ê°„ê³„íš ì €ì¥ ìµœì¢… ì‹¤íŒ¨")
                    return False
    
    def _create_weekly_plans_table(self):
        """weekly_plans í…Œì´ë¸” ìƒì„±"""
        try:
            conn = self.db.get_connection()
            with conn.cursor() as cursor:
                cursor.execute('''
                CREATE TABLE IF NOT EXISTS blog_automation.weekly_plans (
                    id SERIAL PRIMARY KEY,
                    week_start DATE NOT NULL,
                    week_end DATE NOT NULL,
                    plan_data JSONB NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(week_start)
                )
                ''')
                conn.commit()
                logger.info("weekly_plans í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
        except Exception as e:
            logger.error(f"í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - í˜„ì¬ì£¼ ìˆ˜ìµì„± ìµœìš°ì„  ê³„íš ìƒì„±"""
    try:
        planner = ProfitWeeklyPlanner()

        # ğŸ”¥ í˜„ì¬ì£¼ ê³„íš ìƒì„± (ìˆ˜ìµì„± ìµœìš°ì„ )
        logger.info("ğŸ”¥ í˜„ì¬ì£¼ ìˆ˜ìµì„± ìµœìš°ì„  ì£¼ê°„ê³„íš ìƒì„± ì‹œì‘")
        weekly_plan = planner.generate_weekly_plan(target_week='current')
        
        if not weekly_plan or not weekly_plan.get('plans'):
            logger.error("ì£¼ê°„ê³„íš ìƒì„± ì‹¤íŒ¨ ë˜ëŠ” ë¹ˆ ê³„íš")
            return False
            
        logger.info(f"í˜„ì¬ì£¼ ê³„íš ìƒì„± ì™„ë£Œ: {len(weekly_plan['plans'])}ê°œ ê³„íš")
        
    except Exception as e:
        logger.error(f"ì£¼ê°„ê³„íš ìƒì„± ë©”ì¸ ì—ëŸ¬: {e}")
        return False
    
    print("ìë™ ìƒì„±ëœ ì£¼ê°„ê³„íš:")
    print(f"ê¸°ê°„: {weekly_plan['week_start']} ~ {weekly_plan['week_end']}")
    print(f"ì´ {len(weekly_plan['plans'])}ê°œ í¬ìŠ¤íŒ… ê³„íš")
    
    print("\nìƒì„¸ ê³„íš:")
    for plan in weekly_plan['plans']:
        print(f"- {plan['date']} ({plan['day_name']}) - {plan['site'].upper()}")
        print(f"  ì œëª©: {plan['title']}")
        print(f"  ì¹´í…Œê³ ë¦¬: {plan['category']} | ìš°ì„ ë„: {plan['priority']} | íŠ¸ë Œë“œì ìˆ˜: {plan['trend_score']}")
        print()
    
    # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (ê°•ë ¥í•œ ì—ëŸ¬ ë°©ì§€)
    try:
        if planner.save_weekly_plan(weekly_plan):
            print("ğŸ‰ í˜„ì¬ì£¼ ìˆ˜ìµì„± ìµœìš°ì„  ì£¼ê°„ê³„íšì´ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            logger.info("í˜„ì¬ì£¼ ì£¼ê°„ê³„íš ìë™ìƒì„± ë° ì €ì¥ ì™„ë£Œ")
            return True
        else:
            print("âŒ ì£¼ê°„ê³„íš ì €ì¥ ì‹¤íŒ¨")
            logger.error("ì£¼ê°„ê³„íš ì €ì¥ ì‹¤íŒ¨")
            return False
    except Exception as save_error:
        print(f"âŒ ì£¼ê°„ê³„íš ì €ì¥ ì¤‘ ì—ëŸ¬: {save_error}")
        logger.error(f"ì£¼ê°„ê³„íš ì €ì¥ ì¤‘ ì—ëŸ¬: {save_error}")
        return False


if __name__ == "__main__":
    main()