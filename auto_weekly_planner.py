"""
ìë™ ì£¼ê°„ê³„íš ìƒì„±ê¸° - ì‹¤ì‹œê°„ íŠ¸ë Œë“œì™€ ìˆ˜ìµë¥  ë°ì´í„° ê¸°ë°˜ ì£¼ê°„ê³„íš ìë™ ìƒì„±
"""

import os
import json
import random
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from src.utils.trend_collector import TrendCollector
from src.utils.postgresql_database import PostgreSQLDatabase
from src.generators.content_generator import ContentGenerator
from src.utils.high_traffic_keyword_manager import HighTrafficKeywordManager
from src.utils.profit_keyword_manager import ProfitKeywordManager
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AutoWeeklyPlanner:
    """ìë™ ì£¼ê°„ê³„íš ìƒì„±ê¸°"""
    
    def __init__(self):
        self.trend_collector = TrendCollector()
        self.db = PostgreSQLDatabase()
        self.content_generator = ContentGenerator()
        self.high_traffic_manager = HighTrafficKeywordManager()
        self.profit_manager = ProfitKeywordManager()
        
        # ì‚¬ì´íŠ¸ë³„ ì„ í˜¸ ì¹´í…Œê³ ë¦¬
        self.site_preferences = {
            'unpre': ['ê¸°ìˆ ', 'AI/ë¨¸ì‹ ëŸ¬ë‹', 'í”„ë¡œê·¸ë˜ë°', 'ìŠ¤íƒ€íŠ¸ì—…', 'íˆ¬ì'],
            'untab': ['ë¼ì´í”„ìŠ¤íƒ€ì¼', 'ì—¬í–‰', 'ìŒì‹', 'ê±´ê°•', 'ì·¨ë¯¸'],
            'skewese': ['ë¹„ì¦ˆë‹ˆìŠ¤', 'ë§ˆì¼€íŒ…', 'ìê¸°ê³„ë°œ', 'ê²½ì œ', 'íŠ¸ë Œë“œ'],
            'tistory': ['ì¼ë°˜', 'í›„ê¸°', 'ì •ë³´', 'íŒ', 'ê°€ì´ë“œ']
        }
        
    def get_trending_topics(self) -> List[Dict]:
        """ğŸ”¥ ìˆ˜ìµì„± 100% ìµœìš°ì„  ì£¼ì œ ìˆ˜ì§‘ - ì‚¬ì´íŠ¸ ì»¨ì…‰ ì™„ì „ ë¬´ì‹œ"""
        all_topics = []
        
        try:
            # 1. ìµœê³  ìˆ˜ìµì„± í‚¤ì›Œë“œ ìš°ì„  (CPC $10-50, profit_score 90+)
            ultra_profit_keywords = self.profit_manager.get_ultra_profit_keywords(12)
            for kw in ultra_profit_keywords:
                all_topics.append({
                    'title': kw['keyword'],
                    'category': 'ultra_profit',
                    'score': kw['profit_score'],
                    'source': 'ultra_profit',
                    'volume': kw['volume'],
                    'cpc': kw['cpc'],
                    'profit_score': kw['profit_score']
                })
            logger.info(f"ì´ˆê³ ìˆ˜ìµ í‚¤ì›Œë“œ {len(ultra_profit_keywords)}ê°œ ìˆ˜ì§‘ (CPC í‰ê·  ${sum([kw['cpc'] for kw in ultra_profit_keywords])//len(ultra_profit_keywords)/1000:.1f}K)")
            
            # 2. í˜„ì¬ ì›” ê³ ìˆ˜ìµ ê³„ì ˆì„± í‚¤ì›Œë“œ
            month_profit_keywords = self.profit_manager.get_current_month_profit_keywords(8)
            for kw in month_profit_keywords:
                all_topics.append({
                    'title': kw['keyword'],
                    'category': 'monthly_profit',
                    'score': kw['profit_score'],
                    'source': 'monthly_profit',
                    'volume': kw['volume'],
                    'cpc': kw['cpc'],
                    'profit_score': kw['profit_score']
                })
            logger.info(f"ì›”ë³„ ê³ ìˆ˜ìµ í‚¤ì›Œë“œ {len(month_profit_keywords)}ê°œ ìˆ˜ì§‘")
            
            # 3. ì œíœ´ ìˆ˜ìµ í‚¤ì›Œë“œ (commission ë†’ì€ ìˆœ)
            for category in ['ê¸ˆìœµ', 'ì‡¼í•‘', 'ì—¬í–‰', 'êµìœ¡']:
                affiliate_keywords = self.profit_manager.get_affiliate_keywords_by_category(category, 2)
                for kw in affiliate_keywords:
                    all_topics.append({
                        'title': kw['keyword'],
                        'category': 'affiliate_profit',
                        'score': min(99, kw['total_profit'] // 1000),  # ì´ ìˆ˜ìµì„ ì ìˆ˜ë¡œ ë³€í™˜
                        'source': f'affiliate_{category}',
                        'volume': kw['volume'],
                        'cpc': kw['cpc'],
                        'commission': kw['commission'],
                        'profit_score': min(99, kw['total_profit'] // 1000)
                    })
            logger.info(f"ì œíœ´ ìˆ˜ìµ í‚¤ì›Œë“œ ì¶”ê°€ ì™„ë£Œ")
            
            # 4. ì‹¤ì‹œê°„ íŠ¸ë Œë“œëŠ” ìµœí›„ ë³´ì™„ìš©ìœ¼ë¡œë§Œ (ìˆ˜ìµì„±ì´ ë–¨ì–´ì§ˆ ê²½ìš°ì—ë§Œ)
            if len(all_topics) < 20:
                logger.warning("ìˆ˜ìµì„± í‚¤ì›Œë“œê°€ ë¶€ì¡±í•˜ì—¬ íŠ¸ë Œë“œë¡œ ë³´ì™„")
                trends = self.trend_collector.collect_all_trends()
                korean_trends = []
                for trend in trends[:5]:  # ìµœì†Œí•œë§Œ
                    korean_trends.append({
                        'title': trend.title,
                        'category': 'low_profit_trend',
                        'score': 30,  # ë‚®ì€ ìˆ˜ìµì„± ì ìˆ˜
                        'source': 'trend_fallback',
                        'volume': 50000,  # ì¶”ì •ì¹˜
                        'profit_score': 30
                    })
                all_topics.extend(korean_trends)
            
            # ğŸ”¥ ìˆ˜ìµì„± ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œë§Œ ì •ë ¬ (volume, íŠ¸ë Œë“œ ì ìˆ˜ ë¬´ì‹œ)
            all_topics.sort(key=lambda x: x.get('profit_score', 0), reverse=True)
            logger.info(f"ì´ {len(all_topics)}ê°œ ì£¼ì œ ìˆ˜ìµì„± ê¸°ì¤€ ì •ë ¬ ì™„ë£Œ")
            
            # ìƒìœ„ 25ê°œë§Œ ì„ íƒ (ëª¨ë‘ ê³ ìˆ˜ìµ)
            return all_topics[:25]
            
        except Exception as e:
            logger.error(f"ìˆ˜ìµì„± í‚¤ì›Œë“œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return self._get_profit_fallback_topics()
    
    def _get_profit_fallback_topics(self) -> List[Dict]:
        """ìˆ˜ìµì„± í‚¤ì›Œë“œ ìˆ˜ì§‘ ì‹¤íŒ¨ì‹œ ìµœì†Œí•œì˜ ìˆ˜ìµì„± ë³´ì¥ ì£¼ì œ"""
        return [
            {'title': 'ì‹ ìš©ëŒ€ì¶œ ê¸ˆë¦¬ ë¹„êµ', 'category': 'profit', 'score': 85, 'volume': 400000, 'profit_score': 85},
            {'title': 'ë¶€ì—… ì¶”ì²œ ìˆœìœ„', 'category': 'profit', 'score': 90, 'volume': 300000, 'profit_score': 90},
            {'title': 'ìë™ì°¨ë³´í—˜ ë¹„êµê²¬ì ', 'category': 'profit', 'score': 80, 'volume': 350000, 'profit_score': 80},
            {'title': 'ë‹¤ì´ì–´íŠ¸ ë³´ì¡°ì œ ì¶”ì²œ', 'category': 'profit', 'score': 85, 'volume': 250000, 'profit_score': 85},
            {'title': 'í† ìµ ì¸ê°• ì¶”ì²œ', 'category': 'profit', 'score': 75, 'volume': 200000, 'profit_score': 75},
        ]
    
    def _get_fallback_topics(self) -> List[Dict]:
        """íŠ¸ë Œë“œ ìˆ˜ì§‘ ì‹¤íŒ¨ì‹œ ëŒ€ì²´ ì£¼ì œ"""
        current_month = datetime.now().month
        current_day = datetime.now().day
        
        fallback_topics = [
            {'title': f'2025ë…„ {current_month}ì›” ì£¼ëª©í•´ì•¼ í•  ê¸°ìˆ  íŠ¸ë Œë“œ', 'category': 'ê¸°ìˆ ', 'score': 100},
            {'title': 'ì„±ê³µí•˜ëŠ” ì‚¬ëŒë“¤ì˜ ì•„ì¹¨ ë£¨í‹´ 5ê°€ì§€', 'category': 'ìê¸°ê³„ë°œ', 'score': 95},
            {'title': f'{current_month}ì›” ì œì²  ìŒì‹ìœ¼ë¡œ ê±´ê°• ì±™ê¸°ê¸°', 'category': 'ê±´ê°•', 'score': 90},
            {'title': 'ë¶€ë™ì‚° íˆ¬ì ì´ˆë³´ìë¥¼ ìœ„í•œ ê°€ì´ë“œ', 'category': 'íˆ¬ì', 'score': 85},
            {'title': 'ì¬íƒê·¼ë¬´ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ë°©ë²•', 'category': 'ë¼ì´í”„ìŠ¤íƒ€ì¼', 'score': 80},
            {'title': 'ì¸ê³µì§€ëŠ¥ ì‹œëŒ€, ì‚´ì•„ë‚¨ëŠ” ì§ì—…ë“¤', 'category': 'AI', 'score': 75},
        ]
        
        return fallback_topics
    
    def categorize_topic_for_site(self, topic: Dict, site: str) -> str:
        """ì‚¬ì´íŠ¸ì— ë§ëŠ” ì¹´í…Œê³ ë¦¬ë¡œ ë³€í™˜"""
        topic_category = topic.get('category', 'ì¼ë°˜').lower()
        site_prefs = self.site_preferences.get(site, ['ì¼ë°˜'])
        
        # ì¹´í…Œê³ ë¦¬ ë§¤í•‘
        category_mapping = {
            'technology': 'ê¸°ìˆ ',
            'tech': 'ê¸°ìˆ ', 
            'ai': 'AI/ë¨¸ì‹ ëŸ¬ë‹',
            'business': 'ë¹„ì¦ˆë‹ˆìŠ¤',
            'lifestyle': 'ë¼ì´í”„ìŠ¤íƒ€ì¼',
            'health': 'ê±´ê°•',
            'food': 'ìŒì‹',
            'travel': 'ì—¬í–‰',
            'finance': 'íˆ¬ì',
            'programming': 'í”„ë¡œê·¸ë˜ë°'
        }
        
        mapped_category = category_mapping.get(topic_category, topic_category)
        
        # ì‚¬ì´íŠ¸ ì„ í˜¸ë„ì— ë§ëŠ” ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
        for pref in site_prefs:
            if pref in mapped_category or mapped_category in pref:
                return pref
                
        return site_prefs[0]  # ê¸°ë³¸ê°’
    
    def generate_weekly_plan(self, start_date: datetime = None, target_week: str = 'current') -> Dict:
        """ì£¼ê°„ê³„íš ìƒì„± - ì—ëŸ¬ ë°©ì§€ ê°•í™”"""
        try:
            if start_date is None:
                start_date = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
                
            # ì´ë²ˆ ì£¼ ë˜ëŠ” ë‹¤ìŒì£¼ ì›”ìš”ì¼ ê³„ì‚° (ì—ëŸ¬ ë°©ì§€)
            try:
                if target_week == 'next':
                    # ë‹¤ìŒì£¼ ì›”ìš”ì¼ ê³„ì‚°
                    days_since_monday = start_date.weekday()
                    days_to_next_monday = 7 - days_since_monday
                    start_date = start_date + timedelta(days=days_to_next_monday)
                else:
                    # ì´ë²ˆ ì£¼ ì›”ìš”ì¼ ê³„ì‚°
                    days_since_monday = start_date.weekday()
                    start_date = start_date - timedelta(days=days_since_monday)
                    
                logger.info(f"ê³„íš ìƒì„± ëŒ€ìƒì£¼: {target_week}, ì‹œì‘ì¼: {start_date.strftime('%Y-%m-%d')}")
            except Exception as date_calc_error:
                logger.error(f"ë‚ ì§œ ê³„ì‚° ì—ëŸ¬: {date_calc_error}")
                raise ValueError(f"ë‚ ì§œ ê³„ì‚° ì‹¤íŒ¨: {date_calc_error}")
        except Exception as init_error:
            logger.error(f"ì£¼ê°„ê³„íš ì´ˆê¸°í™” ì‹¤íŒ¨: {init_error}")
            raise
        
        logger.info(f"ì£¼ê°„ê³„íš ìƒì„± ì‹œì‘: {start_date.strftime('%Y-%m-%d')} ~ {(start_date + timedelta(days=6)).strftime('%Y-%m-%d')}")
        
        # íŠ¸ë Œë”© ì£¼ì œ ìˆ˜ì§‘ (ê°•ë ¥í•œ ì—ëŸ¬ ë°©ì§€)
        try:
            trending_topics = self.get_trending_topics()
            if not trending_topics:
                logger.warning("íŠ¸ë Œë”© ì£¼ì œê°€ ì—†ìŒ, ê¸°ë³¸ ìˆ˜ìµì„± ì£¼ì œ ì‚¬ìš©")
                trending_topics = self._get_profit_fallback_topics()
            logger.info(f"{len(trending_topics)}ê°œ íŠ¸ë Œë”© ì£¼ì œ ìˆ˜ì§‘ ì™„ë£Œ")
        except Exception as trend_error:
            logger.error(f"íŠ¸ë Œë”© ì£¼ì œ ìˆ˜ì§‘ ì‹¤íŒ¨: {trend_error}")
            logger.info("ê¸°ë³¸ ìˆ˜ìµì„± ì£¼ì œë¡œ ëŒ€ì²´")
            trending_topics = self._get_profit_fallback_topics()
        
        sites = ['unpre', 'untab', 'skewese', 'tistory']
        weekly_plan = {
            'week_start': start_date.strftime('%Y-%m-%d'),
            'week_end': (start_date + timedelta(days=6)).strftime('%Y-%m-%d'),
            'generated_at': datetime.now().isoformat(),
            'plans': []
        }
        
        # ìš”ì¼ë³„ ê³„íš ìƒì„± (ì›”-ì¼, 7ì¼) - ê°•ë ¥í•œ ì—ëŸ¬ ë°©ì§€
        topic_idx = 0
        successful_plans = 0
        
        try:
            for day_offset in range(7):
                try:
                    current_date = start_date + timedelta(days=day_offset)
                    day_names = ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼']
                    day_name = day_names[day_offset] if day_offset < len(day_names) else f'Day_{day_offset}'
                    
                    # í•˜ë£¨ì— ëª¨ë“  ì‚¬ì´íŠ¸(4ê°œ)ì— í¬ìŠ¤íŒ…
                    sites_for_day = sites  # ëª¨ë“  ì‚¬ì´íŠ¸ì— ë§¤ì¼ í¬ìŠ¤íŒ…
                    
                    for site in sites_for_day:
                        try:
                            # ğŸ”¥ ì‚¬ì´íŠ¸ êµ¬ë¶„ ì™„ì „ ë¬´ì‹œ, ìˆ˜ìµì„± ìµœìš°ì„  ì£¼ì œë§Œ ì‚¬ìš©
                            if topic_idx >= len(trending_topics):
                                topic_idx = 0  # ìˆ˜ìµì„± ì£¼ì œ ìˆœí™˜
                            
                            topic = trending_topics[topic_idx]
                            
                            # ìˆ˜ìµì„± ìµœì í™” ì¹´í…Œê³ ë¦¬ë¡œ í†µì¼ (ì‚¬ì´íŠ¸ë³„ ì¹´í…Œê³ ë¦¬ ë¬´ì‹œ)
                            if topic.get('profit_score', 0) >= 90:
                                category = 'ultra_profit'
                            elif topic.get('profit_score', 0) >= 80:
                                category = 'high_profit' 
                            elif topic.get('profit_score', 0) >= 70:
                                category = 'medium_profit'
                            else:
                                category = 'profit_optimized'
                            
                            logger.info(f"{site} ìˆ˜ìµì„± ì£¼ì œ ì ìš© (ì ìˆ˜: {topic.get('profit_score', 0)}): {topic['title'][:50]}...")
                            
                            # ìˆ˜ìµì„± ìµœì í™” ì œëª© ìƒì„± (ì‚¬ì´íŠ¸ë³„ êµ¬ë¶„ ì—†ì´)
                            try:
                                title = self._create_profit_optimized_title(topic['title'], topic.get('profit_score', 0))
                            except Exception as title_error:
                                logger.warning(f"ì œëª© ìƒì„± ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {title_error}")
                                title = topic['title']
                            
                            try:
                                keywords = self._extract_keywords(title)
                            except Exception as keyword_error:
                                logger.warning(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {keyword_error}")
                                keywords = [topic['title'][:20]]
                            
                            plan_item = {
                                'date': current_date.strftime('%Y-%m-%d'),
                                'day_name': day_name,
                                'site': site,
                                'title': title,
                                'category': category,
                                'original_topic': topic.get('title', 'Unknown Topic'),
                                'trend_score': topic.get('score', 0),
                                'profit_score': topic.get('profit_score', 0),
                                'cpc': topic.get('cpc', 0),
                                'volume': topic.get('volume', 0),
                                'source': topic.get('source', 'Unknown'),
                                'keywords': keywords,
                                'status': 'planned',
                                'priority': 'ultra' if topic.get('profit_score', 0) >= 90 else ('high' if topic.get('profit_score', 0) >= 80 else 'medium')
                            }
                            
                            weekly_plan['plans'].append(plan_item)
                            successful_plans += 1
                            topic_idx += 1
                            
                        except Exception as site_error:
                            logger.error(f"{site} ì‚¬ì´íŠ¸ ê³„íš ìƒì„± ì‹¤íŒ¨: {site_error}")
                            continue  # ë‹¤ìŒ ì‚¬ì´íŠ¸ë¡œ ê³„ì†
                            
                except Exception as day_error:
                    logger.error(f"{day_name} ê³„íš ìƒì„± ì‹¤íŒ¨: {day_error}")
                    continue  # ë‹¤ìŒ ë‚ ë¡œ ê³„ì†
                    
        except Exception as main_loop_error:
            logger.error(f"ì£¼ê°„ê³„íš ìƒì„± ë£¨í”„ ì‹¤íŒ¨: {main_loop_error}")
            
        # ìµœì†Œ ê³„íš ê²€ì¦
        if successful_plans == 0:
            logger.error("ì£¼ê°„ê³„íš ìƒì„± ì™„ì „ ì‹¤íŒ¨, ê¸°ë³¸ ê³„íš ìƒì„±")
            # ê¸°ë³¸ ê³„íšì´ë¼ë„ ë§Œë“¤ì–´ì•¼ í•¨
            for i in range(7):
                try:
                    basic_date = start_date + timedelta(days=i)
                    basic_plan = {
                        'date': basic_date.strftime('%Y-%m-%d'),
                        'day_name': ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼'][i],
                        'site': 'unpre',
                        'title': f'ìˆ˜ìµì„± í‚¤ì›Œë“œ ê¸°ë³¸ ê³„íš {basic_date.strftime("%mì›” %dì¼")}',
                        'category': 'profit_optimized',
                        'original_topic': 'ê¸°ë³¸ ìˆ˜ìµì„± ì£¼ì œ',
                        'profit_score': 70,
                        'status': 'planned',
                        'priority': 'medium'
                    }
                    weekly_plan['plans'].append(basic_plan)
                    successful_plans += 1
                except:
                    continue
        
        logger.info(f"ì£¼ê°„ê³„íš ìƒì„± ì™„ë£Œ: {len(weekly_plan['plans'])}ê°œ ì•„ì´í…œ")
        return weekly_plan
    
    def _translate_to_korean(self, title: str) -> str:
        """ì˜ì–´ ì œëª©ì„ í•œêµ­ì–´ë¡œ ë³€í™˜"""
        # ìì£¼ ë‚˜ì˜¤ëŠ” ì˜ì–´ í‚¤ì›Œë“œë“¤ì„ í•œêµ­ì–´ë¡œ ë§¤í•‘
        translations = {
            'AI': 'AI',
            'artificial intelligence': 'ì¸ê³µì§€ëŠ¥',
            'machine learning': 'ë¨¸ì‹ ëŸ¬ë‹',
            'blockchain': 'ë¸”ë¡ì²´ì¸',
            'cryptocurrency': 'ì•”í˜¸í™”í',
            'bitcoin': 'ë¹„íŠ¸ì½”ì¸',
            'technology': 'ê¸°ìˆ ',
            'startup': 'ìŠ¤íƒ€íŠ¸ì—…',
            'business': 'ë¹„ì¦ˆë‹ˆìŠ¤',
            'marketing': 'ë§ˆì¼€íŒ…',
            'finance': 'ê¸ˆìœµ',
            'investment': 'íˆ¬ì',
            'health': 'ê±´ê°•',
            'lifestyle': 'ë¼ì´í”„ìŠ¤íƒ€ì¼',
            'travel': 'ì—¬í–‰',
            'food': 'ìŒì‹',
            'programming': 'í”„ë¡œê·¸ë˜ë°',
            'development': 'ê°œë°œ',
            'web': 'ì›¹',
            'mobile': 'ëª¨ë°”ì¼',
            'cloud': 'í´ë¼ìš°ë“œ',
            'data': 'ë°ì´í„°',
            'security': 'ë³´ì•ˆ',
            'productivity': 'ìƒì‚°ì„±',
            'remote work': 'ì¬íƒê·¼ë¬´',
            'social media': 'ì†Œì…œë¯¸ë””ì–´',
            'ecommerce': 'ì „ììƒê±°ë˜',
            'education': 'êµìœ¡',
            'learning': 'í•™ìŠµ',
            'tips': 'íŒ',
            'guide': 'ê°€ì´ë“œ',
            'tutorial': 'íŠœí† ë¦¬ì–¼',
            'review': 'ë¦¬ë·°',
            'news': 'ë‰´ìŠ¤',
            'trend': 'íŠ¸ë Œë“œ',
            'future': 'ë¯¸ë˜',
            'innovation': 'í˜ì‹ ',
            'digital': 'ë””ì§€í„¸'
        }
        
        # ì˜ì–´ê°€ í¬í•¨ëœ ì œëª©ì¸ ê²½ìš° í•œêµ­ì–´ë¡œ ë³€í™˜ ì‹œë„
        korean_title = title.lower()
        for eng, kor in translations.items():
            korean_title = korean_title.replace(eng, kor)
            
        # ì²« ê¸€ì ëŒ€ë¬¸ìë¡œ ë³µì› ë° ì •ë¦¬
        korean_title = korean_title.capitalize()
        
        # ì˜ì–´ ì œëª©ì´ë©´ í•œêµ­ì–´ ìŠ¤íƒ€ì¼ë¡œ ì¬ì‘ì„±
        if not any(ord(char) >= 0xAC00 and ord(char) <= 0xD7A3 for char in title):
            # ì™„ì „ ì˜ì–´ ì œëª©ì¸ ê²½ìš° í•œêµ­ì–´ ì£¼ì œë¡œ ë³€í™˜
            korean_topics = [
                f"2025ë…„ ì£¼ëª©í•´ì•¼ í•  {korean_title} íŠ¸ë Œë“œ",
                f"{korean_title} ì™„ë²½ ê°€ì´ë“œ",
                f"{korean_title}ë¡œ ì„±ê³µí•˜ëŠ” ë°©ë²•",
                f"{korean_title} ì´ˆë³´ìë¥¼ ìœ„í•œ ì‹¤ì „ íŒ",
                f"{korean_title}ì˜ ëª¨ë“  ê²ƒ",
                f"{korean_title} ì „ë¬¸ê°€ê°€ ë˜ëŠ” 5ë‹¨ê³„"
            ]
            import random
            return random.choice(korean_topics)
            
        return korean_title.strip()

    def _adjust_title_for_site(self, original_title: str, site: str) -> str:
        """ì‚¬ì´íŠ¸ë³„ ì œëª© ì¡°ì •"""
        # ë¨¼ì € í•œêµ­ì–´ë¡œ ë³€í™˜
        title = self._translate_to_korean(original_title)
        
        if site == 'unpre':
            # ê¸°ìˆ /ìŠ¤íƒ€íŠ¸ì—… ìŠ¤íƒ€ì¼
            if not any(word in title for word in ['ê¸°ìˆ ', 'ê°œë°œ', 'AI', 'ìŠ¤íƒ€íŠ¸ì—…', 'IT']):
                return f"{title}ì´ IT ì—…ê³„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥"
        elif site == 'untab':
            # ë¼ì´í”„ìŠ¤íƒ€ì¼ ìŠ¤íƒ€ì¼  
            if 'ë°©ë²•' not in title and 'ê°€ì´ë“œ' not in title and 'íŒ' not in title:
                return f"{title}, ì•Œì•„ì•¼ í•  5ê°€ì§€"
        elif site == 'skewese':
            # ë¹„ì¦ˆë‹ˆìŠ¤ ìŠ¤íƒ€ì¼
            if 'ë¹„ì¦ˆë‹ˆìŠ¤' not in title and 'ì „ëµ' not in title and 'ì„±ê³µ' not in title:
                return f"{title}ë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒ ì°¾ê¸°"
        elif site == 'tistory':
            # ì¼ë°˜ ë¸”ë¡œê·¸ ìŠ¤íƒ€ì¼
            if 'ë°©ë²•' not in title and 'ê°€ì´ë“œ' not in title:
                return f"{title} ì™„ë²½ ì •ë¦¬"
                
        return title
    
    def _create_profit_optimized_title(self, keyword: str, profit_score: int) -> str:
        """ğŸ”¥ ìˆ˜ìµì„± ìµœì í™” ì œëª© ìƒì„± - CTRê³¼ ìˆ˜ìµì„± ìµœëŒ€í™”"""
        
        # ì´ˆê³ ìˆ˜ìµ í‚¤ì›Œë“œìš© ê°•ë ¥í•œ ì œëª© (profit_score 90+)
        if profit_score >= 90:
            ultra_templates = [
                f"{keyword} ì™„ë²½ ë¹„êµ 2025ë…„ TOP ìˆœìœ„ ìˆ¨ê²¨ì§„ í˜œíƒê¹Œì§€ ì´ì •ë¦¬",
                f"{keyword} ì‹¤ì œ í›„ê¸° ì „ë¬¸ê°€ê°€ ì¸ì •í•œ ë² ìŠ¤íŠ¸ ì„ íƒê³¼ í• ì¸ í˜œíƒ",
                f"{keyword} ê°€ê²© ë¹„êµ ìµœì €ê°€ ë³´ì¥ê³¼ íŠ¹ë³„ í• ì¸ ë°›ëŠ” ì™„ë²½ ê°€ì´ë“œ",
                f"{keyword} ì¶”ì²œ ìˆœìœ„ ì‹¤ì‚¬ìš©ì ë§Œì¡±ë„ 1ìœ„ ì—…ì²´ì™€ í˜œíƒ ì •ë³´",
                f"{keyword} ì™„ì „ ë¶„ì„ ìˆ¨ê²¨ì§„ ìˆ˜ìˆ˜ë£Œê¹Œì§€ íˆ¬ëª…í•˜ê²Œ ê³µê°œ",
            ]
            return random.choice(ultra_templates)
        
        # ê³ ìˆ˜ìµ í‚¤ì›Œë“œìš© (profit_score 80-89)  
        elif profit_score >= 80:
            high_templates = [
                f"{keyword} ìˆœìœ„ ë¹„êµ 2025ë…„ ë² ìŠ¤íŠ¸ ì¶”ì²œê³¼ í• ì¸ í˜œíƒ",
                f"{keyword} ì™„ë²½ ê°€ì´ë“œ ì‹¤ì œ ì´ìš©ì í›„ê¸°ì™€ íŠ¹ê°€ ì •ë³´",
                f"{keyword} ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ ì „ë¬¸ê°€ ì„ ì • TOP 5ì™€ í• ì¸ ë°›ê¸°",
                f"{keyword} ë¹„êµ ë¶„ì„ ì¥ë‹¨ì  ì •ë¦¬ì™€ ìµœëŒ€ í˜œíƒ ë°©ë²•",
            ]
            return random.choice(high_templates)
        
        # ì¤‘ê°„ ìˆ˜ìµ í‚¤ì›Œë“œìš© (profit_score 70-79)
        elif profit_score >= 70:
            medium_templates = [
                f"{keyword} ì¶”ì²œ 2025ë…„ ì¸ê¸° ìˆœìœ„ì™€ í• ì¸ ì •ë³´",
                f"{keyword} ë¹„êµ ê°€ì´ë“œ ì‹¤ì œ í›„ê¸°ì™€ í˜œíƒ ì •ë¦¬", 
                f"{keyword} ì„ íƒ ê°€ì´ë“œ ì „ë¬¸ê°€ ì¶”ì²œê³¼ íŒ",
                f"{keyword} ì™„ë²½ ì •ë¦¬ 2025ë…„ ìµœì‹  ì •ë³´",
            ]
            return random.choice(medium_templates)
        
        # ê¸°ë³¸ ìˆ˜ìµì„± í‚¤ì›Œë“œìš© (profit_score 70 ë¯¸ë§Œ)
        else:
            basic_templates = [
                f"{keyword} ê°€ì´ë“œ 2025ë…„ ìµœì‹  ì •ë³´",
                f"{keyword} ì¶”ì²œ ì •ë¦¬",
                f"{keyword} ì™„ë²½ ë¶„ì„",
                f"{keyword} ì´ì •ë¦¬",
            ]
            return random.choice(basic_templates)
    
    def _extract_keywords(self, title: str) -> List[str]:
        """ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP ì‚¬ìš© ê°€ëŠ¥)
        import re
        words = re.findall(r'[ê°€-í£a-zA-Z]+', title)
        
        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = ['ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì˜', 'ì—', 'ì™€', 'ê³¼', 'ë¡œ', 'ìœ¼ë¡œ', 'ì€', 'ëŠ”', 'ì…ë‹ˆë‹¤', 'ìŠµë‹ˆë‹¤']
        keywords = [word for word in words if len(word) > 1 and word not in stopwords]
        
        return keywords[:5]  # ìƒìœ„ 5ê°œ
    
    def save_weekly_plan(self, weekly_plan: Dict) -> bool:
        """ì£¼ê°„ê³„íšì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ - ê°•ë ¥í•œ ì—ëŸ¬ ë°©ì§€"""
        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                conn = self.db.get_connection()
                if not conn:
                    raise Exception("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
                
                with conn.cursor() as cursor:
                    # 1. ê¸°ì¡´ ê°™ì€ ì£¼ì°¨ ê³„íšì´ ìˆëŠ”ì§€ í™•ì¸
                    try:
                        cursor.execute('''
                        SELECT id FROM blog_automation.weekly_plans 
                        WHERE week_start = %s
                        ''', (weekly_plan['week_start'],))
                        
                        existing = cursor.fetchone()
                    except Exception as check_error:
                        logger.warning(f"ê¸°ì¡´ ê³„íš ì²´í¬ ì‹¤íŒ¨: {check_error}")
                        existing = None
                    
                    # 2. JSON ë°ì´í„° ê²€ì¦
                    try:
                        plan_json = json.dumps(weekly_plan, ensure_ascii=False, indent=2)
                        if len(plan_json) > 1000000:  # 1MB ì œí•œ
                            logger.warning("ê³„íš ë°ì´í„°ê°€ ë„ˆë¬´ í¼, ì••ì¶•")
                            # í•„ìš”í•œ ë°ì´í„°ë§Œ ì €ì¥
                            compressed_plan = {
                                'week_start': weekly_plan['week_start'],
                                'week_end': weekly_plan['week_end'],
                                'generated_at': weekly_plan['generated_at'],
                                'plans': weekly_plan['plans'][:28]  # ìµœëŒ€ 28ê°œ ê³„íšë§Œ
                            }
                            plan_json = json.dumps(compressed_plan, ensure_ascii=False)
                    except Exception as json_error:
                        logger.error(f"JSON ë³€í™˜ ì‹¤íŒ¨: {json_error}")
                        return False
                    
                    # 3. ì €ì¥ ì‹¤í–‰
                    if existing:
                        logger.info(f"ê¸°ì¡´ ì£¼ê°„ê³„íš ì—…ë°ì´íŠ¸: {weekly_plan['week_start']}")
                        cursor.execute('''
                        UPDATE blog_automation.weekly_plans 
                        SET plan_data = %s, updated_at = CURRENT_TIMESTAMP
                        WHERE week_start = %s
                        ''', (plan_json, weekly_plan['week_start']))
                    else:
                        logger.info(f"ìƒˆ ì£¼ê°„ê³„íš ìƒì„±: {weekly_plan['week_start']}")
                        cursor.execute('''
                        INSERT INTO blog_automation.weekly_plans (week_start, week_end, plan_data, created_at)
                        VALUES (%s, %s, %s, CURRENT_TIMESTAMP)
                        ''', (weekly_plan['week_start'], weekly_plan['week_end'], plan_json))
                    
                    conn.commit()
                    logger.info(f"âœ… ì£¼ê°„ê³„íš ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ ({len(weekly_plan['plans'])}ê°œ í•­ëª©)")
                    return True
                    
            except Exception as e:
                retry_count += 1
                logger.error(f"ì£¼ê°„ê³„íš ì €ì¥ ì‹¤íŒ¨ (ì‹œë„ {retry_count}/{max_retries}): {e}")
                
                if retry_count == 1:
                    # ì²« ì‹¤íŒ¨ì‹œ í…Œì´ë¸” ìƒì„± ì‹œë„
                    try:
                        logger.info("í…Œì´ë¸” ìƒì„± ì‹œë„")
                        self._create_weekly_plans_table()
                        continue  # ì¬ì‹œë„
                    except Exception as table_error:
                        logger.error(f"í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {table_error}")
                
                if retry_count < max_retries:
                    import time
                    time.sleep(2)  # 2ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
                    continue
                else:
                    logger.error("ì£¼ê°„ê³„íš ì €ì¥ ìµœì¢… ì‹¤íŒ¨")
                    return False
    
    def _create_weekly_plans_table(self):
        """weekly_plans í…Œì´ë¸” ìƒì„±"""
        try:
            conn = self.db.get_connection()
            with conn.cursor() as cursor:
                cursor.execute('''
                CREATE TABLE IF NOT EXISTS blog_automation.weekly_plans (
                    id SERIAL PRIMARY KEY,
                    week_start DATE NOT NULL,
                    week_end DATE NOT NULL,
                    plan_data JSONB NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(week_start)
                )
                ''')
                conn.commit()
                logger.info("weekly_plans í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
        except Exception as e:
            logger.error(f"í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ë‹¤ìŒì£¼ ìˆ˜ìµì„± ìµœìš°ì„  ê³„íš ìƒì„±"""
    try:
        planner = AutoWeeklyPlanner()
        
        # ğŸ”¥ ë‹¤ìŒì£¼ ê³„íš ìƒì„± (ìˆ˜ìµì„± ìµœìš°ì„ )
        logger.info("ğŸ”¥ ë‹¤ìŒì£¼ ìˆ˜ìµì„± ìµœìš°ì„  ì£¼ê°„ê³„íš ìƒì„± ì‹œì‘")
        weekly_plan = planner.generate_weekly_plan(target_week='next')
        
        if not weekly_plan or not weekly_plan.get('plans'):
            logger.error("ì£¼ê°„ê³„íš ìƒì„± ì‹¤íŒ¨ ë˜ëŠ” ë¹ˆ ê³„íš")
            return False
            
        logger.info(f"ë‹¤ìŒì£¼ ê³„íš ìƒì„± ì™„ë£Œ: {len(weekly_plan['plans'])}ê°œ ê³„íš")
        
    except Exception as e:
        logger.error(f"ì£¼ê°„ê³„íš ìƒì„± ë©”ì¸ ì—ëŸ¬: {e}")
        return False
    
    print("ìë™ ìƒì„±ëœ ì£¼ê°„ê³„íš:")
    print(f"ê¸°ê°„: {weekly_plan['week_start']} ~ {weekly_plan['week_end']}")
    print(f"ì´ {len(weekly_plan['plans'])}ê°œ í¬ìŠ¤íŒ… ê³„íš")
    
    print("\nìƒì„¸ ê³„íš:")
    for plan in weekly_plan['plans']:
        print(f"- {plan['date']} ({plan['day_name']}) - {plan['site'].upper()}")
        print(f"  ì œëª©: {plan['title']}")
        print(f"  ì¹´í…Œê³ ë¦¬: {plan['category']} | ìš°ì„ ë„: {plan['priority']} | íŠ¸ë Œë“œì ìˆ˜: {plan['trend_score']}")
        print()
    
    # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (ê°•ë ¥í•œ ì—ëŸ¬ ë°©ì§€)
    try:
        if planner.save_weekly_plan(weekly_plan):
            print("ğŸ‰ ë‹¤ìŒì£¼ ìˆ˜ìµì„± ìµœìš°ì„  ì£¼ê°„ê³„íšì´ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            logger.info("ë‹¤ìŒì£¼ ì£¼ê°„ê³„íš ìë™ìƒì„± ë° ì €ì¥ ì™„ë£Œ")
            return True
        else:
            print("âŒ ì£¼ê°„ê³„íš ì €ì¥ ì‹¤íŒ¨")
            logger.error("ì£¼ê°„ê³„íš ì €ì¥ ì‹¤íŒ¨")
            return False
    except Exception as save_error:
        print(f"âŒ ì£¼ê°„ê³„íš ì €ì¥ ì¤‘ ì—ëŸ¬: {save_error}")
        logger.error(f"ì£¼ê°„ê³„íš ì €ì¥ ì¤‘ ì—ëŸ¬: {save_error}")
        return False


if __name__ == "__main__":
    main()