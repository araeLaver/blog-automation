"""
Koyeb ë°°í¬ìš© ì›¹ ì„œë²„ ì•±
"""

import os
import sys
from pathlib import Path
from flask import Flask, render_template, jsonify, request, send_file, make_response
from flask_cors import CORS
from datetime import datetime, timedelta, date, timezone
import pytz
import json
import logging
import logging.handlers
from dotenv import load_dotenv
import psycopg2
from psycopg2.extras import RealDictCursor
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
import atexit
import threading

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ import
from src.utils.postgresql_database import PostgreSQLDatabase
from src.utils.schedule_manager import ScheduleManager
from src.utils.api_tracker import api_tracker

# AI ì½˜í…ì¸  ìƒì„± import (ë‚˜ì¤‘ì— ì´ˆê¸°í™”)

# Flask ì•± ìƒì„±
app = Flask(__name__, 
            template_folder='templates',
            static_folder='static',
            static_url_path='/static')  # ì •ì  íŒŒì¼ ê²½ë¡œ ëª…ì‹œ
CORS(app)

# í…œí”Œë¦¿ ìºì‹± ë¹„í™œì„±í™”
app.config['TEMPLATES_AUTO_RELOAD'] = True
app.jinja_env.auto_reload = True

# ë¡œê¹… ì„¤ì •
# ë¡œê¹… ì„¤ì • ê°•í™” - íŒŒì¼ê³¼ ì½˜ì†” ë™ì‹œ ì¶œë ¥
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('blog_automation.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ì¸ë©”ëª¨ë¦¬ ë¡œê·¸ ì €ì¥ì†Œ
_memory_logs = []

def add_system_log(level: str, message: str, category: str = 'SYSTEM'):
    """ì‹œìŠ¤í…œ ë¡œê·¸ ì¶”ê°€"""
    global _memory_logs
    
    log_entry = {
        'time': datetime.now().strftime('%H:%M:%S'),
        'level': level.lower(),
        'message': f"[{category}] {message}",
        'timestamp': datetime.now().timestamp()
    }
    
    _memory_logs.append(log_entry)
    
    # ìµœê·¼ 200ê°œë§Œ ìœ ì§€
    if len(_memory_logs) > 200:
        _memory_logs = _memory_logs[-200:]
    
    # ì‹¤ì œ ë¡œê·¸ë„ ê¸°ë¡
    if level.upper() == 'ERROR':
        logger.error(f"[{category}] {message}")
    elif level.upper() == 'WARNING':
        logger.warning(f"[{category}] {message}")
    else:
        logger.info(f"[{category}] {message}")

def get_recent_logs():
    """ìµœê·¼ ë¡œê·¸ ê°€ì ¸ì˜¤ê¸°"""
    global _memory_logs
    return _memory_logs.copy()

# AI ì½˜í…ì¸  ìƒì„±ê¸° ì´ˆê¸°í™”
try:
    from src.generators.content_generator import ContentGenerator
    content_generator = ContentGenerator()
    logger.info("âœ… Claude API ì½˜í…ì¸  ìƒì„±ê¸° ì´ˆê¸°í™” ì™„ë£Œ - v2.0")
    add_system_log('INFO', 'Claude API ì½˜í…ì¸  ìƒì„±ê¸° ì´ˆê¸°í™” ì™„ë£Œ', 'STARTUP')
except Exception as e:
    logger.warning(f"âš ï¸ Claude API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    add_system_log('ERROR', f'Claude API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}', 'STARTUP')
    content_generator = None

# í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
KST = pytz.timezone('Asia/Seoul')

# PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ (ì „ì—­)
db = None
schedule_manager = None

def get_database():
    """ë°ì´í„°ë² ì´ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global db
    if db is None:
        db = PostgreSQLDatabase()
    return db

def get_schedule_manager():
    """ìŠ¤ì¼€ì¤„ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global schedule_manager
    if schedule_manager is None:
        schedule_manager = ScheduleManager()
    return schedule_manager

# PostgreSQL ì—°ê²° í•¨ìˆ˜
def get_db_connection():
    """PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
    try:
        conn = psycopg2.connect(
            host=os.getenv('PG_HOST'),
            port=os.getenv('PG_PORT', 5432),
            database=os.getenv('PG_DATABASE'),
            user=os.getenv('PG_USER'),
            password=os.getenv('PG_PASSWORD'),
            options=f"-c search_path={os.getenv('PG_SCHEMA', 'unble')}"
        )
        return conn
    except Exception as e:
        logger.error(f"Database connection failed: {e}")
        return None

def get_mock_data():
    """DB ì—°ê²° ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ëª©ì—… ë°ì´í„°"""
    now = datetime.now(KST)
    today_3am = now.replace(hour=3, minute=0, second=0, microsecond=0)
    
    # ì˜¤ëŠ˜ ìƒˆë²½ 3ì‹œì— ìë™ë°œí–‰ëœ í¬ìŠ¤íŠ¸ë“¤ ìƒì„±
    posts = []
    
    # ì˜¤ëŠ˜ ìë™ë°œí–‰ëœ í¬ìŠ¤íŠ¸ë“¤ (ìƒˆë²½ 3ì‹œ ì´í›„ë¼ë©´)
    if now >= today_3am:
        posts.extend([
            {
                'id': 1,
                'title': 'ğŸ¤– AI ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ìµœì‹  ë™í–¥',
                'site': 'unpre',
                'category': 'AI/í”„ë¡œê·¸ë˜ë°',
                'url': 'https://unpre.co.kr/ai-coding-assistant-2025',
                'created_at': today_3am.strftime('%Y-%m-%d %H:%M:%S'),
                'published': True
            },
            {
                'id': 2,
                'title': 'ğŸ“š íš¨ìœ¨ì ì¸ ì–¸ì–´í•™ìŠµì„ ìœ„í•œ 5ê°€ì§€ ë°©ë²•',
                'site': 'untab',
                'category': 'êµìœ¡/ì–¸ì–´í•™ìŠµ',
                'url': 'https://untab.co.kr/language-learning-tips-2025',
                'created_at': today_3am.strftime('%Y-%m-%d %H:%M:%S'),
                'published': True
            },
            {
                'id': 3,
                'title': 'ğŸ›ï¸ ì¡°ì„ ì‹œëŒ€ ê³¼í•™ê¸°ìˆ ì˜ ë†€ë¼ìš´ ë°œì „',
                'site': 'skewese',
                'category': 'ì—­ì‚¬/ë¬¸í™”',
                'url': 'https://skewese.com/joseon-science-technology',
                'created_at': today_3am.strftime('%Y-%m-%d %H:%M:%S'),
                'published': True
            },
            {
                'id': 4,
                'title': 'ğŸ“Š 2025ë…„ AI ì‹œì¥ ì „ë§ê³¼ íˆ¬ì íŠ¸ë Œë“œ',
                'site': 'tistory',
                'category': 'íŠ¸ë Œë“œ/ì´ìŠˆ',
                'url': None,  # ë°œí–‰ë˜ì§€ ì•ŠìŒ
                'created_at': today_3am.strftime('%Y-%m-%d %H:%M:%S'),
                'published': False,
                'note': 'ìƒì„±ë¨ (ìˆ˜ë™ ë°œí–‰ í•„ìš”)'
            }
        ])
    
    # ì–´ì œ ë°œí–‰ëœ í¬ìŠ¤íŠ¸ë“¤
    yesterday_3am = today_3am - timedelta(days=1)
    posts.extend([
        {
            'id': 5,
            'title': 'React 18ì˜ ìƒˆë¡œìš´ ê¸°ëŠ¥ë“¤',
            'site': 'unpre',
            'category': 'í”„ë¡œê·¸ë˜ë°',
            'url': 'https://unpre.co.kr/react-18-features',
            'created_at': yesterday_3am.strftime('%Y-%m-%d %H:%M:%S'),
            'published': True
        },
        {
            'id': 6,
            'title': 'ë¶€ë™ì‚° íˆ¬ì ì „ëµ ê°€ì´ë“œ',
            'site': 'untab',
            'category': 'ë¶€ë™ì‚°',
            'url': 'https://untab.co.kr/real-estate-investment',
            'created_at': yesterday_3am.strftime('%Y-%m-%d %H:%M:%S'),
            'published': True
        },
        {
            'id': 7,
            'title': 'ğŸ”¥ MZì„¸ëŒ€ ì†Œë¹„ íŠ¸ë Œë“œ ë³€í™” ë¶„ì„',
            'site': 'tistory',
            'category': 'ì‚¬íšŒ/íŠ¸ë Œë“œ',
            'url': None,
            'created_at': yesterday_3am.strftime('%Y-%m-%d %H:%M:%S'),
            'published': False,
            'note': 'ìƒì„±ë¨ (ìˆ˜ë™ ë°œí–‰ í•„ìš”)'
        }
    ])
    
    today_posts = len([p for p in posts if p['created_at'].startswith(now.strftime('%Y-%m-%d'))])
    
    return {
        'posts': posts,
        'stats': {
            'total_posts': len(posts),
            'published': len(posts),
            'scheduled': 0,
            'today_posts': today_posts
        }
    }

@app.route('/')
def dashboard():
    """ë©”ì¸ ëŒ€ì‹œë³´ë“œ í˜ì´ì§€ (ìƒˆë¡œ ê°œí¸ë¨)"""
    response = make_response(render_template('dashboard.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/old')
def old_dashboard():
    """ê¸°ì¡´ ë³µì¡í•œ ëŒ€ì‹œë³´ë“œ (ë°±ì—…ìš©)"""
    response = make_response(render_template('dashboard_backup.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/api/recent_posts')
def get_recent_posts():
    """ìµœê·¼ í¬ìŠ¤íŠ¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        conn = get_db_connection()
        if conn:
            cursor = conn.cursor(cursor_factory=RealDictCursor)
            
            # ê° ì‚¬ì´íŠ¸ì—ì„œ ìµœê·¼ í¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            posts = []
            for site in ['unpre', 'untab', 'skewese']:
                cursor.execute("""
                    SELECT id, title, site, 
                           CASE WHEN categories IS NOT NULL AND jsonb_array_length(categories) > 0 
                                THEN categories->>0 
                                ELSE 'default' END as category,
                           created_at::text, 
                           CASE WHEN status = 'published' THEN true ELSE false END as published
                    FROM unble.content_files 
                    WHERE site = %s
                    ORDER BY created_at DESC 
                    LIMIT 5
                """, (site,))
                site_posts = cursor.fetchall()
                posts.extend(site_posts if site_posts else [])
            
            cursor.close()
            conn.close()
            
            # ì‹œê°„ìˆœ ì •ë ¬
            posts.sort(key=lambda x: x.get('created_at', ''), reverse=True)
            return jsonify(posts[:20])
        else:
            mock = get_mock_data()
            return jsonify(mock['posts'])
    except Exception as e:
        logger.error(f"ìµœê·¼ í¬ìŠ¤íŠ¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        mock = get_mock_data()
        return jsonify(mock['posts'])

@app.route('/api/posts')
def get_posts():
    """ë°œí–‰ëœ í¬ìŠ¤íŠ¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        conn = get_db_connection()
        if conn:
            cursor = conn.cursor(cursor_factory=RealDictCursor)
            site_filter = request.args.get('site', 'all')
            date_filter = request.args.get('date', '')
            
            posts = []
            # WordPress ì‚¬ì´íŠ¸ë“¤ + í‹°ìŠ¤í† ë¦¬ í¬í•¨
            all_sites = ['unpre', 'untab', 'skewese', 'tistory']
            
            for site in all_sites:
                if site_filter == 'all' or site_filter == site:
                    query = """
                        SELECT id, title, site, 
                               CASE WHEN categories IS NOT NULL AND jsonb_array_length(categories) > 0 
                                    THEN categories->>0 
                                    ELSE 'default' END as category,
                               url, 
                               created_at::text, 
                               CASE WHEN status = 'published' THEN true ELSE false END as published
                        FROM unble.content_files 
                        WHERE site = %s
                    """
                    params = [site]
                    
                    if date_filter:
                        query += " AND DATE(created_at) = %s"
                        params.append(date_filter)
                    
                    query += " ORDER BY created_at DESC LIMIT 10"
                    
                    cursor.execute(query, params)
                    site_posts = cursor.fetchall()
                    
                    # í‹°ìŠ¤í† ë¦¬ ì½˜í…ì¸ ëŠ” íŠ¹ë³„ í‘œì‹œ
                    if site == 'tistory' and site_posts:
                        for post in site_posts:
                            post['note'] = 'ìƒì„±ë¨ (ìˆ˜ë™ ë°œí–‰ í•„ìš”)'
                            post['published'] = False  # í‹°ìŠ¤í† ë¦¬ëŠ” í•­ìƒ ë°œí–‰ë˜ì§€ ì•Šì€ ìƒíƒœ
                    
                    posts.extend(site_posts if site_posts else [])
            
            cursor.close()
            conn.close()
            
            posts.sort(key=lambda x: x.get('created_at', ''), reverse=True)
            return jsonify({'status': 'success', 'posts': posts})
        else:
            mock = get_mock_data()
            return jsonify({'status': 'success', 'posts': mock['posts']})
            
    except Exception as e:
        logger.error(f"í¬ìŠ¤íŠ¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        mock = get_mock_data()
        return jsonify({'status': 'success', 'posts': mock['posts']})

@app.route('/api/stats')
def get_stats():
    """í†µê³„ ì •ë³´ ì¡°íšŒ"""
    try:
        conn = get_db_connection()
        if conn:
            cursor = conn.cursor(cursor_factory=RealDictCursor)
            
            # ì „ì²´ í†µê³„ ì¡°íšŒ
            cursor.execute("""
                SELECT 
                    COUNT(*) as total_posts,
                    COUNT(CASE WHEN status = 'published' THEN 1 END) as published,
                    COUNT(CASE WHEN status != 'published' THEN 1 END) as scheduled,
                    COUNT(CASE WHEN DATE(created_at) = CURRENT_DATE THEN 1 END) as today_posts
                FROM unble.content_files
            """)
            
            stats = cursor.fetchone()
            cursor.close()
            conn.close()
            
            if stats:
                stats['revenue'] = {
                    'total_views': 0,
                    'total_revenue': 0
                }
                return jsonify(stats)
            else:
                mock = get_mock_data()
                stats = mock['stats']
                stats['revenue'] = {
                    'total_views': 0,
                    'total_revenue': 0
                }
                return jsonify(stats)
        else:
            mock = get_mock_data()
            stats = mock['stats']
            stats['revenue'] = {
                'total_views': 0,
                'total_revenue': 0
            }
            return jsonify(stats)
        
    except Exception as e:
        logger.error(f"í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        mock = get_mock_data()
        stats = mock['stats']
        stats['revenue'] = {
            'total_views': 0,
            'total_revenue': 0
        }
        return jsonify(stats)

@app.route('/api/topic_stats')
def get_topic_stats():
    """ì£¼ì œ í’€ í†µê³„ ì¡°íšŒ"""
    return jsonify({
        'unpre': {
            'total': 50,
            'used': 25,
            'available': 25
        },
        'untab': {
            'total': 50,
            'used': 20,
            'available': 30
        },
        'skewese': {
            'total': 50,
            'used': 15,
            'available': 35
        }
    })

@app.route('/api/system_status')
def get_system_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
    conn = get_db_connection()
    db_status = 'online' if conn else 'offline'
    if conn:
        conn.close()
    
    return jsonify({
        'api': {
            'openai': {'status': 'online', 'response_time': 150},
            'claude': {'status': 'online', 'response_time': 120},
            'pexels': {'status': 'online', 'response_time': 200}
        },
        'sites': {
            'unpre': {'status': 'online', 'last_post': datetime.now(KST).strftime('%Y-%m-%d')},
            'untab': {'status': 'online', 'last_post': datetime.now(KST).strftime('%Y-%m-%d')},
            'skewese': {'status': 'online', 'last_post': datetime.now(KST).strftime('%Y-%m-%d')}
        },
        'database': {'status': db_status},
        'scheduler': {'status': 'online', 'next_run': '03:00 KST'}
    })

@app.route('/trending')
def trending_page():
    """íŠ¸ë Œë”© í˜ì´ì§€"""
    return render_template('trending.html')

@app.route('/api/trending')
@app.route('/api/trending/<period>')
def get_trending(period='current'):
    """íŠ¸ë Œë”© í† í”½ ì¡°íšŒ - ì£¼ê°„ ì—…ë°ì´íŠ¸"""
    try:
        from datetime import datetime, timedelta
        
        # í˜„ì¬ ì£¼ì°¨ ê³„ì‚°
        today = datetime.now().date()
        week_start = today - timedelta(days=today.weekday())
        week_number = week_start.isocalendar()[1]  # ISO ì£¼ì°¨
        
        # ì£¼ì°¨ë³„ ë™ì  íŠ¸ë Œë”© ìƒì„±
        trending_generator = WeeklyTrendingGenerator()
        
        if period == 'current':
            trends = trending_generator.generate_current_week_trends(week_start, week_number)
        elif period == 'next':
            next_week_start = week_start + timedelta(days=7)
            next_week_number = next_week_start.isocalendar()[1]
            trends = trending_generator.generate_next_week_trends(next_week_start, next_week_number)
        else:
            trends = trending_generator.generate_current_week_trends(week_start, week_number)
        
        return jsonify({
            'status': 'success',
            'success': True,
            'data': trends
        })
    except Exception as e:
        logger.error(f"íŠ¸ë Œë”© ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({
            'status': 'success',
            'success': True,
            'data': {
                'period': 'ê¸°ë³¸ íŠ¸ë Œë“œ',
                'cross_category_issues': [],
                'site_trends': {}
            }
        })

class WeeklyTrendingGenerator:
    """ì£¼ê°„ íŠ¸ë Œë”© í† í”½ ìƒì„±ê¸°"""
    
    def __init__(self):
        # 2025ë…„ ì£¼ìš” ì´ìŠˆë“¤ (ì£¼ì°¨ë³„ë¡œ ë‹¤ì–‘í•˜ê²Œ êµ¬ì„±)
        self.global_trending_pool = [
            # AI & ê¸°ìˆ 
            {'title': 'ChatGPT-5 ì¶œì‹œ ì„ë°•', 'category': 'AI/Tech', 'keywords': ['ChatGPT', 'AI', 'ì¸ê³µì§€ëŠ¥', 'OpenAI']},
            {'title': 'Apple Vision Pro 2ì„¸ëŒ€ ë°œí‘œ', 'category': 'Tech', 'keywords': ['Apple', 'VisionPro', 'ê°€ìƒí˜„ì‹¤', 'AR']},
            {'title': 'í…ŒìŠ¬ë¼ ììœ¨ì£¼í–‰ ì™„ì „ ìƒìš©í™”', 'category': 'Tech', 'keywords': ['Tesla', 'ììœ¨ì£¼í–‰', 'FSD', 'ì „ê¸°ì°¨']},
            {'title': 'êµ¬ê¸€ Gemini Ultra ì—…ê·¸ë ˆì´ë“œ', 'category': 'AI', 'keywords': ['Google', 'Gemini', 'AI', 'ë©€í‹°ëª¨ë‹¬']},
            {'title': 'NVIDIA RTX 5090 ì¶œì‹œ', 'category': 'Hardware', 'keywords': ['NVIDIA', 'RTX', 'GPU', 'ê²Œì´ë°']},
            {'title': 'ë©”íƒ€ Quest 4 ê³µê°œ', 'category': 'VR/AR', 'keywords': ['Meta', 'Quest', 'VR', 'ë©”íƒ€ë²„ìŠ¤']},
            {'title': 'ì‚¼ì„± ê°¤ëŸ­ì‹œ S25 AI ê¸°ëŠ¥ ê°•í™”', 'category': 'Mobile', 'keywords': ['Samsung', 'Galaxy', 'AI', 'ìŠ¤ë§ˆíŠ¸í°']},
            {'title': 'Microsoft Copilot Pro í™•ì¥', 'category': 'Productivity', 'keywords': ['Microsoft', 'Copilot', 'AI', 'ìƒì‚°ì„±']},
            
            # ê²½ì œ & ê¸ˆìœµ
            {'title': 'ë¹„íŠ¸ì½”ì¸ 10ë§Œ ë‹¬ëŸ¬ ëŒíŒŒ', 'category': 'Crypto', 'keywords': ['Bitcoin', 'ì•”í˜¸í™”í', '10ë§Œë‹¬ëŸ¬', 'íˆ¬ì']},
            {'title': 'í•œêµ­ ê¸°ì¤€ê¸ˆë¦¬ ì¶”ê°€ ì¸í•˜', 'category': 'Economy', 'keywords': ['ê¸°ì¤€ê¸ˆë¦¬', 'í•œêµ­ì€í–‰', 'ì¸í•˜', 'ê²½ì œì •ì±…']},
            {'title': 'ë¯¸êµ­ ì¸í”Œë ˆì´ì…˜ 2% ëª©í‘œ ë‹¬ì„±', 'category': 'Economy', 'keywords': ['ì¸í”Œë ˆì´ì…˜', 'ë¯¸êµ­', 'ì—°ì¤€', 'ê¸ˆë¦¬']},
            {'title': 'ì¼ë³¸ ì—”í™” ê¸‰ë“±', 'category': 'Finance', 'keywords': ['ì—”í™”', 'ì¼ë³¸', 'í™˜ìœ¨', 'íˆ¬ì']},
            {'title': 'TSMC 3ë‚˜ë…¸ ì¹© ì–‘ì‚° í™•ëŒ€', 'category': 'Semiconductor', 'keywords': ['TSMC', '3ë‚˜ë…¸', 'ë°˜ë„ì²´', 'ì¹©']},
            {'title': 'ì¤‘êµ­ ë¶€ë™ì‚° ì‹œì¥ íšŒë³µ ì‹ í˜¸', 'category': 'Real Estate', 'keywords': ['ì¤‘êµ­', 'ë¶€ë™ì‚°', 'íšŒë³µ', 'ì‹œì¥']},
            
            # ì •ì¹˜ & ì‚¬íšŒ
            {'title': '2025ë…„ ëŒ€ì„  í›„ë³´ ë“±ë¡ ì‹œì‘', 'category': 'Politics', 'keywords': ['ëŒ€ì„ ', 'í›„ë³´ë“±ë¡', '2025ë…„', 'ì •ì¹˜']},
            {'title': 'ê¸°í›„ë³€í™” ëŒ€ì‘ ê¸€ë¡œë²Œ í˜‘ì•½', 'category': 'Environment', 'keywords': ['ê¸°í›„ë³€í™”', 'í˜‘ì•½', 'íƒ„ì†Œì¤‘ë¦½', 'í™˜ê²½']},
            {'title': 'ìš°í¬ë¼ì´ë‚˜ ì „ìŸ íœ´ì „ í˜‘ìƒ', 'category': 'International', 'keywords': ['ìš°í¬ë¼ì´ë‚˜', 'ëŸ¬ì‹œì•„', 'íœ´ì „', 'í˜‘ìƒ']},
            {'title': 'ë¶í•œ í•µ í˜‘ìƒ ì¬ê°œ', 'category': 'International', 'keywords': ['ë¶í•œ', 'í•µí˜‘ìƒ', 'ì™¸êµ', 'í‰í™”']},
            {'title': 'EU ë””ì§€í„¸ ì„œë¹„ìŠ¤ë²• ì‹œí–‰', 'category': 'Policy', 'keywords': ['EU', 'ë””ì§€í„¸ë²•', 'ë¹…í…Œí¬', 'ê·œì œ']},
            
            # í—¬ìŠ¤ì¼€ì–´ & ë°”ì´ì˜¤
            {'title': 'mRNA ì•” ë°±ì‹  ì„ìƒ ì„±ê³µ', 'category': 'Healthcare', 'keywords': ['mRNA', 'ì•”ë°±ì‹ ', 'ì„ìƒ', 'ë°”ì´ì˜¤']},
            {'title': 'ì•Œì¸ í•˜ì´ë¨¸ ì‹ ì•½ FDA ìŠ¹ì¸', 'category': 'Medicine', 'keywords': ['ì•Œì¸ í•˜ì´ë¨¸', 'ì‹ ì•½', 'FDA', 'ì¹˜ë§¤']},
            {'title': 'ì¤„ê¸°ì„¸í¬ ì¹˜ë£Œë²• ìƒìš©í™”', 'category': 'Biotech', 'keywords': ['ì¤„ê¸°ì„¸í¬', 'ì¹˜ë£Œë²•', 'ì¬ìƒì˜í•™', 'ë°”ì´ì˜¤']},
            {'title': 'ë””ì§€í„¸ í—¬ìŠ¤ì¼€ì–´ ê¸‰ì„±ì¥', 'category': 'Digital Health', 'keywords': ['ë””ì§€í„¸í—¬ìŠ¤', 'ì›ê²©ì˜ë£Œ', 'í—¬ìŠ¤í…Œí¬', 'ì˜ë£Œ']},
            
            # ë¬¸í™” & ì—”í„°í…Œì¸ë¨¼íŠ¸
            {'title': 'K-ë“œë¼ë§ˆ ê¸€ë¡œë²Œ í¥í–‰ ì§€ì†', 'category': 'Entertainment', 'keywords': ['Kë“œë¼ë§ˆ', 'í•œë¥˜', 'ê¸€ë¡œë²Œ', 'ë„·í”Œë¦­ìŠ¤']},
            {'title': 'BTS ì¬ê²°í•© ì»´ë°± ë°œí‘œ', 'category': 'K-Pop', 'keywords': ['BTS', 'ì¬ê²°í•©', 'ì»´ë°±', 'K-Pop']},
            {'title': 'ì˜¬ë¦¼í”½ eìŠ¤í¬ì¸  ì •ì‹ ì¢…ëª© í™•ì •', 'category': 'Sports', 'keywords': ['ì˜¬ë¦¼í”½', 'eìŠ¤í¬ì¸ ', 'ê²Œì„', 'ìŠ¤í¬ì¸ ']},
            {'title': 'AI ìƒì„± ì˜í™” ì•„ì¹´ë°ë¯¸ í›„ë³´', 'category': 'Cinema', 'keywords': ['AIì˜í™”', 'ì•„ì¹´ë°ë¯¸', 'ì˜í™”ì œ', 'ì¸ê³µì§€ëŠ¥']},
            
            # ìŠ¤íƒ€íŠ¸ì—… & ë¹„ì¦ˆë‹ˆìŠ¤
            {'title': 'í•œêµ­ ìœ ë‹ˆì½˜ ê¸°ì—… 30ê°œ ëŒíŒŒ', 'category': 'Startup', 'keywords': ['ìœ ë‹ˆì½˜', 'ìŠ¤íƒ€íŠ¸ì—…', 'í•œêµ­', 'íˆ¬ì']},
            {'title': 'ë°°ë‹¬ ë¡œë´‡ ìƒìš©í™” í™•ì‚°', 'category': 'Robotics', 'keywords': ['ë°°ë‹¬ë¡œë´‡', 'ìë™í™”', 'ë¬¼ë¥˜', 'ë¡œë´‡']},
            {'title': 'ë©”íƒ€ë²„ìŠ¤ ì‡¼í•‘ëª° ê¸‰ì„±ì¥', 'category': 'E-commerce', 'keywords': ['ë©”íƒ€ë²„ìŠ¤', 'ì‡¼í•‘ëª°', 'VR', 'ì»¤ë¨¸ìŠ¤']},
            {'title': 'íƒ„ì†Œ í¬ì§‘ ê¸°ìˆ  ìƒìš©í™”', 'category': 'CleanTech', 'keywords': ['íƒ„ì†Œí¬ì§‘', 'ê¸°í›„ê¸°ìˆ ', 'íƒ„ì†Œì¤‘ë¦½', 'í™˜ê²½']},
        ]
        
        # ì‚¬ì´íŠ¸ë³„ ì „ë¬¸ íŠ¸ë Œë”©
        self.site_trends = {
            'unpre': [
                {'title': 'GitHub Copilot ë¬´ë£Œí™”', 'category': 'Developer Tools', 'keywords': ['GitHub', 'Copilot', 'ê°œë°œë„êµ¬', 'AI']},
                {'title': 'Python 3.13 ì„±ëŠ¥ í˜ì‹ ', 'category': 'Programming', 'keywords': ['Python', '3.13', 'ì„±ëŠ¥', 'í”„ë¡œê·¸ë˜ë°']},
                {'title': 'Rust ì›¹ í”„ë ˆì„ì›Œí¬ ê¸‰ë¶€ìƒ', 'category': 'Web Dev', 'keywords': ['Rust', 'ì›¹í”„ë ˆì„ì›Œí¬', 'ì„±ëŠ¥', 'ë°±ì—”ë“œ']},
                {'title': 'WebAssembly ë¸Œë¼ìš°ì € í‘œì¤€í™”', 'category': 'Web Tech', 'keywords': ['WebAssembly', 'ë¸Œë¼ìš°ì €', 'í‘œì¤€', 'ì„±ëŠ¥']},
                {'title': 'Kubernetes ë³´ì•ˆ ê°•í™”', 'category': 'DevOps', 'keywords': ['Kubernetes', 'ë³´ì•ˆ', 'DevOps', 'ì»¨í…Œì´ë„ˆ']},
                {'title': 'React 19 ì„œë²„ ì»´í¬ë„ŒíŠ¸', 'category': 'Frontend', 'keywords': ['React', '19', 'ì„œë²„ì»´í¬ë„ŒíŠ¸', 'í”„ë¡ íŠ¸ì—”ë“œ']},
                {'title': 'TypeScript 5.5 ìƒˆ ê¸°ëŠ¥', 'category': 'Language', 'keywords': ['TypeScript', '5.5', 'ìƒˆê¸°ëŠ¥', 'ê°œë°œ']},
                {'title': 'AI ì½”ë“œ ë¦¬ë·° ë„êµ¬ í™•ì‚°', 'category': 'AI Tools', 'keywords': ['AI', 'ì½”ë“œë¦¬ë·°', 'ìë™í™”', 'ê°œë°œë„êµ¬']},
                {'title': 'Edge Computing í”Œë«í¼ ì„±ì¥', 'category': 'Infrastructure', 'keywords': ['Edge', 'Computing', 'í”Œë«í¼', 'ì¸í”„ë¼']},
                {'title': 'NoSQL ë°ì´í„°ë² ì´ìŠ¤ ì§„í™”', 'category': 'Database', 'keywords': ['NoSQL', 'ë°ì´í„°ë² ì´ìŠ¤', 'ì§„í™”', 'DB']},
            ],
            'untab': [
                {'title': 'ì„œìš¸ ì•„íŒŒíŠ¸ ê°€ê²© ì•ˆì •í™”', 'category': 'Real Estate', 'keywords': ['ì„œìš¸', 'ì•„íŒŒíŠ¸', 'ê°€ê²©ì•ˆì •', 'ë¶€ë™ì‚°']},
                {'title': 'ë¶€ë™ì‚° PF ì‹œì¥ íšŒë³µ', 'category': 'Finance', 'keywords': ['ë¶€ë™ì‚°PF', 'ì‹œì¥íšŒë³µ', 'ê¸ˆìœµ', 'íˆ¬ì']},
                {'title': 'ì§€ë°© ë¶€ë™ì‚° íˆ¬ì ê¸‰ì¦', 'category': 'Investment', 'keywords': ['ì§€ë°©', 'ë¶€ë™ì‚°íˆ¬ì', 'ê¸‰ì¦', 'ìˆ˜ìµë¥ ']},
                {'title': 'ì¬ê°œë°œ ì‚¬ì—… í™œì„±í™”', 'category': 'Development', 'keywords': ['ì¬ê°œë°œ', 'ì‚¬ì—…', 'í™œì„±í™”', 'ë„ì‹œê°œë°œ']},
                {'title': 'ì „ì„¸ê¸ˆ ë°˜í™˜ë³´ì¦ ê°•í™”', 'category': 'Policy', 'keywords': ['ì „ì„¸ê¸ˆ', 'ë°˜í™˜ë³´ì¦', 'ê°•í™”', 'ì •ì±…']},
                {'title': 'ë¶€ë™ì‚° ì„¸ì œ ê°œí¸ì•ˆ', 'category': 'Tax', 'keywords': ['ë¶€ë™ì‚°ì„¸ì œ', 'ê°œí¸', 'ì„¸ê¸ˆ', 'ì •ì±…']},
                {'title': 'ìŠ¤ë§ˆíŠ¸í™ˆ ê¸°ìˆ  í™•ì‚°', 'category': 'Smart Home', 'keywords': ['ìŠ¤ë§ˆíŠ¸í™ˆ', 'ê¸°ìˆ í™•ì‚°', 'IoT', 'ì£¼ê±°']},
                {'title': 'ì¹œí™˜ê²½ ê±´ì¶• ì¸ì¦ í™•ëŒ€', 'category': 'Green Building', 'keywords': ['ì¹œí™˜ê²½ê±´ì¶•', 'ì¸ì¦', 'ê·¸ë¦°ë¹Œë”©', 'ê±´ì„¤']},
                {'title': 'ë¶€ë™ì‚° ê²½ë§¤ ì‹œì¥ ë™í–¥', 'category': 'Auction', 'keywords': ['ë¶€ë™ì‚°ê²½ë§¤', 'ì‹œì¥ë™í–¥', 'íˆ¬ì', 'ê²½ë§¤']},
                {'title': 'ì„ëŒ€ì£¼íƒ ê³µê¸‰ í™•ëŒ€', 'category': 'Rental', 'keywords': ['ì„ëŒ€ì£¼íƒ', 'ê³µê¸‰í™•ëŒ€', 'ì£¼ê±°', 'ì •ì±…']},
            ],
            'skewese': [
                {'title': 'ì¡°ì„ ì™•ì¡°ì‹¤ë¡ ë””ì§€í„¸í™”', 'category': 'Digital Heritage', 'keywords': ['ì¡°ì„ ì™•ì¡°ì‹¤ë¡', 'ë””ì§€í„¸í™”', 'ë¬¸í™”ì¬', 'ì—­ì‚¬']},
                {'title': 'í•œêµ­ì‚¬ êµìœ¡ê³¼ì • ê°œí¸', 'category': 'Education', 'keywords': ['í•œêµ­ì‚¬', 'êµìœ¡ê³¼ì •', 'ê°œí¸', 'ì—­ì‚¬êµìœ¡']},
                {'title': 'ë¬¸í™”ì¬ ë³µì› ê¸°ìˆ  í˜ì‹ ', 'category': 'Cultural Heritage', 'keywords': ['ë¬¸í™”ì¬ë³µì›', 'ê¸°ìˆ í˜ì‹ ', 'ì „í†µ', 'ë³´ì¡´']},
                {'title': 'K-ì»¬ì²˜ ì—­ì‚¬ ì½˜í…ì¸  ì¸ê¸°', 'category': 'Culture', 'keywords': ['Kì»¬ì²˜', 'ì—­ì‚¬ì½˜í…ì¸ ', 'í•œë¥˜', 'ë¬¸í™”']},
                {'title': 'ì „í†µ ê³µì˜ˆ í˜„ëŒ€ì  ì¬í•´ì„', 'category': 'Traditional Craft', 'keywords': ['ì „í†µê³µì˜ˆ', 'í˜„ëŒ€ì¬í•´ì„', 'ê³µì˜ˆ', 'ë¬¸í™”']},
                {'title': 'ë°•ë¬¼ê´€ ë””ì§€í„¸ ì „ì‹œ í™•ì‚°', 'category': 'Museum', 'keywords': ['ë°•ë¬¼ê´€', 'ë””ì§€í„¸ì „ì‹œ', 'ê°€ìƒí˜„ì‹¤', 'ë¬¸í™”']},
                {'title': 'ê³ ê³ í•™ AI ë°œêµ´ ê¸°ìˆ ', 'category': 'Archaeology', 'keywords': ['ê³ ê³ í•™', 'AIë°œêµ´', 'ê¸°ìˆ ', 'ì—­ì‚¬']},
                {'title': 'í•œë³µ ê¸€ë¡œë²Œ íŒ¨ì…˜ íŠ¸ë Œë“œ', 'category': 'Fashion', 'keywords': ['í•œë³µ', 'ê¸€ë¡œë²Œ', 'íŒ¨ì…˜íŠ¸ë Œë“œ', 'ì „í†µ']},
                {'title': 'ì—­ì‚¬ ë‹¤íë©˜í„°ë¦¬ ë¥´ë„¤ìƒìŠ¤', 'category': 'Documentary', 'keywords': ['ì—­ì‚¬ë‹¤í', 'ë¥´ë„¤ìƒìŠ¤', 'ë°©ì†¡', 'ì½˜í…ì¸ ']},
                {'title': 'ì „í†µìŒì‹ ë ˆì‹œí”¼ ë³µì›', 'category': 'Food Culture', 'keywords': ['ì „í†µìŒì‹', 'ë ˆì‹œí”¼ë³µì›', 'ìŒì‹ë¬¸í™”', 'ì „í†µ']},
            ]
        }
    
    def generate_current_week_trends(self, week_start, week_number):
        """ì´ë²ˆì£¼ íŠ¸ë Œë”© ìƒì„±"""
        import random
        
        # ì£¼ì°¨ì— ë”°ë¼ ì‹œë“œ ì„¤ì • (ì¼ê´€ì„± ìˆëŠ” ëœë¤)
        random.seed(week_number * 100)
        
        # ê¸€ë¡œë²Œ ì´ìŠˆ 8-10ê°œ ì„ íƒ
        global_issues = random.sample(self.global_trending_pool, 9)
        
        # íŠ¸ë Œë“œ íƒ€ì…ê³¼ ìš°ì„ ìˆœìœ„ ëœë¤ í• ë‹¹
        trend_types = ['hot', 'rising', 'predicted', 'viral']
        for i, issue in enumerate(global_issues):
            issue['trend_type'] = random.choice(trend_types)
            issue['priority'] = 10 - i  # ìš°ì„ ìˆœìœ„ ì„¤ì •
            issue['description'] = f"{issue['title']}ì´(ê°€) ì´ë²ˆì£¼ ì£¼ìš” ì´ìŠˆë¡œ ë– ì˜¤ë¥´ê³  ìˆìŠµë‹ˆë‹¤."
        
        # ì‚¬ì´íŠ¸ë³„ íŠ¸ë Œë“œ 7-8ê°œì”©
        site_trends = {}
        for site, trends in self.site_trends.items():
            selected = random.sample(trends, 7)
            for i, trend in enumerate(selected):
                trend['trend_type'] = random.choice(trend_types)
                trend['priority'] = 8 - i
                trend['description'] = f"{trend['title']}ì´(ê°€) {site} ë¶„ì•¼ì—ì„œ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤."
            site_trends[site] = selected
        
        return {
            'period': f'ì´ë²ˆì£¼ íŠ¸ë Œë“œ ({week_start})',
            'week_start': week_start.strftime('%Y-%m-%d'),
            'week_number': week_number,
            'cross_category_issues': global_issues,
            'site_trends': site_trends,
            'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
    
    def generate_next_week_trends(self, week_start, week_number):
        """ë‹¤ìŒì£¼ ì˜ˆì¸¡ íŠ¸ë Œë”© ìƒì„±"""
        import random
        
        # ë‹¤ìŒì£¼ìš© ì‹œë“œ
        random.seed(week_number * 200)
        
        # ì˜ˆì¸¡ëœ ì´ìŠˆë“¤
        predicted_issues = random.sample(self.global_trending_pool, 8)
        
        for i, issue in enumerate(predicted_issues):
            issue['trend_type'] = 'predicted'
            issue['priority'] = 9 - i
            issue['description'] = f"{issue['title']}ì´(ê°€) ë‹¤ìŒì£¼ ì£¼ìš” ì´ìŠˆê°€ ë  ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ë©ë‹ˆë‹¤."
        
        # ì‚¬ì´íŠ¸ë³„ ì˜ˆì¸¡ íŠ¸ë Œë“œ
        site_trends = {}
        for site, trends in self.site_trends.items():
            selected = random.sample(trends, 7)
            for i, trend in enumerate(selected):
                trend['trend_type'] = 'predicted'
                trend['priority'] = 7 - i
                trend['description'] = f"{trend['title']}ì´(ê°€) ë‹¤ìŒì£¼ {site} ë¶„ì•¼ í•«ì´ìŠˆê°€ ë  ì „ë§ì…ë‹ˆë‹¤."
            site_trends[site] = selected
        
        return {
            'period': f'ë‹¤ìŒì£¼ ì˜ˆì¸¡ íŠ¸ë Œë“œ ({week_start})',
            'week_start': week_start.strftime('%Y-%m-%d'),
            'week_number': week_number,
            'cross_category_issues': predicted_issues,
            'site_trends': site_trends,
            'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }

@app.route('/api/chart_data')
def get_chart_data():
    """ì°¨íŠ¸ ë°ì´í„° ì¡°íšŒ"""
    now = datetime.now(KST)
    daily_data = []
    site_data = {
        'unpre': 0,
        'untab': 0,
        'skewese': 0
    }
    
    try:
        conn = get_db_connection()
        if conn:
            cursor = conn.cursor(cursor_factory=RealDictCursor)
            
            for i in range(7):
                date = (now - timedelta(days=i)).strftime('%Y-%m-%d')
                
                cursor.execute("""
                    SELECT site, COUNT(*) as count
                    FROM unble.content_files
                    WHERE DATE(created_at) = %s
                    GROUP BY site
                """, (date,))
                
                day_results = cursor.fetchall()
                day_count = sum(r['count'] for r in day_results) if day_results else 0
                daily_data.append({'date': date, 'count': day_count})
                
                for r in day_results:
                    site_data[r['site']] = site_data.get(r['site'], 0) + r['count']
            
            cursor.close()
            conn.close()
        else:
            # ëª©ì—… ë°ì´í„°
            for i in range(7):
                date = (now - timedelta(days=i)).strftime('%Y-%m-%d')
                daily_data.append({'date': date, 'count': 3 - i % 2})
            site_data = {'unpre': 7, 'untab': 5, 'skewese': 3}
    except Exception as e:
        logger.error(f"ì°¨íŠ¸ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
        # ëª©ì—… ë°ì´í„°
        for i in range(7):
            date = (now - timedelta(days=i)).strftime('%Y-%m-%d')
            daily_data.append({'date': date, 'count': 3 - i % 2})
        site_data = {'unpre': 7, 'untab': 5, 'skewese': 3}
    
    return jsonify({
        'daily': daily_data,
        'bySite': site_data
    })

@app.route('/api/scheduler/status')
def get_scheduler_status():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ í™•ì¸ API"""
    try:
        global scheduler
        if scheduler and scheduler.running:
            jobs = scheduler.get_jobs()
            job_info = []
            for job in jobs:
                job_info.append({
                    'id': job.id,
                    'name': job.name,
                    'next_run': job.next_run_time.strftime('%Y-%m-%d %H:%M:%S KST') if job.next_run_time else None,
                    'trigger': str(job.trigger)
                })
            
            return jsonify({
                'status': 'running',
                'jobs': job_info,
                'message': 'ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.'
            })
        else:
            return jsonify({
                'status': 'stopped',
                'jobs': [],
                'message': 'ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì‹¤í–‰ë˜ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.'
            })
    except Exception as e:
        logger.error(f"ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {e}")
        return jsonify({
            'status': 'error',
            'error': str(e)
        }), 500

@app.route('/api/scheduler/trigger', methods=['POST'])
def trigger_scheduler():
    """ìˆ˜ë™ìœ¼ë¡œ ìë™ ë°œí–‰ ì‘ì—… ì‹¤í–‰"""
    try:
        add_system_log('INFO', 'ìˆ˜ë™ ìë™ ë°œí–‰ ì‘ì—… íŠ¸ë¦¬ê±°', 'API')
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
        thread = threading.Thread(target=auto_publish_task)
        thread.start()
        
        return jsonify({
            'success': True,
            'message': 'ìë™ ë°œí–‰ ì‘ì—…ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.'
        })
    except Exception as e:
        logger.error(f"ìˆ˜ë™ íŠ¸ë¦¬ê±° ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/schedule/create', methods=['POST'])
def create_weekly_schedule():
    """ì£¼ê°„ ìŠ¤ì¼€ì¤„ ìˆ˜ë™ ìƒì„±"""
    try:
        from src.utils.schedule_manager import schedule_manager
        from datetime import datetime, timedelta
        
        data = request.get_json()
        week_start = data.get('week_start')
        
        if week_start:
            start_date = datetime.strptime(week_start, '%Y-%m-%d').date()
        else:
            # ë‹¤ìŒ ì£¼ ì›”ìš”ì¼ ê¸°ë³¸ê°’
            today = datetime.now().date()
            days_ahead = 7 - today.weekday()  
            start_date = today + timedelta(days=days_ahead)
        
        add_system_log('INFO', f'{start_date} ì£¼ê°„ ìŠ¤ì¼€ì¤„ ìƒì„± ì‹œì‘', 'SCHEDULE')
        
        success = schedule_manager.create_weekly_schedule(start_date)
        
        if success:
            add_system_log('SUCCESS', f'{start_date} ì£¼ê°„ ìŠ¤ì¼€ì¤„ ìƒì„± ì™„ë£Œ', 'SCHEDULE')
            return jsonify({
                'success': True,
                'message': f'{start_date} ì£¼ê°„ ìŠ¤ì¼€ì¤„ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.',
                'week_start': start_date.strftime('%Y-%m-%d')
            })
        else:
            return jsonify({
                'success': False,
                'message': 'ìŠ¤ì¼€ì¤„ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'
            }), 500
            
    except Exception as e:
        logger.error(f"ì£¼ê°„ ìŠ¤ì¼€ì¤„ ìƒì„± ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/schedule/save', methods=['POST'])
def save_schedule():
    """í´ë¼ì´ì–¸íŠ¸ì—ì„œ ìƒì„±í•œ ìŠ¤ì¼€ì¤„ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    try:
        data = request.get_json()
        schedule_data = data.get('schedule_data')
        
        if not schedule_data:
            return jsonify({'success': False, 'error': 'ìŠ¤ì¼€ì¤„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'}), 400
        
        # ìŠ¤ì¼€ì¤„ ë§¤ë‹ˆì €ë¥¼ ì‚¬ìš©í•´ DBì— ì €ì¥
        sm = get_schedule_manager()
        success = sm.save_client_schedule(schedule_data)
        
        if success:
            add_system_log('SUCCESS', f'í´ë¼ì´ì–¸íŠ¸ ìŠ¤ì¼€ì¤„ DB ì €ì¥ ì™„ë£Œ: {schedule_data.get("week_start")}', 'SCHEDULE')
            return jsonify({'success': True, 'message': 'ìŠ¤ì¼€ì¤„ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.'})
        else:
            return jsonify({'success': False, 'error': 'ìŠ¤ì¼€ì¤„ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'}), 500
            
    except Exception as e:
        add_system_log('ERROR', f'ìŠ¤ì¼€ì¤„ ì €ì¥ API ì˜¤ë¥˜: {e}', 'SCHEDULE')
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/logs')
def get_logs():
    """ì‹¤ì‹œê°„ ë¡œê·¸ ì¡°íšŒ - ìë™ë°œí–‰ ëª¨ë‹ˆí„°ë§"""
    try:
        # ì¸ë©”ëª¨ë¦¬ ë¡œê·¸ ê°€ì ¸ì˜¤ê¸°
        logs = get_recent_logs()
        
        # ë¡œê·¸ íŒŒì¼ì—ì„œë„ ê°€ì ¸ì˜¤ê¸° (ë°±ì—…)
        import os
        log_file = 'blog_automation.log'
        if os.path.exists(log_file):
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()[-50:]  # ìµœê·¼ 50ì¤„
                    for line in lines:
                        if line.strip():
                            parts = line.strip().split(' - ', 3)
                            if len(parts) >= 3:
                                log_time = parts[0]
                                log_level = parts[1].lower()
                                log_message = ' - '.join(parts[2:])
                                
                                # ì‹œê°„ í¬ë§· ë³€í™˜
                                try:
                                    parsed_time = datetime.strptime(log_time, '%Y-%m-%d %H:%M:%S,%f')
                                    formatted_time = parsed_time.strftime('%H:%M:%S')
                                except:
                                    formatted_time = log_time
                                
                                logs.append({
                                    'time': formatted_time,
                                    'level': log_level,
                                    'message': log_message
                                })
            except Exception as e:
                print(f"ë¡œê·¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        
        # ì‹œê°„ìˆœ ì •ë ¬ (ìµœì‹ ìˆœ)
        logs.sort(key=lambda x: x['time'], reverse=True)
        
        return jsonify(logs[:100])  # ìµœê·¼ 100ê°œë§Œ
        
    except Exception as e:
        logger.error(f"ë¡œê·¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify([
            {
                'time': datetime.now(KST).strftime('%H:%M:%S'),
                'level': 'info',
                'message': 'ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™ ì¤‘'
            }
        ])


@app.route('/api/schedule/status')
def get_schedule_status():
    """ìë™ë°œí–‰ ìŠ¤ì¼€ì¤„ ìƒíƒœ í™•ì¸"""
    try:
        from config.sites_config import PUBLISHING_SCHEDULE
        import pytz
        
        now = datetime.now(pytz.timezone('Asia/Seoul'))
        today = now.date()
        current_time = now.strftime('%H:%M')
        
        schedule_info = {}
        
        for site, config in PUBLISHING_SCHEDULE.items():
            schedule_time = config['time']
            days = config['days']
            
            # ì˜¤ëŠ˜ ë°œí–‰ ì˜ˆì •ì¸ì§€ í™•ì¸
            today_weekday = ['mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun'][today.weekday()]
            is_today = today_weekday in days
            
            # ë°œí–‰ ì‹œê°„ê¹Œì§€ ë‚¨ì€ ì‹œê°„ ê³„ì‚°
            if is_today:
                schedule_datetime = datetime.combine(today, datetime.strptime(schedule_time, '%H:%M').time())
                schedule_datetime = pytz.timezone('Asia/Seoul').localize(schedule_datetime)
                
                if now < schedule_datetime:
                    time_until = schedule_datetime - now
                    hours, remainder = divmod(int(time_until.total_seconds()), 3600)
                    minutes, _ = divmod(remainder, 60)
                    status = f'{hours}ì‹œê°„ {minutes}ë¶„ í›„ ë°œí–‰ ì˜ˆì •'
                else:
                    status = 'ì˜¤ëŠ˜ ë°œí–‰ ì™„ë£Œ ë˜ëŠ” ì§„í–‰ ì¤‘'
            else:
                # ë‹¤ìŒ ë°œí–‰ì¼ ì°¾ê¸°
                next_publish_days = []
                for i in range(1, 8):
                    future_date = today + timedelta(days=i)
                    future_weekday = ['mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun'][future_date.weekday()]
                    if future_weekday in days:
                        next_publish_days.append(future_date.strftime('%m/%d'))
                        break
                
                status = f'ë‹¤ìŒ ë°œí–‰: {next_publish_days[0] if next_publish_days else "ì—†ìŒ"} {schedule_time}'
            
            schedule_info[site] = {
                'schedule_time': schedule_time,
                'is_today': is_today,
                'status': status,
                'days': days
            }
        
        add_system_log('INFO', f'ìŠ¤ì¼€ì¤„ ìƒíƒœ ì¡°íšŒ - í˜„ì¬ ì‹œê°„: {current_time}', 'SCHEDULE_CHECK')
        
        return jsonify({
            'current_time': current_time,
            'current_date': today.strftime('%Y-%m-%d'),
            'schedule_info': schedule_info,
            'auto_publish_enabled': True
        })
        
    except Exception as e:
        logger.error(f"ìŠ¤ì¼€ì¤„ ìƒíƒœ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        add_system_log('ERROR', f'ìŠ¤ì¼€ì¤„ ìƒíƒœ ì¡°íšŒ ì˜¤ë¥˜: {e}', 'SCHEDULE_CHECK')
        return jsonify({'error': str(e)}), 500

@app.route('/api/schedule/weekly')
def get_weekly_schedule():
    """ì£¼ê°„ ìŠ¤ì¼€ì¤„ ì¡°íšŒ - ê°„ë‹¨í•˜ê³  í™•ì‹¤í•œ ë™ì  ìƒì„±"""
    try:
        # ìš”ì²­ëœ ì‹œì‘ ë‚ ì§œ íŒŒì‹±
        week_start = request.args.get('week_start') or request.args.get('start_date')
        if week_start:
            start_date = datetime.strptime(week_start, '%Y-%m-%d').date()
            add_system_log('DEBUG', f'API ìš”ì²­ ë‚ ì§œ: {start_date}', 'SCHEDULE')
        else:
            # í˜„ì¬ ì£¼ ì¼ìš”ì¼ ê³„ì‚°
            today = datetime.now(KST).date()
            days_since_sunday = (today.weekday() + 1) % 7  
            start_date = today - timedelta(days=days_since_sunday)
            add_system_log('DEBUG', f'ê³„ì‚°ëœ ë‚ ì§œ: {start_date} (ì˜¤ëŠ˜: {today})', 'SCHEDULE')
        
        # DBì—ì„œ ì‹¤ì œ ìŠ¤ì¼€ì¤„ ë°ì´í„° ì¡°íšŒ
        from src.utils.schedule_manager import schedule_manager
        add_system_log('INFO', f'DB ìŠ¤ì¼€ì¤„ ì¡°íšŒ ì‹œì‘: {start_date}', 'SCHEDULE')
        schedule_data = schedule_manager.get_weekly_schedule(start_date)
        add_system_log('INFO', f'DB ìŠ¤ì¼€ì¤„ ì¡°íšŒ ì™„ë£Œ: week_start={schedule_data.get("week_start")}', 'SCHEDULE')
        
        # ëŒ€ì‹œë³´ë“œìš© ê°„ë‹¨í•œ í¬ë§· ë³€í™˜
        formatted_schedule = {}
        
        if schedule_data and 'schedule' in schedule_data:
            for day_idx, day_info in schedule_data['schedule'].items():
                if not isinstance(day_info, dict) or 'date' not in day_info:
                    continue
                    
                date_str = day_info['date'].strftime('%Y-%m-%d')
                formatted_schedule[date_str] = {}
                
                sites_data = day_info.get('sites', {})
                current_date = datetime.now(KST).date()
                target_date = day_info['date']
                
                # DBì—ì„œ ê°€ì ¸ì˜¨ ì‚¬ì´íŠ¸ ë°ì´í„° ê·¸ëŒ€ë¡œ ì‚¬ìš©
                for site, site_info in sites_data.items():
                    if site_info and isinstance(site_info, dict):
                        topic = site_info.get('topic', f'{site} ì£¼ì œ ì—†ìŒ')
                        
                        # í‹°ìŠ¤í† ë¦¬ì˜ ê²½ìš° ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë§ˆì»¤ í™•ì¸
                        if site == 'tistory':
                            # ì˜¤ëŠ˜ ì´í›„ ë‚ ì§œë©´ì„œ ìµœê·¼ ì—…ë°ì´íŠ¸ëœ ê²½ìš° íŠ¸ë Œë“œ ë§ˆí¬
                            updated_at = site_info.get('updated_at')
                            if target_date >= current_date and updated_at:
                                # ìµœê·¼ 24ì‹œê°„ ë‚´ ì—…ë°ì´íŠ¸ëœ ê²½ìš°
                                from datetime import datetime, timezone
                                now = datetime.now(timezone.utc)
                                if isinstance(updated_at, str):
                                    updated_time = datetime.fromisoformat(updated_at.replace('Z', '+00:00'))
                                else:
                                    updated_time = updated_at
                                
                                if (now - updated_time).total_seconds() < 86400:  # 24ì‹œê°„
                                    topic = f"ğŸ”¥ {topic}"
                        
                        # ìƒíƒœ ê²°ì •
                        if target_date < current_date:
                            status = 'published' if site != 'tistory' else 'generated'
                        elif target_date == current_date:
                            current_time = datetime.now(KST).time()
                            if current_time >= datetime.strptime('03:00', '%H:%M').time():
                                status = 'published' if site != 'tistory' else 'generated'
                            else:
                                status = 'scheduled'
                        else:
                            status = 'scheduled'
                        
                        formatted_schedule[date_str][site] = {
                            'topic': topic,
                            'status': status,
                            'time': '03:00'
                        }
                        
                        if site == 'tistory':
                            formatted_schedule[date_str][site]['note'] = 'ì½˜í…ì¸  ìƒì„±ë§Œ (ìˆ˜ë™ ë°œí–‰)'
                            # ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë§ˆì»¤ ì¶”ê°€
                            if target_date >= current_date:  # ì˜¤ëŠ˜ ì´í›„ ë‚ ì§œ
                                formatted_schedule[date_str][site]['trending'] = True
                                formatted_schedule[date_str][site]['topic'] = f"ğŸ”¥ {topic}"
                else:
                    formatted_schedule[date_str][site] = {
                        'time': '03:00',
                        'topic': topic,
                        'status': status
                    }
        
        return jsonify(formatted_schedule)
        
    except Exception as e:
        logger.error(f"Weekly schedule error: {e}")
        return jsonify({}), 500

@app.route('/api/schedule/test')
def test_dynamic_schedule():
    """ë™ì  ìŠ¤ì¼€ì¤„ í…ŒìŠ¤íŠ¸ API"""
    start_date = request.args.get('start_date', '2025-08-24')
    start_date_obj = datetime.strptime(start_date, '%Y-%m-%d').date()
    
    # ì§ì ‘ í…ŒìŠ¤íŠ¸
    import random
    from datetime import timedelta
    
    week_seed = start_date_obj.toordinal()
    random.seed(week_seed)
    
    unpre_topics = ["JWT í† í° ê¸°ë°˜ ì‹œíë¦¬í‹° êµ¬í˜„", "DDD(ë„ë©”ì¸ ì£¼ë„ ì„¤ê³„) ì‹¤ì „ ì ìš©", "C++ ìµœì‹  í”„ë¡œê·¸ë˜ë° ê¸°ë²•"]
    
    topic_index = (week_seed + 0 * 10 + hash('unpre')) % len(unpre_topics)
    selected_topic = unpre_topics[topic_index]
    
    return jsonify({
        'request_date': start_date,
        'week_seed': week_seed,
        'topic_index': topic_index,
        'selected_topic': selected_topic,
        'all_topics': unpre_topics
    })

@app.route('/api/generate_wordpress', methods=['POST'])
def generate_wordpress():
    """WordPress ì½˜í…ì¸  ìƒì„±"""
    try:
        data = request.json
        site = data.get('site', 'unpre')
        topic = data.get('topic', 'í”„ë¡œê·¸ë˜ë°')
        
        database = get_database()
        
        try:
            if database.is_connected:
                # Claude APIë¡œ ì‹¤ì œ ì½˜í…ì¸  ìƒì„±
                logger.info(f"Content generator ìƒíƒœ: {content_generator is not None}")
                
                # ContentGeneratorê°€ Noneì´ë©´ ë‹¤ì‹œ ì´ˆê¸°í™” ì‹œë„
                current_generator = content_generator
                if current_generator is None:
                    try:
                        logger.info("ContentGenerator ì¬ì´ˆê¸°í™” ì‹œë„...")
                        from src.generators.content_generator import ContentGenerator
                        current_generator = ContentGenerator()
                        logger.info("âœ… ContentGenerator ì¬ì´ˆê¸°í™” ì„±ê³µ")
                    except Exception as e:
                        logger.error(f"âŒ ContentGenerator ì¬ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                        current_generator = None
                
                if current_generator:
                    logger.info(f"Claude APIë¡œ {topic} ì½˜í…ì¸  ìƒì„± ì‹œì‘...")
                    
                    # ì‚¬ì´íŠ¸ë³„ ì„¤ì •
                    site_configs = {
                        'unpre': {
                            'name': 'unpre',
                            'target_audience': 'ê°œë°œì ë° IT ì „ë¬¸ê°€',
                            'content_style': 'ì‹¤ìš©ì ì´ê³  ê¸°ìˆ ì ì¸',
                            'keywords_focus': data.get('keywords', [topic])
                        },
                        'untab': {
                            'name': 'untab',
                            'target_audience': 'ë¶€ë™ì‚° íˆ¬ìì ë° ì¼ë°˜ì¸',
                            'content_style': 'ì‹¤ìš©ì ì´ê³  ìƒì„¸í•œ ê°€ì´ë“œ',
                            'keywords_focus': data.get('keywords', [topic])
                        },
                        'skewese': {
                            'name': 'skewese',
                            'target_audience': 'ì—­ì‚¬ì™€ ë¬¸í™”ì— ê´€ì‹¬ìˆëŠ” ì¼ë°˜ì¸',
                            'content_style': 'í¥ë¯¸ë¡­ê³  êµìœ¡ì ì¸',
                            'keywords_focus': data.get('keywords', [topic])
                        }
                    }
                    
                    site_config = site_configs.get(site, site_configs['unpre'])
                    
                    # AI ì½˜í…ì¸  ìƒì„± (ì‹¤ì œ Claude API í˜¸ì¶œ)
                    generated_content = current_generator.generate_content(
                        site_config=site_config,
                        topic=topic,
                        category=data.get('category', 'í”„ë¡œê·¸ë˜ë°'),
                        content_length='medium'
                    )
                    
                    # ì´ë¯¸ì§€ ìƒì„± (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
                    images = []
                    try:
                        logger.info(f"ì´ë¯¸ì§€ ìƒì„± ì‹œì‘...")
                        from src.utils.safe_image_generator import SafeImageGenerator
                        img_gen = SafeImageGenerator()
                        
                        # ëŒ€í‘œì´ë¯¸ì§€ ìƒì„±
                        featured_image_path = img_gen.generate_featured_image(title=generated_content['title'])
                        
                        if featured_image_path and os.path.exists(featured_image_path):
                            images = [{
                                'url': featured_image_path,
                                'type': 'thumbnail',  # ëŒ€í‘œì´ë¯¸ì§€ë¡œ ì„¤ì •
                                'alt': f"{generated_content['title']} ëŒ€í‘œì´ë¯¸ì§€"
                            }]
                        else:
                            images = []
                        logger.info(f"ì´ë¯¸ì§€ {len(images)}ê°œ ìƒì„± ì™„ë£Œ")
                    except Exception as img_e:
                        logger.warning(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ë§Œ ì§„í–‰: {img_e}")
                        images = []
                    
                    # WordPress Exporter ì‚¬ìš©í•˜ì—¬ HTML ìƒì„±
                    from src.generators.wordpress_content_exporter import WordPressContentExporter
                    exporter = WordPressContentExporter()
                    file_path = exporter.export_content(site, generated_content, images)
                    
                    title = generated_content['title']
                    logger.info(f"Claude API ì½˜í…ì¸  ìƒì„± ì™„ë£Œ: {title[:50]}...")
                    logger.info(f"ìƒì„±ëœ íŒŒì¼ ê²½ë¡œ: {file_path}")
                    
                    # íŒŒì¼ ê²½ë¡œ í™•ì¸
                    if not file_path or not os.path.exists(file_path):
                        raise Exception(f"íŒŒì¼ ìƒì„± ì‹¤íŒ¨ ë˜ëŠ” ê²½ë¡œ ì—†ìŒ: {file_path}")
                    
                else:
                    # Fallback ì½˜í…ì¸ 
                    logger.warning("ContentGeneratorê°€ Noneì…ë‹ˆë‹¤. ê¸°ë³¸ ì½˜í…ì¸ ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                    title = f'{topic} ì™„ì „ ê°€ì´ë“œ'
                    content_dict = {
                        'title': title,
                        'introduction': f'{topic}ì— ëŒ€í•œ ìƒì„¸í•œ ë¶„ì„ì…ë‹ˆë‹¤.',
                        'sections': [
                            {'heading': 'ì†Œê°œ', 'content': f'{topic}ì— ëŒ€í•œ ê¸°ë³¸ ê°œë…ì„ ì„¤ëª…í•©ë‹ˆë‹¤.'},
                            {'heading': 'ì£¼ìš” ë‚´ìš©', 'content': f'{topic}ì˜ í•µì‹¬ ë‚´ìš©ì„ ë‹¤ë£¹ë‹ˆë‹¤.'},
                        ],
                        'conclusion': f'{topic}ì— ëŒ€í•œ ì¢…í•©ì ì¸ ì´í•´ë¥¼ ë•ìŠµë‹ˆë‹¤.',
                        'meta_description': f'{title} - ìƒì„¸í•œ ê°€ì´ë“œì™€ íŒ',
                        'tags': data.get('keywords', [topic]),
                        'categories': [data.get('category', 'ê¸°ë³¸')]
                    }
                    
                    from src.generators.wordpress_content_exporter import WordPressContentExporter
                    exporter = WordPressContentExporter()
                    file_path = exporter.export_content(site, content_dict, [])
                    logger.warning(f"Claude API ë¯¸ì‚¬ìš©, ê¸°ë³¸ ì½˜í…ì¸  ìƒì„±: {title}")
                
                # JSON ë©”íƒ€ë°ì´í„° íŒŒì¼ ìƒì„± (ëª©ë¡ í‘œì‹œìš©)
                import time
                import json
                json_file_path = file_path.replace('.html', '.json')
                metadata_content = {
                    'title': title,
                    'id': int(time.time()),
                    'site': site,
                    'status': 'draft',
                    'tags': data.get('keywords', [topic]),
                    'categories': [data.get('category', 'ê¸°ë³¸')],
                    'created_at': time.strftime('%Y-%m-%d %H:%M:%S'),
                    'file_path': file_path
                }
                
                with open(json_file_path, 'w', encoding='utf-8') as f:
                    json.dump(metadata_content, f, ensure_ascii=False, indent=2)
                
                # ì½˜í…ì¸ ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì§ì ‘ ì €ì¥
                file_id = database.add_content_file(
                    site=site,
                    title=title,
                    file_path=file_path,  # ìƒì„±ëœ íŒŒì¼ ê²½ë¡œ ì €ì¥
                    file_type='wordpress',
                    metadata={
                        'categories': [data.get('category', 'ê¸°ë³¸')],
                        'tags': data.get('keywords', [topic]),
                        'word_count': 1000,  # ëŒ€ëµì ì¸ ê°’
                        'reading_time': 5,  # ëŒ€ëµ 5ë¶„
                        'file_size': os.path.getsize(file_path) if os.path.exists(file_path) else 1000,
                        'status': 'draft'  # ìƒˆë¡œ ìƒì„±ëœ ì½˜í…ì¸ ëŠ” draftë¡œ ì„¤ì •
                    }
                )
                
                # ìƒì„± ì„±ê³µ ì‘ë‹µ
                return jsonify({
                    'success': True,
                    'message': f'{site} ì‚¬ì´íŠ¸ì— {topic} ì£¼ì œë¡œ ì½˜í…ì¸ ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.',
                    'title': title,
                    'id': file_id,
                    'file_path': file_path,  # íŒŒì¼ ê²½ë¡œ ì¶”ê°€
                    'post': {
                        'id': file_id,
                        'title': title,
                        'site': site,
                        'status': 'draft'
                    }
                })
        except Exception as db_error:
            logger.error(f"DB ì €ì¥ ì‹¤íŒ¨, ëª©ì—… ëª¨ë“œë¡œ ì „í™˜: {db_error}")
        
        # DB ì—°ê²° ì‹¤íŒ¨ì‹œ ëª©ì—… ì‘ë‹µ
        import time
        current_time = int(time.time())
        
        new_file = {
            'title': f'{topic} ì™„ì „ ê°€ì´ë“œ',
            'id': current_time,
            'site': site,
            'status': 'draft',
            'created_at': time.strftime('%Y-%m-%d %H:%M:%S'),
        }
        
        return jsonify({
            'success': True,
            'message': f'{site} ì‚¬ì´íŠ¸ì— {topic} ì£¼ì œë¡œ ì½˜í…ì¸ ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. (ëª©ì—… ëª¨ë“œ)',
            'title': new_file['title'],
            'id': new_file['id'],
            'post': new_file
        })
        
    except Exception as e:
        logger.error(f"WordPress ì½˜í…ì¸  ìƒì„± ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/generate_tistory', methods=['POST'])
def generate_tistory():
    """Tistory ì½˜í…ì¸  ìƒì„±"""
    try:
        data = request.json
        topic = data.get('topic', 'í”„ë¡œê·¸ë˜ë°')
        
        database = get_database()
        
        try:
            if database.is_connected:
                # Claude APIë¡œ ì‹¤ì œ ì½˜í…ì¸  ìƒì„±
                logger.info(f"Tistory Content generator ìƒíƒœ: {content_generator is not None}")
                
                # ContentGeneratorê°€ Noneì´ë©´ ë‹¤ì‹œ ì´ˆê¸°í™” ì‹œë„
                current_generator = content_generator
                if current_generator is None:
                    try:
                        logger.info("Tistory ContentGenerator ì¬ì´ˆê¸°í™” ì‹œë„...")
                        from src.generators.content_generator import ContentGenerator
                        current_generator = ContentGenerator()
                        logger.info("âœ… Tistory ContentGenerator ì¬ì´ˆê¸°í™” ì„±ê³µ")
                    except Exception as e:
                        logger.error(f"âŒ Tistory ContentGenerator ì¬ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                        current_generator = None
                
                if current_generator:
                    logger.info(f"Claude APIë¡œ Tistory {topic} ì½˜í…ì¸  ìƒì„± ì‹œì‘...")
                    
                    # ì‚¬ì´íŠ¸ ì„¤ì •
                    site_config = {
                        'name': 'untab',
                        'target_audience': 'ì¼ë°˜ ëŒ€ì¤‘ ë° ê´€ì‹¬ìˆëŠ” ë…ì',
                        'content_style': 'ì´í•´í•˜ê¸° ì‰¬ìš°ê³  ì‹¤ìš©ì ì¸',
                        'keywords_focus': data.get('keywords', [topic])
                    }
                    
                    # AI ì½˜í…ì¸  ìƒì„± (ì‹¤ì œ Claude API í˜¸ì¶œ)
                    generated_content = current_generator.generate_content(
                        site_config=site_config,
                        topic=topic,
                        category=data.get('category', 'ì¼ë°˜'),
                        content_length='medium'
                    )
                    
                    # HTML í˜•íƒœë¡œ ë³€í™˜ - Tistory ê¹”ë”í•œ ë””ìì¸
                    content_html = _create_beautiful_html_template(generated_content, site_config)
                    
                    content = content_html
                    title = generated_content.get('title', f'{topic} ë¶„ì„')
                    logger.info(f"Claude API Tistory ì½˜í…ì¸  ìƒì„± ì™„ë£Œ: {title[:50]}...")
                    
                else:
                    # Fallback ì½˜í…ì¸ 
                    logger.warning("Tistory ContentGeneratorê°€ Noneì…ë‹ˆë‹¤. ê¸°ë³¸ ì½˜í…ì¸ ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                    content = f'<h1>{topic} ì‹¬í™” ë¶„ì„</h1>\n<p>{topic}ì— ëŒ€í•œ ìƒì„¸í•œ ë¶„ì„ì…ë‹ˆë‹¤.</p>'
                    title = f'{topic} ì‹¬í™” ë¶„ì„'
                    logger.warning(f"Claude API ë¯¸ì‚¬ìš©, Tistory ê¸°ë³¸ ì½˜í…ì¸  ìƒì„±: {title}")
                
                # Tistory íŒŒì¼ë¡œ ì €ì¥ (ëª©ë¡ í‘œì‹œë¥¼ ìœ„í•´)
                import time
                import json
                from datetime import datetime
                
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).rstrip()
                safe_title = safe_title.replace(' ', ' ')[:50]  # ì œëª© ê¸¸ì´ ì œí•œ
                
                html_filename = f"{timestamp}_{safe_title}.html"
                html_file_path = os.path.join('data', 'tistory_posts', html_filename)
                
                # ë””ë ‰í† ë¦¬ ìƒì„±
                os.makedirs(os.path.dirname(html_file_path), exist_ok=True)
                
                # HTML íŒŒì¼ ì €ì¥
                with open(html_file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                # _meta.json íŒŒì¼ ìƒì„± (ëª©ë¡ í‘œì‹œìš©)
                meta_filename = html_filename.replace('.html', '_meta.json')
                meta_file_path = os.path.join('data', 'tistory_posts', meta_filename)
                
                metadata_content = {
                    'title': title,
                    'tags': data.get('keywords', [topic]),
                    'category': data.get('category', 'ê¸°ë³¸'),
                    'created_at': datetime.now().isoformat(),
                    'file_path': html_file_path.replace('\\', '/')
                }
                
                with open(meta_file_path, 'w', encoding='utf-8') as f:
                    json.dump(metadata_content, f, ensure_ascii=False, indent=2)
                
                # ì½˜í…ì¸ ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì—ë„ ì €ì¥
                file_id = database.add_content_file(
                    site='tistory',
                    title=title,
                    file_path=html_file_path,  # íŒŒì¼ ê²½ë¡œ ì €ì¥
                    file_type='tistory',
                    metadata={
                        'categories': [data.get('category', 'ê¸°ë³¸')],
                        'tags': data.get('keywords', [topic]),
                        'word_count': len(content.split()),
                        'reading_time': len(content.split()) // 200 + 1,
                        'file_size': len(content.encode('utf-8')),
                        'status': 'draft'  # ìƒˆë¡œ ìƒì„±ëœ ì½˜í…ì¸ ëŠ” draftë¡œ ì„¤ì •
                    }
                )
                
                # ìƒì„± ì„±ê³µ ì‘ë‹µ
                return jsonify({
                    'success': True,
                    'message': f'Tistoryì— {topic} ì£¼ì œë¡œ ì½˜í…ì¸ ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.',
                    'title': title,
                    'id': file_id,
                    'post': {
                        'id': file_id,
                        'title': title,
                        'status': 'draft'
                    }
                })
        except Exception as db_error:
            logger.error(f"DB ì €ì¥ ì‹¤íŒ¨, ëª©ì—… ëª¨ë“œë¡œ ì „í™˜: {db_error}")
        
        # DB ì—°ê²° ì‹¤íŒ¨ì‹œ ëª©ì—… ì‘ë‹µ
        import time
        current_time = int(time.time())
        
        new_file = {
            'title': f'{topic} ì‹¬í™” ë¶„ì„',
            'id': current_time,
            'status': 'draft',
            'created_at': time.strftime('%Y-%m-%d %H:%M:%S'),
        }
        
        return jsonify({
            'success': True,
            'message': f'Tistoryì— {topic} ì£¼ì œë¡œ ì½˜í…ì¸ ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. (ëª©ì—… ëª¨ë“œ)',
            'title': new_file['title'],
            'id': new_file['id'],
            'post': new_file
        })
        
    except Exception as e:
        logger.error(f"Tistory ì½˜í…ì¸  ìƒì„± ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/preview_content/<int:file_id>')
def preview_content(file_id):
    """ì½˜í…ì¸  ë¯¸ë¦¬ë³´ê¸°"""
    try:
        database = get_database()
        
        if database.is_connected:
            # DBì—ì„œ íŒŒì¼ ì •ë³´ ì¡°íšŒ
            files = database.get_content_files(limit=1000)  # ì „ì²´ ì¡°íšŒ
            target_file = None
            
            for f in files:
                if f.get('id') == file_id:
                    target_file = f
                    break
            
            if target_file:
                # content í•„ë“œì—ì„œ ì§ì ‘ ì½˜í…ì¸  ì½ê¸° (ìˆ˜ë™ë°œí–‰ í›„ ì €ì¥ëœ HTML)
                content = target_file.get('content')
                
                # contentê°€ ì—†ìœ¼ë©´ file_pathì—ì„œ ì½ê¸° ì‹œë„ (ê¸°ì¡´ ë°©ì‹)
                if not content:
                    file_path = target_file.get('file_path')
                    if file_path and os.path.exists(file_path):
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                content = f.read()
                            logger.info(f"íŒŒì¼ì—ì„œ ì½˜í…ì¸  ì½ê¸° ì„±ê³µ: {file_path}")
                        except Exception as e:
                            logger.warning(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
                            content = None
                
                # ì½˜í…ì¸ ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì½˜í…ì¸  ìƒì„±
                if not content:
                    content = f"""<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{target_file.get('title', 'ì œëª© ì—†ìŒ')}</title>
    <style>
        body {{ font-family: 'Segoe UI', sans-serif; margin: 40px; line-height: 1.6; }}
        h1 {{ color: #333; border-bottom: 3px solid #007bff; padding-bottom: 10px; }}
        .meta {{ color: #666; margin-bottom: 20px; }}
        .content {{ margin-top: 30px; }}
    </style>
</head>
<body>
    <h1>{target_file.get('title', 'ì œëª© ì—†ìŒ')}</h1>
    <div class="meta">
        <p><strong>ì‚¬ì´íŠ¸:</strong> {target_file.get('site', 'N/A')}</p>
        <p><strong>ìƒì„±ì¼:</strong> {target_file.get('created_at', 'N/A')}</p>
        <p><strong>ìƒíƒœ:</strong> {target_file.get('status', 'draft')}</p>
        <p><strong>ì¹´í…Œê³ ë¦¬:</strong> {target_file.get('categories', ['ê¸°ë³¸'])[0] if target_file.get('categories') else 'ê¸°ë³¸'}</p>
    </div>
    <div class="content">
        <p>ì½˜í…ì¸ ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.</p>
    </div>
</body>
</html>"""
                
                # HTML ì‘ë‹µ ë°˜í™˜
                response = make_response(content)
                response.headers['Content-Type'] = 'text/html; charset=utf-8'
                return response
        
        # íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
        return "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", 404
        
    except Exception as e:
        logger.error(f"ë¯¸ë¦¬ë³´ê¸° ì˜¤ë¥˜: {e}")
        return f"ë¯¸ë¦¬ë³´ê¸° ì˜¤ë¥˜: {str(e)}", 500

@app.route('/api/download_content/<int:file_id>')
def download_content(file_id):
    """ì½˜í…ì¸  íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    try:
        database = get_database()
        
        if database.is_connected:
            # DBì—ì„œ íŒŒì¼ ì •ë³´ ì¡°íšŒ
            files = database.get_content_files(limit=1000)  # ì „ì²´ ì¡°íšŒ
            target_file = None
            
            for f in files:
                if f.get('id') == file_id:
                    target_file = f
                    break
            
            if target_file:
                # content í•„ë“œì—ì„œ ì§ì ‘ ì½˜í…ì¸  ì½ê¸° (ìˆ˜ë™ë°œí–‰ í›„ ì €ì¥ëœ HTML)
                content = target_file.get('content')
                
                # contentê°€ ì—†ìœ¼ë©´ file_pathì—ì„œ ì½ê¸° ì‹œë„ (ê¸°ì¡´ ë°©ì‹)
                if not content:
                    file_path = target_file.get('file_path')
                    if file_path and os.path.exists(file_path):
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                content = f.read()
                            logger.info(f"íŒŒì¼ì—ì„œ ì½˜í…ì¸  ì½ê¸° ì„±ê³µ: {file_path}")
                        except Exception as e:
                            logger.warning(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
                            content = None
                
                # ì½˜í…ì¸ ê°€ ì—†ê±°ë‚˜ ì½ê¸° ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ì½˜í…ì¸  ìƒì„±
                if not content:
                    content = f"""<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{target_file.get('title', 'ì œëª© ì—†ìŒ')}</title>
    <style>
        body {{ font-family: 'Segoe UI', sans-serif; margin: 40px; line-height: 1.6; }}
        h1 {{ color: #333; border-bottom: 3px solid #007bff; padding-bottom: 10px; }}
        .meta {{ color: #666; margin-bottom: 20px; }}
        .content {{ margin-top: 30px; }}
    </style>
</head>
<body>
    <h1>{target_file.get('title', 'ì œëª© ì—†ìŒ')}</h1>
    <div class="meta">
        <p><strong>ì‚¬ì´íŠ¸:</strong> {target_file.get('site', 'N/A')}</p>
        <p><strong>ìƒì„±ì¼:</strong> {target_file.get('created_at', 'N/A')}</p>
        <p><strong>ìƒíƒœ:</strong> {target_file.get('status', 'draft')}</p>
        <p><strong>ì¹´í…Œê³ ë¦¬:</strong> {target_file.get('categories', ['ê¸°ë³¸'])[0] if target_file.get('categories') else 'ê¸°ë³¸'}</p>
    </div>
    <div class="content">
        <p>ì´ ì½˜í…ì¸ ëŠ” ìë™ ìƒì„±ëœ {target_file.get('file_type', 'unknown')} ì½˜í…ì¸ ì…ë‹ˆë‹¤.</p>
        <p>ì½˜í…ì¸  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ ë‚´ìš©ì„ í‘œì‹œí•©ë‹ˆë‹¤.</p>
    </div>
</body>
</html>"""
                
                # íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‘ë‹µ
                response = make_response(content)
                # í•œê¸€ íŒŒì¼ëª… ì²˜ë¦¬ - ì œëª©ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                safe_title = target_file.get('title', 'content')[:80]  # ê¸¸ì´ ì œí•œ
                import re
                # íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ìë§Œ ì œê±°, í•œê¸€ì€ ìœ ì§€
                safe_title = re.sub(r'[<>:"/\\|?*]', '', safe_title).strip()
                filename = f"{safe_title}.html"
                
                # ê°„ë‹¨í•˜ê³  ì•ˆì „í•œ íŒŒì¼ëª… í—¤ë” ì„¤ì •
                import urllib.parse
                # ì•ˆì „í•œ ê¸°ë³¸ íŒŒì¼ëª… ì‚¬ìš©
                safe_filename = f"blog_content_{file_id}.html"
                
                response.headers['Content-Disposition'] = f'attachment; filename="{safe_filename}"'
                response.headers['Content-Type'] = 'text/html; charset=utf-8'
                logger.info(f"ë‹¤ìš´ë¡œë“œ ì œê³µ: {filename}")
                return response
        
        # íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
        return jsonify({
            'success': False,
            'error': 'íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
        }), 404
        
    except Exception as e:
        logger.error(f"ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/debug/content_generator')
def debug_content_generator():
    """ContentGenerator ìƒíƒœ ë””ë²„ê¹…"""
    try:
        import os
        api_key = os.getenv("ANTHROPIC_API_KEY")
        return jsonify({
            'content_generator_initialized': content_generator is not None,
            'api_key_exists': api_key is not None,
            'api_key_length': len(api_key) if api_key else 0,
            'api_key_prefix': api_key[:20] if api_key else None,
            'error_info': str(getattr(content_generator, '_init_error', 'No error'))
        })
    except Exception as e:
        return jsonify({
            'error': str(e),
            'content_generator_initialized': False
        })

@app.route('/api/publish_post', methods=['POST'])
def publish_post():
    """í¬ìŠ¤íŠ¸ ì‹¤ì œ ì‚¬ì´íŠ¸ì— ë°œí–‰"""
    try:
        data = request.json
        post_id = data.get('post_id')
        site = data.get('site', 'wordpress')  # ì‚¬ì´íŠ¸ íƒ€ì… (wordpress, tistory)
        
        if not post_id:
            return jsonify({
                'success': False,
                'error': 'í¬ìŠ¤íŠ¸ IDê°€ í•„ìš”í•©ë‹ˆë‹¤.'
            }), 400
        
        database = get_database()
        
        if database.is_connected:
            try:
                # í¬ìŠ¤íŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                files = database.get_content_files(limit=1000)
                target_file = None
                
                for f in files:
                    if f.get('id') == int(post_id):
                        target_file = f
                        break
                
                if not target_file:
                    return jsonify({
                        'success': False,
                        'error': 'í¬ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
                    }), 404
                
                # ë””ë²„ê·¸: íŒŒì¼ êµ¬ì¡° í™•ì¸
                logger.info(f"target_file keys: {list(target_file.keys())}")
                logger.info(f"target_file content preview: {str(target_file.get('content', ''))[:200]}...")
                
                # íŒŒì¼ì—ì„œ ì‹¤ì œ ì½˜í…ì¸  ì½ê¸°
                content_data = None
                raw_content = ''
                
                # file_pathì—ì„œ ì‹¤ì œ ì½˜í…ì¸  ì½ê¸° (file_pathê°€ HTML ì½˜í…ì¸  ìì²´ì¼ ìˆ˜ë„ ìˆìŒ)
                file_path = target_file.get('file_path', '')
                if file_path:
                    # file_pathê°€ HTMLì¸ì§€ ì‹¤ì œ íŒŒì¼ ê²½ë¡œì¸ì§€ í™•ì¸
                    if file_path.strip().startswith('<!DOCTYPE html>') or file_path.strip().startswith('<html'):
                        # file_path ìì²´ê°€ HTML ì½˜í…ì¸ ì¸ ê²½ìš°
                        logger.info("file_path í•„ë“œì— HTML ì½˜í…ì¸ ê°€ ì§ì ‘ ì €ì¥ë˜ì–´ ìˆìŒ")
                        raw_content = file_path
                        logger.info(f"HTML ì½˜í…ì¸  ê¸¸ì´: {len(raw_content)}")
                    else:
                        # ì‹¤ì œ íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
                        try:
                            logger.info(f"íŒŒì¼ ê²½ë¡œì—ì„œ ì½˜í…ì¸  ì½ê¸°: {file_path}")
                            with open(file_path, 'r', encoding='utf-8') as f:
                                raw_content = f.read()
                            logger.info(f"íŒŒì¼ ì½ê¸° ì„±ê³µ, ê¸¸ì´: {len(raw_content)}")
                        except Exception as e:
                            logger.error(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
                            raw_content = target_file.get('content', '')
                else:
                    logger.info("file_path ì—†ìŒ, content í•„ë“œ ì‚¬ìš©")
                    raw_content = target_file.get('content', '')
                
                try:
                    # JSON êµ¬ì¡°ì¸ì§€ ë¨¼ì € í™•ì¸
                    import json
                    content_data = json.loads(raw_content)
                    logger.info("JSON êµ¬ì¡° ì½˜í…ì¸  íŒŒì‹± ì„±ê³µ")
                except:
                    # JSONì´ ì•„ë‹Œ ê²½ìš° HTML ì½˜í…ì¸ ë¡œ ì²˜ë¦¬
                    logger.info("HTML ì½˜í…ì¸ ë¡œ ì²˜ë¦¬")
                    
                    # ì¸ì½”ë”© ë¬¸ì œ í•´ê²°: ë¬¸ì œê°€ ë˜ëŠ” íŠ¹ìˆ˜ ë¬¸ìë“¤ì„ ì•ˆì „í•œ ë¬¸ìë¡œ ëŒ€ì²´
                    safe_content = raw_content
                    
                    # 1. ì´ëª¨ì§€ì™€ íŠ¹ìˆ˜ ë¬¸ì ëŒ€ì²´
                    char_replacements = {
                        '\U0001f4c5': '[ë‚ ì§œ]',  # ğŸ“… ìº˜ë¦°ë”
                        '\U0001f516': '[íƒœê·¸]',  # ğŸ”– ë¶ë§ˆí¬
                        '\U0001f4a1': '[íŒ]',   # ğŸ’¡ ì „êµ¬
                        '\U0001f3f7\ufe0f': '[íƒœê·¸]',  # ğŸ·ï¸ ë¼ë²¨
                        '\U0001f4bb': '[ì»´í“¨í„°]',  # ğŸ’» ë…¸íŠ¸ë¶
                        '\U0001f680': '[ë¡œì¼“]',  # ğŸš€ ë¡œì¼“
                        '\U0001f525': '[ë¶ˆ]',   # ğŸ”¥ ë¶ˆ
                        '\U0001f3af': '[íƒ€ê²Ÿ]',  # ğŸ¯ ë‹¤íŠ¸
                        '\U0001f4d1': '[ë¶ë§ˆí¬]', # ğŸ“‘ ë¶ë§ˆí¬ íƒ­
                        '\u2022': 'â€¢',  # bullet point
                        '\u2023': 'â€£',  # triangular bullet
                        '\u2043': 'âƒ',  # hyphen bullet
                        '\u25aa': 'â–ª',  # black small square
                        '\u25ab': 'â–«',  # white small square
                        '\u25b6': 'â–¶',  # black right-pointing triangle
                        '\u25c0': 'â—€',  # black left-pointing triangle
                    }
                    
                    for char, replacement in char_replacements.items():
                        if char in safe_content:
                            safe_content = safe_content.replace(char, replacement)
                            logger.info(f"íŠ¹ìˆ˜ ë¬¸ì ëŒ€ì²´: {repr(char)} -> {replacement}")
                    
                    # 2. í¬ê´„ì  í•´ê²°: CP949ì—ì„œ ì¸ì½”ë”©í•  ìˆ˜ ì—†ëŠ” ëª¨ë“  ë¬¸ìë¥¼ ì•ˆì „í•œ ë¬¸ìë¡œ ë³€í™˜
                    try:
                        # CP949ë¡œ ì¸ì½”ë”© ì‹œë„í•˜ì—¬ ë¬¸ì œ ìˆëŠ” ë¬¸ì ì°¾ê¸°
                        safe_content.encode('cp949')
                    except UnicodeEncodeError:
                        logger.info("CP949 ì¸ì½”ë”© ë¶ˆê°€ëŠ¥í•œ ë¬¸ì ë°œê²¬, ì•ˆì „í•œ ë¬¸ìë¡œ ë³€í™˜")
                        # ê° ë¬¸ìë¥¼ ì²´í¬í•˜ì—¬ ì¸ì½”ë”© ê°€ëŠ¥í•œ ë¬¸ìë§Œ ìœ ì§€
                        safe_chars = []
                        for char in safe_content:
                            try:
                                char.encode('cp949')
                                safe_chars.append(char)
                            except UnicodeEncodeError:
                                # ì¸ì½”ë”© ë¶ˆê°€ëŠ¥í•œ ë¬¸ìëŠ” ë¬¼ìŒí‘œë¡œ ëŒ€ì²´
                                safe_chars.append('?')
                                logger.info(f"ë¬¸ì œ ë¬¸ì ë°œê²¬: {repr(char)} -> ?")
                        safe_content = ''.join(safe_chars)
                    
                    content_data = {
                        'title': target_file.get('title', 'ì œëª© ì—†ìŒ'),
                        'content': safe_content,  # ì´ëª¨ì§€ê°€ ì œê±°ëœ ì•ˆì „í•œ ì½˜í…ì¸ 
                        'meta_description': f"{target_file.get('title', '')} ê´€ë ¨ ë‚´ìš©ì…ë‹ˆë‹¤.",
                        'tags': target_file.get('tags', ['ë¸”ë¡œê·¸', 'ìë™í™”']),
                        'categories': [target_file.get('category', 'ê¸°íƒ€')]
                    }
                
                logger.info(f"ì½˜í…ì¸  ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: title={content_data.get('title')}, content_length={len(content_data.get('content', ''))}")
                
                # ì‚¬ì´íŠ¸ë³„ ì‹¤ì œ ë°œí–‰
                success = False
                published_url = None
                error_message = None
                
                if site.lower() in ['wordpress', 'unpre', 'untab', 'skewese']:
                    # WordPress ë°œí–‰
                    try:
                        from src.publishers.wordpress_publisher import WordPressPublisher
                        
                        # ì‚¬ì´íŠ¸ í‚¤ ë§¤í•‘
                        site_key_map = {
                            'wordpress': 'unpre',
                            'unpre': 'unpre', 
                            'untab': 'untab',
                            'skewese': 'skewese'
                        }
                        site_key = site_key_map.get(site.lower(), 'unpre')
                        
                        publisher = WordPressPublisher(site_key)
                        success, result = publisher.publish_post(content_data)
                        
                        if success:
                            published_url = result
                            logger.info(f"WordPress ë°œí–‰ ì„±ê³µ: {published_url}")
                        else:
                            error_message = f"WordPress ë°œí–‰ ì‹¤íŒ¨: {result}"
                            logger.error(error_message)
                            
                    except Exception as e:
                        error_message = f"WordPress ë°œí–‰ ì˜¤ë¥˜: {str(e)}"
                        logger.error(error_message)
                        
                elif site.lower() == 'tistory':
                    # Tistory ë°œí–‰
                    try:
                        from src.publishers.tistory_publisher import TistoryPublisher
                        
                        publisher = TistoryPublisher()
                        success, result = publisher.publish_post(content_data)
                        
                        if success:
                            published_url = result
                            logger.info(f"Tistory ë°œí–‰ ì„±ê³µ: {published_url}")
                        else:
                            error_message = f"Tistory ë°œí–‰ ì‹¤íŒ¨: {result}"
                            logger.error(error_message)
                            
                    except Exception as e:
                        error_message = f"Tistory ë°œí–‰ ì˜¤ë¥˜: {str(e)}"
                        logger.error(error_message)
                
                # ë°œí–‰ ì„±ê³µì‹œ ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ì—…ë°ì´íŠ¸
                if success:
                    conn = get_db_connection()
                    if conn:
                        cursor = conn.cursor()
                        cursor.execute(
                            "UPDATE unble.content_files SET status = 'published' WHERE id = %s",
                            (post_id,)
                        )
                        conn.commit()
                        cursor.close()
                        conn.close()
                    
                    return jsonify({
                        'success': True,
                        'message': f'í¬ìŠ¤íŠ¸ "{target_file.get("title", "")}"ê°€ {site} ì‚¬ì´íŠ¸ì— ì„±ê³µì ìœ¼ë¡œ ë°œí–‰ë˜ì—ˆìŠµë‹ˆë‹¤.',
                        'post_id': post_id,
                        'url': published_url
                    })
                else:
                    return jsonify({
                        'success': False,
                        'error': error_message or 'ë°œí–‰ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
                    }), 500
                    
            except Exception as e:
                logger.error(f"í¬ìŠ¤íŠ¸ ë°œí–‰ ì‹¤íŒ¨: {e}")
                return jsonify({
                    'success': False,
                    'error': str(e)
                }), 500
        
        # DB ì—°ê²° ì‹¤íŒ¨ì‹œ ëª©ì—… ì‘ë‹µ
        return jsonify({
            'success': True,
            'message': f'í¬ìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ë°œí–‰ë˜ì—ˆìŠµë‹ˆë‹¤. (ëª©ì—… ëª¨ë“œ)',
            'post_id': post_id
        })
        
    except Exception as e:
        logger.error(f"í¬ìŠ¤íŠ¸ ë°œí–‰ ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/publish_to_wordpress', methods=['POST'])
def publish_to_wordpress():
    """WordPressì— ì½˜í…ì¸  ë°œí–‰"""
    try:
        data = request.json
        file_path = data.get('file_path')
        site = data.get('site', 'unpre')
        
        if not file_path:
            return jsonify({'success': False, 'error': 'íŒŒì¼ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤'}), 400
        
        # HTML íŒŒì¼ ì½ê¸°
        if not os.path.exists(file_path):
            return jsonify({'success': False, 'error': f'íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}'}), 404
        
        with open(file_path, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        # HTML íŒŒì‹±
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # ì œëª© ì¶”ì¶œ
        title_tag = soup.find('h1') or soup.find('title')
        title = title_tag.text.strip() if title_tag else 'ì œëª© ì—†ìŒ'
        
        # ì œëª©ì—ì„œ ë„ë©”ì¸ëª… ì œê±° (ì˜ˆ: "ì œëª© - unpre.co.kr" -> "ì œëª©")
        site_domains = [' - unpre.co.kr', ' - untab.co.kr', ' - skewese.com', ' - tistory.com']
        for domain in site_domains:
            if title.endswith(domain):
                title = title[:-len(domain)].strip()
                break
        
        # ë©”íƒ€ ì„¤ëª… ì¶”ì¶œ
        meta_desc = soup.find('meta', {'name': 'description'})
        meta_description = meta_desc['content'] if meta_desc else ''
        
        # íƒœê·¸ ì¶”ì¶œ
        tags_div = soup.find('div', class_='tags')
        tags = []
        if tags_div:
            tag_spans = tags_div.find_all('span', class_='tag')
            tags = [span.text.replace('#', '').strip() for span in tag_spans]
        
        # ì´ë¯¸ì§€ ìƒì„± (ë°œí–‰ ì‹œì ì— ìƒì„±, ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
        images = []
        try:
            logger.info(f"WordPress ë°œí–‰ìš© ì´ë¯¸ì§€ ìƒì„± ì‹œì‘...")
            from src.utils.safe_image_generator import SafeImageGenerator
            img_gen = SafeImageGenerator()
            
            # ëŒ€í‘œì´ë¯¸ì§€ ìƒì„±
            featured_image_path = img_gen.generate_featured_image(title=title)
            
            if featured_image_path and os.path.exists(featured_image_path):
                images = [{
                    'url': featured_image_path,
                    'type': 'thumbnail',  # WordPress publisherê°€ ì¸ì‹í•  ìˆ˜ ìˆë„ë¡
                    'alt': f"{title} ëŒ€í‘œì´ë¯¸ì§€"
                }]
            else:
                images = []
            logger.info(f"ë°œí–‰ìš© ì´ë¯¸ì§€ {len(images)}ê°œ ìƒì„± ì™„ë£Œ")
        except Exception as img_e:
            logger.warning(f"ë°œí–‰ìš© ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ë§Œ ë°œí–‰: {img_e}")
            images = []
        
        # WordPress Publisher ì‚¬ìš©
        from src.publishers.wordpress_publisher import WordPressPublisher
        publisher = WordPressPublisher(site)
        
        content_data = {
            'title': title,
            'content': html_content,
            'meta_description': meta_description,
            'tags': tags,
            'categories': [data.get('category', 'ê¸°ë³¸')]
        }
        
        success, result = publisher.publish_post(content_data, images)
        
        if success:
            logger.info(f"WordPress ë°œí–‰ ì„±ê³µ: {result}")
            
            # ë°œí–‰ ì„±ê³µ ì‹œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            try:
                database = get_database()
                if database.is_connected:
                    file_id = database.add_content_file(
                        site=site,
                        title=title,
                        file_path=file_path,
                        file_type='wordpress',
                        metadata={
                            'categories': [data.get('category', 'ê¸°ë³¸')],
                            'tags': tags,
                            'word_count': len(title.split()) * 50,  # ì¶”ì •ê°’
                            'reading_time': 5,
                            'file_size': os.path.getsize(file_path) if os.path.exists(file_path) else 1000,
                            'published_url': result,
                            'status': 'published'
                        }
                    )
                    
                    # ìƒíƒœë¥¼ publishedë¡œ ì—…ë°ì´íŠ¸
                    database.update_content_file_status(file_id, 'published')
                    logger.info(f"ë°ì´í„°ë² ì´ìŠ¤ì— ë°œí–‰ëœ ì½˜í…ì¸  ì €ì¥ ì™„ë£Œ: {file_id}")
                    
            except Exception as db_e:
                logger.warning(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨í•˜ì§€ë§Œ ë°œí–‰ì€ ì„±ê³µ: {db_e}")
            
            return jsonify({
                'success': True,
                'message': f'{site} ì‚¬ì´íŠ¸ì— ì„±ê³µì ìœ¼ë¡œ ë°œí–‰ë˜ì—ˆìŠµë‹ˆë‹¤.',
                'url': result
            })
        else:
            logger.error(f"WordPress ë°œí–‰ ì‹¤íŒ¨: {result}")
            return jsonify({
                'success': False,
                'error': result
            }), 500
            
    except Exception as e:
        logger.error(f"WordPress ë°œí–‰ ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/schedule/recreate', methods=['GET', 'POST'])
def recreate_schedule():
    """ìŠ¤ì¼€ì¤„ ê°•ì œ ì¬ìƒì„± (í‹°ìŠ¤í† ë¦¬ í¬í•¨)"""
    try:
        from src.utils.schedule_manager import schedule_manager
        from datetime import datetime, timedelta
        
        today = datetime.now().date()
        week_start = today - timedelta(days=today.weekday())
        
        # ê¸°ì¡´ ìŠ¤ì¼€ì¤„ ì‚­ì œ
        database = get_database()
        if database.is_connected:
            conn = database.get_connection()
            with conn.cursor() as cursor:
                cursor.execute('DELETE FROM publishing_schedule WHERE week_start_date = %s', (week_start,))
                deleted = cursor.rowcount
                conn.commit()
                logger.info(f"ê¸°ì¡´ ìŠ¤ì¼€ì¤„ {deleted}ê°œ ì‚­ì œë¨")
        
        # ìƒˆ ìŠ¤ì¼€ì¤„ ìƒì„± (í‹°ìŠ¤í† ë¦¬ í¬í•¨)
        success = schedule_manager.create_weekly_schedule(week_start)
        
        if success:
            # ìƒì„±ëœ ìŠ¤ì¼€ì¤„ í™•ì¸
            schedule_data = schedule_manager.get_weekly_schedule(week_start)
            sites = []
            if schedule_data and 'schedule' in schedule_data:
                first_day = schedule_data['schedule'].get(0, {})
                sites = list(first_day.get('sites', {}).keys())
            
            return jsonify({
                'success': True,
                'message': f'{week_start} ì£¼ ìŠ¤ì¼€ì¤„ ì¬ìƒì„± ì™„ë£Œ',
                'sites': sites,
                'week_start': str(week_start)
            })
        else:
            return jsonify({
                'success': False,
                'error': 'ìŠ¤ì¼€ì¤„ ìƒì„± ì‹¤íŒ¨'
            }), 500
            
    except Exception as e:
        logger.error(f"ìŠ¤ì¼€ì¤„ ì¬ìƒì„± ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/delete_posts', methods=['POST'])
def delete_posts():
    """í¬ìŠ¤íŠ¸ ì‚­ì œ"""
    try:
        data = request.json
        post_ids = data.get('post_ids', [])
        
        database = get_database()
        
        if database.is_connected and post_ids:
            # ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‚­ì œ
            deleted_count = 0
            for post_id in post_ids:
                try:
                    if database.delete_content_file(post_id):
                        deleted_count += 1
                except Exception as e:
                    logger.error(f"í¬ìŠ¤íŠ¸ {post_id} ì‚­ì œ ì‹¤íŒ¨: {e}")
            
            return jsonify({
                'success': True,
                'message': f'{deleted_count}ê°œì˜ í¬ìŠ¤íŠ¸ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.',
                'deleted': deleted_count
            })
        
        # DB ì—°ê²° ì‹¤íŒ¨ì‹œ ëª©ì—… ì‘ë‹µ
        return jsonify({
            'success': True,
            'message': f'{len(post_ids)}ê°œì˜ í¬ìŠ¤íŠ¸ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤. (ëª©ì—… ëª¨ë“œ)',
            'deleted': post_ids
        })
        
    except Exception as e:
        logger.error(f"í¬ìŠ¤íŠ¸ ì‚­ì œ ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/bulk_delete_files', methods=['DELETE'])
def bulk_delete_files():
    """íŒŒì¼ ê¸°ë°˜ ì½˜í…ì¸  ì¼ê´„ ì‚­ì œ"""
    try:
        data = request.json
        file_paths = data.get('file_paths', [])
        
        logger.info(f"[DELETE] ì‚­ì œ ìš”ì²­ ë°›ìŒ: {len(file_paths)}ê°œ íŒŒì¼")
        logger.info(f"[DELETE] íŒŒì¼ ê²½ë¡œë“¤: {file_paths}")
        
        if not file_paths:
            logger.warning("[DELETE] ì‚­ì œí•  íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•ŠìŒ")
            return jsonify({
                'success': False,
                'error': 'ì‚­ì œí•  íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
            }), 400
        
        deleted_count = 0
        failed_files = []
        
        # DB ì—°ê²°
        database = get_database()
        
        for file_path in file_paths:
            try:
                # ë°±ìŠ¬ë˜ì‹œë¥¼ ìŠ¬ë˜ì‹œë¡œ ë³€í™˜ (ëª¨ë“  í™˜ê²½)
                file_path = file_path.replace('\\', '/')
                logger.info(f"[DELETE] ì²˜ë¦¬ ì¤‘ì¸ íŒŒì¼: {file_path}")
                
                # ìš´ì˜ í™˜ê²½ ê²½ë¡œ ë³€í™˜
                actual_file_path = file_path
                if os.getenv('KOYEB_SERVICE'):
                    # Koyeb í™˜ê²½ì—ì„œëŠ” ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                    if not file_path.startswith('/workspace'):
                        if file_path.startswith('data/'):
                            actual_file_path = f"/workspace/{file_path}"
                        else:
                            actual_file_path = f"/workspace/data/{file_path}"
                
                logger.info(f"[DELETE] ë³€í™˜ëœ ê²½ë¡œ: {actual_file_path}")
                
                # DBì—ì„œ ë¨¼ì € ì‚­ì œ
                if database.is_connected:
                    try:
                        # ì›ë³¸ ê²½ë¡œì™€ ë³€í™˜ëœ ê²½ë¡œ ëª¨ë‘ ì‹œë„
                        database.delete_content_by_path(file_path)
                        if file_path != actual_file_path:
                            database.delete_content_by_path(actual_file_path)
                        logger.info(f"DBì—ì„œ ì‚­ì œ ì™„ë£Œ: {file_path}")
                    except Exception as db_error:
                        logger.warning(f"DB ì‚­ì œ ì‹¤íŒ¨ (íŒŒì¼ì€ ì‚­ì œ ì§„í–‰): {db_error}")
                
                # íŒŒì¼ ê²½ë¡œ ê²€ì¦ ë° ì‚­ì œ
                file_deleted = False
                for path_to_try in [actual_file_path, file_path]:
                    if os.path.exists(path_to_try):
                        os.remove(path_to_try)
                        file_deleted = True
                        logger.info(f"íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {path_to_try}")
                        
                        # JSON ë©”íƒ€ë°ì´í„° íŒŒì¼ë„ ì‚­ì œ (ìˆëŠ” ê²½ìš°)
                        # ì¼ë°˜ JSON íŒŒì¼ê³¼ Tistory _meta.json íŒŒì¼ ëª¨ë‘ í™•ì¸
                        json_paths = [
                            path_to_try.replace('.html', '.json'),
                            path_to_try.replace('.html', '_meta.json')
                        ]
                        
                        for json_path in json_paths:
                            if os.path.exists(json_path):
                                os.remove(json_path)
                                logger.info(f"ë©”íƒ€ë°ì´í„° íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {json_path}")
                        break
                
                if file_deleted:
                    deleted_count += 1
                else:
                    logger.warning(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_path} / {actual_file_path}")
                    # DBì—ì„œë§Œ ì‚­ì œë˜ì—ˆìœ¼ë¯€ë¡œ ì¹´ìš´íŠ¸ ì¦ê°€
                    deleted_count += 1
                    
            except Exception as e:
                logger.error(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ {file_path}: {e}")
                failed_files.append(file_path)
        
        return jsonify({
            'success': True,
            'message': f'{deleted_count}ê°œì˜ ì½˜í…ì¸ ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.',
            'deleted_count': deleted_count,
            'failed_files': failed_files
        })
        
    except Exception as e:
        logger.error(f"ì¼ê´„ ì‚­ì œ ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/schedule')
def get_schedule():
    """ë°œí–‰ ì¼ì • ì¡°íšŒ"""
    try:
        now = datetime.now(KST)
        schedule = []
        
        # ë‹¤ìŒ 7ì¼ê°„ì˜ ì˜ˆì •
        for i in range(7):
            date = (now + timedelta(days=i)).strftime('%Y-%m-%d')
            schedule.append({
                'date': date,
                'time': '03:00',
                'status': 'scheduled',
                'sites': ['unpre', 'untab', 'skewese', 'tistory']
            })
        
        return jsonify(schedule)
    except Exception as e:
        return jsonify([]), 500

@app.route('/api/today-topics')
def get_today_topics():
    """ì˜¤ëŠ˜ì˜ ë°œí–‰ ì£¼ì œ ì¡°íšŒ"""
    try:
        from src.utils.schedule_manager import schedule_manager
        from datetime import date
        
        today = date.today()
        weekday = today.weekday()
        week_start = today - timedelta(days=weekday)
        
        sites = ['unpre', 'untab', 'skewese', 'tistory']
        topics_data = {}
        
        conn = schedule_manager.db.get_connection()
        if conn:
            with conn.cursor() as cursor:
                for site in sites:
                    cursor.execute("""
                        SELECT topic_category, specific_topic, keywords, target_length, status
                        FROM publishing_schedule 
                        WHERE week_start_date = %s AND day_of_week = %s AND site = %s
                        AND status = 'planned'
                        ORDER BY topic_category
                    """, (week_start, weekday, site))
                    
                    results = cursor.fetchall()
                    topics_data[site] = []
                    
                    for row in results:
                        category, topic, keywords, length, status = row
                        topics_data[site].append({
                            'category': category,
                            'topic': topic,
                            'keywords': keywords if keywords else [],
                            'length': length or 'medium',
                            'status': status
                        })
        
        add_system_log('INFO', f'ì˜¤ëŠ˜ì˜ ì£¼ì œ ì¡°íšŒ ì™„ë£Œ: {sum(len(v) for v in topics_data.values())}ê°œ', 'API')
        return jsonify(topics_data)
        
    except Exception as e:
        logger.error(f"Today topics error: {e}")
        add_system_log('ERROR', f'ì˜¤ëŠ˜ì˜ ì£¼ì œ ì¡°íšŒ ì˜¤ë¥˜: {e}', 'API')
        return jsonify({'error': str(e)}), 500

@app.route('/api/schedule/monthly')
def get_monthly_schedule():
    """ë‹¹ì›” ì „ì²´ ê³„íší‘œ ì¡°íšŒ - ëŒ€ì‹œë³´ë“œ í˜¸í™˜ í˜•ì‹"""
    try:
        # ì›” íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’: í˜„ì¬ ì›”)
        month = request.args.get('month')
        if month:
            year, month = map(int, month.split('-'))
            target_date = date(year, month, 1)
        else:
            today = date.today()
            target_date = date(today.year, today.month, 1)
        
        # í•´ë‹¹ ì›”ì˜ ì²«ì§¸ ë‚ ê³¼ ë§ˆì§€ë§‰ ë‚ 
        if target_date.month == 12:
            next_month = target_date.replace(year=target_date.year + 1, month=1)
        else:
            next_month = target_date.replace(month=target_date.month + 1)
        
        last_day = (next_month - timedelta(days=1)).day
        
        add_system_log('INFO', f'ì›”ë³„ ê³„íší‘œ ì¡°íšŒ: {target_date.year}-{target_date.month:02d}', 'SCHEDULE')
        
        # DBì—ì„œ í•´ë‹¹ ì›” ì „ì²´ ìŠ¤ì¼€ì¤„ ì¡°íšŒ
        from src.utils.schedule_manager import schedule_manager
        
        conn = schedule_manager.db.get_connection()
        monthly_schedule = {}
        
        if conn:
            with conn.cursor() as cursor:
                # í•´ë‹¹ ì›”ì˜ ëª¨ë“  ìŠ¤ì¼€ì¤„ ì¡°íšŒ
                cursor.execute("""
                    SELECT week_start_date, day_of_week, site, topic_category, 
                           specific_topic, keywords, target_length, status, updated_at
                    FROM publishing_schedule 
                    WHERE week_start_date + (day_of_week * INTERVAL '1 day') >= %s
                    AND week_start_date + (day_of_week * INTERVAL '1 day') < %s
                    ORDER BY week_start_date, day_of_week, site, topic_category
                """, (target_date, next_month))
                
                results = cursor.fetchall()
                
                # ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”
                for row in results:
                    week_start, day_of_week, site, category, topic, keywords, length, status, updated_at = row
                    
                    # ì‹¤ì œ ë‚ ì§œ ê³„ì‚°
                    actual_date = week_start + timedelta(days=day_of_week)
                    date_str = actual_date.strftime('%Y-%m-%d')
                    
                    if date_str not in monthly_schedule:
                        monthly_schedule[date_str] = {
                            'date': date_str,
                            'day_name': ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼'][actual_date.weekday()],
                            'sites': {}
                        }
                    
                    if site not in monthly_schedule[date_str]['sites']:
                        monthly_schedule[date_str]['sites'][site] = []
                    
                    # í‹°ìŠ¤í† ë¦¬ ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë§ˆì»¤
                    if site == 'tistory' and updated_at:
                        from datetime import datetime, timezone
                        now = datetime.now(timezone.utc)
                        if isinstance(updated_at, str):
                            updated_time = datetime.fromisoformat(updated_at.replace('Z', '+00:00'))
                        else:
                            updated_time = updated_at.replace(tzinfo=timezone.utc) if updated_at.tzinfo is None else updated_at
                        
                        # ìµœê·¼ 24ì‹œê°„ ë‚´ ì—…ë°ì´íŠ¸ë©´ íŠ¸ë Œë“œ ë§ˆí¬
                        if (now - updated_time).total_seconds() < 86400:
                            topic = f"ğŸ”¥ {topic}"
                    
                    monthly_schedule[date_str]['sites'][site].append({
                        'category': category,
                        'topic': topic,
                        'keywords': keywords,
                        'length': length,
                        'status': status
                    })
        
        # ë‚ ì§œìˆœ ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        sorted_schedule = []
        for day in range(1, last_day + 1):
            date_str = f"{target_date.year}-{target_date.month:02d}-{day:02d}"
            day_data = monthly_schedule.get(date_str, {
                'date': date_str,
                'day_name': ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼'][date(target_date.year, target_date.month, day).weekday()],
                'sites': {}
            })
            sorted_schedule.append(day_data)
        
        response_data = {
            'year': target_date.year,
            'month': target_date.month,
            'month_name': f"{target_date.year}ë…„ {target_date.month}ì›”",
            'total_days': last_day,
            'schedule': sorted_schedule
        }
        
        add_system_log('INFO', f'ì›”ë³„ ê³„íší‘œ ì‘ë‹µ: {len(sorted_schedule)}ì¼', 'SCHEDULE')
        return jsonify(response_data)
        
    except Exception as e:
        logger.error(f"Monthly schedule error: {e}")
        add_system_log('ERROR', f'ì›”ë³„ ê³„íší‘œ ì˜¤ë¥˜: {e}', 'SCHEDULE')
        return jsonify({'error': str(e)}), 500

# ìƒˆ ëŒ€ì‹œë³´ë“œìš© API ì—”ë“œí¬ì¸íŠ¸ë“¤
@app.route('/api/content/<site>')
def get_content_list(site):
    """ì‚¬ì´íŠ¸ë³„ ì½˜í…ì¸  ëª©ë¡ ì¡°íšŒ - DB ê¸°ë°˜ ì•ˆì •ì„± ê°•í™”"""
    try:
        import os
        import json
        from datetime import datetime

        # ë¡œê¹…ìœ¼ë¡œ ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
        logger.info(f"ì½˜í…ì¸  ëª©ë¡ ì¡°íšŒ ìš”ì²­: {site}")

        # ì‚¬ì´íŠ¸ ìœ íš¨ì„± ê²€ì‚¬
        valid_sites = ['skewese', 'tistory', 'unpre', 'untab']
        if site not in valid_sites:
            logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‚¬ì´íŠ¸: {site}")
            return jsonify([])

        contents = []

        # ë¨¼ì € DBì—ì„œ ì½˜í…ì¸  ì¡°íšŒ (ìš°ì„ )
        try:
            from src.utils.postgresql_database import PostgreSQLDatabase
            db = PostgreSQLDatabase()
            conn = db.get_connection()

            if conn:
                with conn.cursor() as cursor:
                    cursor.execute('''
                        SELECT id, site, title, file_path, created_at, status, metadata
                        FROM blog_automation.content_files
                        WHERE site = %s
                        ORDER BY created_at DESC
                        LIMIT 50
                    ''', (site,))

                    db_results = cursor.fetchall()

                    for row in db_results:
                        content_data = {
                            'id': row[0],
                            'site': row[1],
                            'title': row[2],
                            'file_path': row[3],
                            'created_at': row[4].isoformat() if row[4] else datetime.now().isoformat(),
                            'status': row[5],
                            'metadata': row[6] if row[6] else {}
                        }

                        # ìš´ì˜ í™˜ê²½ì—ì„œ ê²½ë¡œ ì •ê·œí™”
                        if os.getenv('KOYEB_SERVICE') and content_data.get('file_path'):
                            content_data['file_path'] = content_data['file_path'].replace('\\', '/')

                        contents.append(content_data)

                    logger.info(f"{site} DBì—ì„œ {len(contents)}ê°œ ì½˜í…ì¸  ì¡°íšŒ ì™„ë£Œ")

                    if contents:
                        return jsonify(contents)

        except Exception as db_error:
            logger.warning(f"DB ì¡°íšŒ ì‹¤íŒ¨, íŒŒì¼ì‹œìŠ¤í…œ í´ë°± ì‚¬ìš©: {db_error}")
            # ì‹œìŠ¤í…œ ë¡œê·¸ì— DB ì˜¤ë¥˜ ê¸°ë¡
            try:
                add_system_log('WARNING', f'ì½˜í…ì¸  ëª©ë¡ DB ì¡°íšŒ ì‹¤íŒ¨: {db_error}', 'DB_ERROR')
            except:
                pass

        # DB ì¡°íšŒ ì‹¤íŒ¨ ì‹œ íŒŒì¼ì‹œìŠ¤í…œ í´ë°±
        site_map = {
            'skewese': 'wordpress_posts/skewese',
            'tistory': 'tistory_posts',
            'unpre': 'wordpress_posts/unpre',
            'untab': 'wordpress_posts/untab'
        }

        current_dir = os.path.dirname(os.path.abspath(__file__))
        content_dir = os.path.join(current_dir, 'data', site_map[site])

        logger.info(f"íŒŒì¼ì‹œìŠ¤í…œ í´ë°± - ì½˜í…ì¸  ë””ë ‰í† ë¦¬: {content_dir}")

        if not os.path.exists(content_dir):
            logger.info(f"ì½˜í…ì¸  ë””ë ‰í† ë¦¬ ì—†ìŒ: {content_dir}")
            return jsonify([])

        # ì•ˆì „í•œ íŒŒì¼ ê²€ìƒ‰
        try:
            for filename in os.listdir(content_dir):
                if (site == 'tistory' and filename.endswith('_meta.json')) or \
                   (site != 'tistory' and filename.endswith('.json') and not filename.endswith('_meta.json')):
                    json_file_path = os.path.join(content_dir, filename)
                    try:
                        with open(json_file_path, 'r', encoding='utf-8') as f:
                            content_data = json.load(f)

                            # ê²½ë¡œ ì •ê·œí™”
                            if 'file_path' in content_data and os.getenv('KOYEB_SERVICE'):
                                content_data['file_path'] = content_data['file_path'].replace('\\', '/')

                            contents.append(content_data)
                    except Exception as e:
                        logger.warning(f"JSON íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ {filename}: {e}")
        except Exception as e:
            logger.error(f"ë””ë ‰í† ë¦¬ ì½ê¸° ì˜¤ë¥˜ {content_dir}: {e}")
            return jsonify([])

        # ìµœì‹ ìˆœ ì •ë ¬
        contents.sort(key=lambda x: x.get('created_at', ''), reverse=True)
        logger.info(f"{site} íŒŒì¼ì‹œìŠ¤í…œì—ì„œ {len(contents)}ê°œ ì½˜í…ì¸  ì¡°íšŒ ì™„ë£Œ")
        return jsonify(contents[:50])

    except Exception as e:
        logger.error(f"ì½˜í…ì¸  ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜ {site}: {e}")
        # ì‹œìŠ¤í…œ ë¡œê·¸ì— ì—ëŸ¬ ê¸°ë¡
        try:
            add_system_log('ERROR', f'ì½˜í…ì¸  ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨ ({site}): {e}', 'API_ERROR')
        except:
            pass
        return jsonify({'error': f'ì½˜í…ì¸  ì¡°íšŒ ì‹¤íŒ¨: {str(e)}', 'site': site}), 500

@app.route('/api/content/<site>/preview')
def get_content_preview(site):
    """ì½˜í…ì¸  ë¯¸ë¦¬ë³´ê¸°"""
    try:
        file_path = request.args.get('file')
        if not file_path:
            return jsonify({'error': 'íŒŒì¼ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤'}), 400
            
        # URL ë””ì½”ë”© ë° ê²½ë¡œ ì •ê·œí™”
        from urllib.parse import unquote_plus, unquote
        import re
        
        # ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ URL ë””ì½”ë”© ì‹œë„
        original_path = file_path
        decoded_path = None
        
        # ë°©ë²• 1: unquote_plus ì‹œë„
        try:
            decoded_path = unquote_plus(file_path)
            if '%' in decoded_path:
                decoded_path = unquote_plus(decoded_path)
        except:
            pass
        
        # ë°©ë²• 2: unquote ì‹œë„ (plusê°€ ì‹¤íŒ¨í•œ ê²½ìš°)
        if not decoded_path or decoded_path == original_path:
            try:
                decoded_path = unquote(file_path)
                if '%' in decoded_path:
                    decoded_path = unquote(decoded_path)
            except:
                pass
        
        # ë°©ë²• 3: í•œê¸€ ì¸ì½”ë”© ë¬¸ì œ í•´ê²° ì‹œë„
        if not decoded_path or decoded_path == original_path:
            try:
                decoded_path = unquote(file_path, encoding='utf-8', errors='replace')
                if '%' in decoded_path:
                    decoded_path = unquote(decoded_path, encoding='utf-8', errors='replace')
            except:
                pass
        
        # ìµœì¢…ì ìœ¼ë¡œ ë””ì½”ë”©ëœ ê²½ë¡œ ì‚¬ìš©
        file_path = decoded_path if decoded_path else file_path
        
        # íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬
        file_path = re.sub(r'[\t\r\n\x00-\x08\x0b\x0c\x0e-\x1f]', '', file_path)
        
        # ê²½ë¡œ ì •ê·œí™”
        file_path = os.path.normpath(file_path)
        
        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜ (ë³´ì•ˆìƒ í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€)
        if not os.path.isabs(file_path):
            file_path = os.path.abspath(file_path)
        
        logger.info(f"[PREVIEW] Original path: {request.args.get('file')}, Decoded+Normalized: {file_path}")
        
        # JSON ë©”íƒ€ë°ì´í„° ë¡œë“œ
        json_path = file_path.replace('.html', '.json')
        logger.info(f"[PREVIEW] Checking JSON: {json_path}, exists: {os.path.exists(json_path)}")
        if os.path.exists(json_path):
            with open(json_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
        else:
            metadata = {}
            
        # HTML ì½˜í…ì¸  ë¡œë“œ
        logger.info(f"[PREVIEW] Checking HTML: {file_path}, exists: {os.path.exists(file_path)}")
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        else:
            content = 'íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.'
            
        # ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì›¹ ê²½ë¡œë¡œ ë³€í™˜
        import re
        from bs4 import BeautifulSoup
        
        def replace_image_path(match):
            original_path = match.group(1)
            if 'blog_automation_images' in original_path:
                # ë¡œì»¬ temp ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì›¹ ê²½ë¡œë¡œ ë³€í™˜
                filename = os.path.basename(original_path)
                return f'src="/api/images/{filename}"'
            return match.group(0)
        
        # HTML ë‚´ ì´ë¯¸ì§€ src ê²½ë¡œë¥¼ ì›¹ ê²½ë¡œë¡œ ë³€í™˜
        content = re.sub(r'src="([^"]*)"', replace_image_path, content)
        
        # HTMLì—ì„œ body ë‚´ìš©ë§Œ ì¶”ì¶œ
        try:
            soup = BeautifulSoup(content, 'html.parser')
            body = soup.find('body')
            if body:
                # body ë‚´ì˜ ëª¨ë“  ë‚´ìš©ì„ ì¶”ì¶œ
                content = str(body)
                # body íƒœê·¸ ìì²´ëŠ” ì œê±°í•˜ê³  ë‚´ìš©ë§Œ ë‚¨ê¹€
                content = re.sub(r'^<body[^>]*>', '', content)
                content = re.sub(r'</body>$', '', content)
            else:
                # bodyê°€ ì—†ìœ¼ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                pass
        except Exception as e:
            logger.warning(f"HTML íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {e}")
            pass
        
        return jsonify({
            'title': metadata.get('title', ''),
            'categories': metadata.get('categories', []),
            'tags': metadata.get('tags', []),
            'keywords': metadata.get('keywords', []),
            'content': content,
            'word_count': metadata.get('word_count', 0),
            'created_at': metadata.get('created_at', '')
        })
        
    except Exception as e:
        logger.error(f"ë¯¸ë¦¬ë³´ê¸° ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/images/<filename>')
def serve_image(filename):
    """ì„ì‹œ ì´ë¯¸ì§€ íŒŒì¼ ì„œë¹™"""
    try:
        import tempfile
        temp_dir = tempfile.gettempdir()
        image_dir = os.path.join(temp_dir, 'blog_automation_images')
        
        # ë³´ì•ˆìƒ íŒŒì¼ëª… ê²€ì¦
        if '..' in filename or '/' in filename or '\\' in filename:
            return "Invalid filename", 400
            
        image_path = os.path.join(image_dir, filename)
        
        if os.path.exists(image_path):
            return send_file(image_path)
        else:
            return "Image not found", 404
            
    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ ì„œë¹™ ì˜¤ë¥˜: {e}")
        return "Error serving image", 500

@app.route('/api/content/<site>/download')
def get_content_download(site):
    """ì½˜í…ì¸  ë‹¤ìš´ë¡œë“œ"""
    try:
        file_path = request.args.get('file')
        if not file_path:
            return "íŒŒì¼ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤", 400
            
        # URL ë””ì½”ë”© ë° ê²½ë¡œ ì •ê·œí™”
        from urllib.parse import unquote_plus, unquote
        import re
        
        # ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ URL ë””ì½”ë”© ì‹œë„
        original_path = file_path
        decoded_path = None
        
        # ë°©ë²• 1: unquote_plus ì‹œë„
        try:
            decoded_path = unquote_plus(file_path)
            if '%' in decoded_path:
                decoded_path = unquote_plus(decoded_path)
        except:
            pass
        
        # ë°©ë²• 2: unquote ì‹œë„ (plusê°€ ì‹¤íŒ¨í•œ ê²½ìš°)
        if not decoded_path or decoded_path == original_path:
            try:
                decoded_path = unquote(file_path)
                if '%' in decoded_path:
                    decoded_path = unquote(decoded_path)
            except:
                pass
        
        # ë°©ë²• 3: í•œê¸€ ì¸ì½”ë”© ë¬¸ì œ í•´ê²° ì‹œë„
        if not decoded_path or decoded_path == original_path:
            try:
                decoded_path = unquote(file_path, encoding='utf-8', errors='replace')
                if '%' in decoded_path:
                    decoded_path = unquote(decoded_path, encoding='utf-8', errors='replace')
            except:
                pass
        
        # ìµœì¢…ì ìœ¼ë¡œ ë””ì½”ë”©ëœ ê²½ë¡œ ì‚¬ìš©
        file_path = decoded_path if decoded_path else file_path
        
        # íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬
        file_path = re.sub(r'[\t\r\n\x00-\x08\x0b\x0c\x0e-\x1f]', '', file_path)
        
        # ê²½ë¡œ ì •ê·œí™”
        file_path = os.path.normpath(file_path)
        
        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜ (ë³´ì•ˆìƒ í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€)
        if not os.path.isabs(file_path):
            file_path = os.path.abspath(file_path)
        
        logger.info(f"[DOWNLOAD] Original path: {request.args.get('file')}, Decoded+Normalized: {file_path}")
        
        if not os.path.exists(file_path):
            return "íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤", 404
            
        return send_file(file_path, as_attachment=True, download_name=os.path.basename(file_path))
        
    except Exception as e:
        logger.error(f"ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        return "ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨", 500

@app.route('/api/system/status')
def system_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
    try:
        return jsonify({
            'server_status': 'running',
            'scheduler_active': True,
            'database_connected': True,
            'next_run': 'ë‚´ì¼ ìƒˆë²½ 3ì‹œ',
            'total_content': 0
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/api_usage/today')
def get_api_usage_today():
    """ì˜¤ëŠ˜ì˜ API ì‚¬ìš©ëŸ‰ ì¡°íšŒ"""
    try:
        usage = api_tracker.get_today_usage()
        return jsonify(usage)
    except Exception as e:
        logger.error(f"API ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/api_usage/monthly')
def get_api_usage_monthly():
    """ì´ë²ˆ ë‹¬ API ì‚¬ìš©ëŸ‰ ì¡°íšŒ"""
    try:
        usage = api_tracker.get_monthly_usage()
        return jsonify(usage)
    except Exception as e:
        logger.error(f"ì›”ê°„ API ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/api_usage/recent')
def get_api_usage_recent():
    """ìµœê·¼ API í˜¸ì¶œ ë‚´ì—­ ì¡°íšŒ"""
    try:
        limit = request.args.get('limit', 20, type=int)
        calls = api_tracker.get_recent_calls(limit)
        return jsonify(calls)
    except Exception as e:
        logger.error(f"ìµœê·¼ API í˜¸ì¶œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

# ë°œí–‰ ìƒíƒœë¥¼ ì „ì—­ìœ¼ë¡œ ì¶”ì 
publish_status = {
    'in_progress': False,
    'current_site': '',
    'progress': 0,
    'total_sites': 0,
    'results': [],
    'message': ''
}

@app.route('/api/publish_status')
def get_publish_status():
    """ë°œí–‰ ì§„í–‰ ìƒíƒœ ì¡°íšŒ"""
    try:
        return jsonify(publish_status)
    except Exception as e:
        return jsonify({
            'in_progress': False,
            'current_site': '',
            'progress': 0,
            'total_sites': 0,
            'results': [],
            'message': f'ìƒíƒœ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}'
        })

@app.route('/api/publish_status/reset', methods=['POST'])
def reset_publish_status():
    """ìˆ˜ë™ ë°œí–‰ ìƒíƒœ ì´ˆê¸°í™”"""
    global publish_status
    publish_status = {
        'in_progress': False,
        'current_site': '',
        'progress': 0,
        'total_sites': 0,
        'results': [],
        'message': 'ìƒíƒœ ì´ˆê¸°í™”ë¨'
    }
    add_system_log('INFO', 'ë°œí–‰ ìƒíƒœ ê°•ì œ ì´ˆê¸°í™”ë¨', 'RESET')
    return jsonify({
        'success': True,
        'message': 'ë°œí–‰ ìƒíƒœê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.'
    })

@app.route('/api/quick-publish/preview', methods=['GET'])
def quick_publish_preview():
    """ìˆ˜ë™ë°œí–‰ ë¯¸ë¦¬ë³´ê¸°: ì˜¤ëŠ˜ì˜ ìˆ˜ìµ ìµœìš°ì„  ì£¼ì œ í‘œì‹œ"""
    try:
        from auto_weekly_planner import ProfitWeeklyPlanner
        from datetime import datetime
        
        planner = ProfitWeeklyPlanner()
        today_topics = planner.get_today_profit_topics()
        
        preview_data = {
            'date': datetime.now().strftime('%Y-%m-%d'),
            'sites': {}
        }
        
        for topic_info in today_topics:
            site = topic_info['site']
            preview_data['sites'][site] = {
                'title': topic_info['title'],
                'category': topic_info['category'],
                'keywords': topic_info.get('keywords', []),
                'trend_score': topic_info.get('trend_score', 0),
                'profit_type': 'ultra_profit' if topic_info.get('trend_score', 0) >= 90 else 
                              'high_profit' if topic_info.get('trend_score', 0) >= 80 else 
                              'profit_optimized'
            }
        
        return jsonify(preview_data)
        
    except Exception as e:
        logger.error(f"ë¯¸ë¦¬ë³´ê¸° ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/quick_publish', methods=['POST'])
def quick_publish():
    """ìˆ˜ë™ ë°œí–‰: ì˜¤ëŠ˜ ìŠ¤ì¼€ì¤„ ì£¼ì œë¡œ ì§ì ‘ ë°œí–‰ + WordPress ì—…ë¡œë“œ"""
    try:
        data = request.json or {}
        sites = data.get('sites', ['unpre', 'untab', 'skewese', 'tistory'])
        upload_to_wordpress = data.get('upload_to_wordpress', True)  # ê¸°ë³¸ê°’: ì—…ë¡œë“œ í™œì„±í™”
        
        # ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
        global publish_status
        if publish_status.get('in_progress', False):
            return jsonify({
                'success': False,
                'error': 'ì´ë¯¸ ë°œí–‰ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.'
            }), 400
        
        # ë°œí–‰ ì‹œì‘
        publish_status.update({
            'in_progress': True,
            'current_site': '',
            'progress': 0,
            'total_sites': len(sites),
            'results': [],
            'message': 'ë°œí–‰ ì¤€ë¹„ ì¤‘...'
        })
        
        def background_publish():
            try:
                from datetime import datetime, timedelta
                from src.utils.schedule_manager import schedule_manager
                import requests
                
                today = datetime.now().date()
                add_system_log('INFO', f'ìˆ˜ë™ë°œí–‰ ì‹œì‘: {today} - {len(sites)}ê°œ ì‚¬ì´íŠ¸', 'MANUAL')
                
                for i, site in enumerate(sites):
                    publish_status.update({
                        'current_site': site,
                        'progress': int((i / len(sites)) * 100),
                        'message': f'{site} ë°œí–‰ ì¤‘...'
                    })
                    
                    try:
                        # APIì—ì„œ ì£¼ê°„ ìŠ¤ì¼€ì¤„ ê°€ì ¸ì˜¤ê¸°
                        weekday = today.weekday()
                        week_start = today - timedelta(days=weekday)
                        
                        # ë¯¸ë¦¬ë³´ê¸° APIì™€ ë™ì¼í•œ ë¡œì§ìœ¼ë¡œ ì£¼ì œ ê°€ì ¸ì˜¤ê¸°
                        today_str = today.strftime('%Y-%m-%d')
                        database = get_database()
                        conn = database.get_connection()
                        
                        # ìˆ˜ìµ ìµœìš°ì„  ê³„íší‘œì—ì„œ ê°€ì ¸ì˜¤ê¸°
                        from auto_weekly_planner import ProfitWeeklyPlanner
                        planner = ProfitWeeklyPlanner()
                        
                        topic_data = None
                        try:
                            # ì˜¤ëŠ˜ì˜ ìˆ˜ìµ ìµœìš°ì„  ì£¼ì œ ê°€ì ¸ì˜¤ê¸°
                            today_topics = planner.get_today_profit_topics()
                            
                            # ì‚¬ì´íŠ¸ë³„ ì£¼ì œ ì°¾ê¸°
                            for topic_info in today_topics:
                                if topic_info['site'] == site:
                                    topic_data = {
                                        'topic': topic_info['title'],
                                        'category': topic_info['category'],
                                        'keywords': topic_info.get('keywords', [])
                                    }
                                    add_system_log('INFO', f'{site} ìˆ˜ìµ ìµœìš°ì„  ê³„íš ì‚¬ìš©: {topic_data["topic"]} (ì¹´í…Œê³ ë¦¬: {topic_data["category"]}, íŠ¸ë Œë“œì ìˆ˜: {topic_info.get("trend_score", 0)})', 'PROFIT_SCHEDULE')
                                    break
                        except Exception as e:
                            add_system_log('WARNING', f'ìˆ˜ìµ ê³„íší‘œ ì¡°íšŒ ì‹¤íŒ¨, DB í´ë°±: {e}', 'SCHEDULE')
                            
                            # í´ë°±: DBì—ì„œ ê°€ì ¸ì˜¤ê¸°
                            with conn.cursor() as cursor:
                                days_since_monday = today.weekday()
                                week_start = today - timedelta(days=days_since_monday)
                                
                                cursor.execute('''
                                SELECT plan_data FROM blog_automation.weekly_plans 
                                WHERE week_start = %s
                                ORDER BY created_at DESC
                                LIMIT 1
                                ''', (week_start,))
                                
                                result = cursor.fetchone()
                                if result:
                                    plan_data = result[0]
                                    plans = plan_data.get('plans', [])
                                    
                                    # ì˜¤ëŠ˜ ë‚ ì§œ, í˜„ì¬ ì‚¬ì´íŠ¸ì— í•´ë‹¹í•˜ëŠ” ê³„íš ì°¾ê¸°
                                    today_plan = next((plan for plan in plans 
                                                     if plan.get('date') == today_str and plan.get('site') == site), None)
                                    
                                    if today_plan:
                                        topic_data = {
                                            'topic': today_plan.get('title'),
                                            'category': today_plan.get('category'),
                                            'keywords': today_plan.get('keywords', [site])
                                        }
                                        add_system_log('INFO', f'{site} DB ê³„íš ì‚¬ìš©: {topic_data["topic"]}', 'SCHEDULE')
                        
                        if topic_data:
                            topic = topic_data['topic']
                            category = topic_data['category'] 
                            keywords = topic_data.get('keywords', [site])
                            add_system_log('INFO', f'{site}: {topic}', 'SCHEDULE')
                        else:
                            # ë¯¸ë¦¬ë³´ê¸° APIì™€ ë™ì¼í•œ ëŒ€ì²´ ì£¼ì œ ì‚¬ìš©
                            topic = f'ì˜¤ëŠ˜ì˜ {site.upper()} ì¶”ì²œ ì£¼ì œ'
                            category = 'ì¼ë°˜'
                            keywords = ['ì˜¤ëŠ˜', 'ì¶”ì²œ', 'ì£¼ì œ']
                            add_system_log('WARNING', f'{site}: ëŒ€ì²´ ì£¼ì œ ì‚¬ìš© - {topic}', 'FALLBACK')
                        
                        # ì§ì ‘ ì½˜í…ì¸  ìƒì„± (HTTP í˜¸ì¶œ ëŒ€ì‹ )
                        try:
                            # ì½˜í…ì¸  ìƒì„±ê¸° ì‚¬ìš©
                            generator = ContentGenerator()
                            
                            # ì‚¬ì´íŠ¸ë³„ ì„¤ì •
                            if site == 'tistory':
                                from src.generators.tistory_content_exporter import TistoryContentExporter
                                exporter = TistoryContentExporter()
                                site_config = {
                                    'name': 'TISTORY',
                                    'categories': [category],
                                    'content_style': 'ì¹œê·¼í•˜ê³  ì½ê¸° ì‰¬ìš´ í†¤',
                                    'target_audience': 'ì¼ë°˜ ëŒ€ì¤‘',
                                    'keywords_focus': keywords
                                }
                            else:
                                from src.generators.wordpress_content_exporter import WordPressContentExporter
                                exporter = WordPressContentExporter()
                                site_config = {
                                    'name': site.upper(),
                                    'categories': [category],
                                    'content_style': 'ì „ë¬¸ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í†¤',
                                    'target_audience': 'ê´€ì‹¬ ìˆëŠ” ë…ìë“¤',
                                    'keywords_focus': keywords
                                }
                            
                            # ì½˜í…ì¸  ìƒì„±
                            content_data = generator.generate_content(
                                site_config,
                                topic,
                                category,
                                None,  # existing_posts
                                'medium',  # content_length
                                site  # site_key for API tracking
                            )
                            
                            if content_data:
                                # íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°
                                if site == 'tistory':
                                    filepath = exporter.export_content(content_data)
                                else:
                                    filepath = exporter.export_content(site, content_data)
                                
                                # DBì— ì €ì¥
                                file_id = db.add_content_file(
                                    site=site,
                                    title=content_data['title'],
                                    file_path=filepath,
                                    file_type='tistory' if site == 'tistory' else 'wordpress',
                                    metadata={
                                        'category': category,
                                        'tags': content_data.get('tags', []),
                                        'manual_published': True,
                                        'published_at': datetime.now(timezone(timedelta(hours=9))).isoformat()
                                    }
                                )
                                
                                # ë°œí–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
                                db.update_file_status(file_id, 'published', datetime.now())

                                # WordPress ì—…ë¡œë“œ (WordPress ì‚¬ì´íŠ¸ë§Œ)
                                upload_result = None
                                publish_url = None
                                if upload_to_wordpress and site in ['unpre', 'untab', 'skewese']:
                                    try:
                                        from src.publishers.wordpress_publisher import WordPressPublisher
                                        import json
                                        
                                        # WordPress ì„¤ì • ë¡œë“œ
                                        config_path = 'config/wordpress_sites.json'
                                        if os.path.exists(config_path):
                                            with open(config_path, 'r', encoding='utf-8') as f:
                                                wp_config = json.load(f)
                                            
                                            if site in wp_config:
                                                publisher = WordPressPublisher(wp_config[site])
                                                
                                                wp_content = {
                                                    'title': content_data['title'],
                                                    'content': content_data['content'],
                                                    'excerpt': content_data.get('summary', '')[:100],
                                                    'status': 'publish'
                                                }
                                                
                                                upload_result = publisher.publish_post(wp_content)
                                                if upload_result and upload_result.get('success'):
                                                    publish_url = upload_result.get('url')
                                                    add_system_log('INFO', f'{site} WordPress ì—…ë¡œë“œ ì„±ê³µ: {publish_url}', 'SUCCESS')
                                                else:
                                                    add_system_log('ERROR', f'{site} WordPress ì—…ë¡œë“œ ì‹¤íŒ¨: {upload_result.get("error")}', 'ERROR')
                                    except Exception as wp_error:
                                        add_system_log('ERROR', f'{site} WordPress ì—…ë¡œë“œ ì˜¤ë¥˜: {wp_error}', 'ERROR')

                                # ë°œí–‰ ì´ë ¥ ê¸°ë¡ (publish_history í…Œì´ë¸”)
                                try:
                                    from datetime import timezone, timedelta
                                    kst = timezone(timedelta(hours=9))
                                    publish_status_val = 'success' if (not upload_to_wordpress or site == 'tistory' or upload_result.get('success')) else 'partial'
                                    error_msg = None if publish_status_val == 'success' else upload_result.get('error') if upload_result else None

                                    conn = db.get_connection()
                                    with conn.cursor() as cursor:
                                        cursor.execute(f'''
                                            INSERT INTO {db.schema}.publish_history
                                            (site, content_file_id, publish_type, publish_status, error_message,
                                             published_at, publish_url, response_data)
                                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s::jsonb)
                                        ''', (
                                            site,
                                            file_id,
                                            'manual',
                                            publish_status_val,
                                            error_msg,
                                            datetime.now(kst),
                                            publish_url,
                                            json.dumps({'manual_publish': True, 'upload_to_wordpress': upload_to_wordpress}, ensure_ascii=False)
                                        ))
                                        conn.commit()
                                except Exception as history_error:
                                    add_system_log('WARNING', f'{site} ë°œí–‰ ì´ë ¥ ê¸°ë¡ ì‹¤íŒ¨: {history_error}', 'WARNING')

                                # ê²°ê³¼ì— WordPress ì—…ë¡œë“œ ì •ë³´ í¬í•¨
                                result_message = f'{site} ë°œí–‰ ì„±ê³µ'
                                if upload_result:
                                    if upload_result.get('success'):
                                        result_message += f' + WordPress ì—…ë¡œë“œ ì„±ê³µ'
                                    else:
                                        result_message += f' (WordPress ì—…ë¡œë“œ ì‹¤íŒ¨)'
                                
                                publish_status['results'].append({
                                    'site': site,
                                    'success': True,
                                    'message': result_message,
                                    'topic': topic,
                                    'wordpress_upload': upload_result
                                })
                                add_system_log('INFO', f'{site} ë°œí–‰ ì„±ê³µ: {topic}', 'SUCCESS')
                            else:
                                publish_status['results'].append({
                                    'site': site,
                                    'success': False,
                                    'message': f'{site} ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨',
                                    'topic': topic
                                })
                                add_system_log('ERROR', f'{site} ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨', 'ERROR')
                        
                        except Exception as content_error:
                            publish_status['results'].append({
                                'site': site,
                                'success': False,
                                'message': f'{site} ì½˜í…ì¸  ìƒì„± ì˜¤ë¥˜: {str(content_error)}',
                                'topic': topic
                            })
                            add_system_log('ERROR', f'{site} ì½˜í…ì¸  ìƒì„± ì˜¤ë¥˜: {content_error}', 'ERROR')
                            
                    except Exception as site_error:
                        publish_status['results'].append({
                            'site': site,
                            'success': False,
                            'message': f'{site} ì˜¤ë¥˜: {str(site_error)}',
                            'topic': topic if 'topic' in locals() else 'ì•Œ ìˆ˜ ì—†ìŒ'
                        })
                        add_system_log('ERROR', f'{site} ì˜¤ë¥˜: {site_error}', 'ERROR')
                
                # ì™„ë£Œ ì²˜ë¦¬
                success_count = sum(1 for r in publish_status['results'] if r['success'])
                publish_status.update({
                    'in_progress': False,
                    'progress': 100,
                    'message': f'ë°œí–‰ ì™„ë£Œ: {success_count}/{len(sites)} ì„±ê³µ'
                })
                add_system_log('INFO', f'ìˆ˜ë™ë°œí–‰ ì™„ë£Œ: {success_count}/{len(sites)} ì„±ê³µ', 'COMPLETE')
                
            except Exception as e:
                publish_status.update({
                    'in_progress': False,
                    'message': f'ë°œí–‰ ì˜¤ë¥˜: {str(e)}'
                })
                add_system_log('ERROR', f'ì „ì²´ ë°œí–‰ ì˜¤ë¥˜: {e}', 'ERROR')
        
        import threading
        threading.Thread(target=background_publish, daemon=True).start()
        
        return jsonify({
            'success': True,
            'message': f'{len(sites)}ê°œ ì‚¬ì´íŠ¸ ë°œí–‰ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'ë°œí–‰ ì‹œì‘ ì‹¤íŒ¨: {str(e)}'
        }), 500

@app.route('/api/manual-publish', methods=['POST'])
def manual_publish():
    """ìˆ˜ë™ ë°œí–‰ (ëŒ€ì‹œë³´ë“œìš©)"""
    # quick_publishì™€ ë™ì¼í•œ ë¡œì§ì„ ì‚¬ìš©
    return quick_publish()

@app.route('/api/schedule/auto_publish', methods=['POST'])
def manual_auto_publish():
    """ìˆ˜ë™ìœ¼ë¡œ ìë™ ë°œí–‰ ì‹¤í–‰"""
    try:
        data = request.json
        sites = data.get('sites', ['unpre', 'untab', 'skewese', 'tistory'])
        
        # ì „ì—­ ìƒíƒœ ì´ˆê¸°í™”
        global publish_status
        publish_status.update({
            'in_progress': True,
            'current_site': '',
            'progress': 0,
            'total_sites': len(sites),
            'results': [],
            'message': 'ë°œí–‰ì„ ì‹œì‘í•©ë‹ˆë‹¤...'
        })
        
        results = []
        
        for idx, site in enumerate(sites):
            try:
                # ìƒíƒœ ì—…ë°ì´íŠ¸
                publish_status.update({
                    'current_site': site,
                    'progress': int((idx / len(sites)) * 100),
                    'message': f'{site} ì‚¬ì´íŠ¸ ë°œí–‰ ì¤‘...'
                })
                
                # ìë™ë°œí–‰ê³„íšì—ì„œ ì˜¤ëŠ˜ ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” ì‹¤ì œ ì£¼ì œ ê°€ì ¸ì˜¤ê¸°
                from src.utils.schedule_manager import ScheduleManager
                from datetime import datetime, timedelta
                
                schedule_manager = ScheduleManager()
                
                # ì˜¤ëŠ˜ì˜ ê³„íšëœ ì£¼ì œ ê°€ì ¸ì˜¤ê¸°
                scheduled_topic = schedule_manager.get_today_scheduled_topic(site)
                
                if scheduled_topic:
                    topic = scheduled_topic['topic']
                    keywords = scheduled_topic['keywords']
                    category = scheduled_topic['category']
                    logger.info(f"[SCHEDULE] {site} ìŠ¤ì¼€ì¤„ ì£¼ì œ ì‚¬ìš©: {topic}")
                else:
                    # ìŠ¤ì¼€ì¤„ì— ì—†ìœ¼ë©´ ê¸°ë³¸ ì£¼ì œ ì‚¬ìš©
                    topic_map = {
                        'unpre': 'Python ê¸°ì´ˆ í”„ë¡œê·¸ë˜ë° ì™„ë²½ ê°€ì´ë“œ',
                        'untab': '2025ë…„ ë¶€ë™ì‚° íˆ¬ì ì „ëµ ë¶„ì„',
                        'skewese': 'ì¡°ì„ ì™•ì¡° ì—­ì‚¬ ì† ìˆ¨ê²¨ì§„ ì´ì•¼ê¸°'
                    }
                    topic = topic_map.get(site, 'IT ê¸°ìˆ  íŠ¸ë Œë“œ')
                    keywords = [site, 'ê°€ì´ë“œ']
                    category = 'programming' if site == 'unpre' else 'realestate' if site == 'untab' else 'history'
                    logger.info(f"[SCHEDULE] {site} ê¸°ë³¸ ì£¼ì œ ì‚¬ìš©: {topic}")
                
                # ì§ì ‘ ì½˜í…ì¸  ìƒì„± API í˜¸ì¶œ
                import requests
                import json
                
                # 1. ì½˜í…ì¸  ìƒì„±
                generate_payload = {
                    'site': site,
                    'topic': topic,
                    'keywords': keywords,
                    'category': category,
                    'content_length': 'medium'
                }
                
                logger.info(f"[AUTO_PUBLISH] {site} ì½˜í…ì¸  ìƒì„± ì‹œì‘ - ì£¼ì œ: {topic}")
                
                # í˜„ì¬ ì„œë²„ URL ê²°ì • (ìš´ì˜/ê°œë°œ í™˜ê²½ ìë™ ê°ì§€)
                server_url = request.url_root.rstrip('/')
                
                logger.info(f"[AUTO_PUBLISH] {site} API í˜¸ì¶œ: {server_url}/api/generate_wordpress")
                generate_response = requests.post(
                    f'{server_url}/api/generate_wordpress',
                    headers={'Content-Type': 'application/json'},
                    json=generate_payload,
                    timeout=300
                )
                
                if generate_response.status_code != 200:
                    logger.error(f"[AUTO_PUBLISH] {site} ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: {generate_response.status_code}")
                    success = False
                else:
                    generate_result = generate_response.json()
                    if not generate_result.get('success'):
                        logger.error(f"[AUTO_PUBLISH] {site} ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: {generate_result.get('error')}")
                        success = False
                    else:
                        # 2. WordPress ë°œí–‰
                        file_path = generate_result.get('file_path')
                        if not file_path:
                            logger.error(f"[AUTO_PUBLISH] {site} íŒŒì¼ ê²½ë¡œ ì—†ìŒ")
                            success = False
                        else:
                            logger.info(f"[AUTO_PUBLISH] {site} WordPress ë°œí–‰ ì¤‘...")
                            publish_payload = {
                                'file_path': file_path,
                                'site': site
                            }
                            
                            publish_response = requests.post(
                                f'{server_url}/api/publish_to_wordpress',
                                headers={'Content-Type': 'application/json'},
                                json=publish_payload,
                                timeout=120
                            )
                            
                            if publish_response.status_code != 200:
                                logger.error(f"[AUTO_PUBLISH] {site} WordPress ë°œí–‰ ì‹¤íŒ¨: {publish_response.status_code}")
                                success = False
                            else:
                                publish_result = publish_response.json()
                                if not publish_result.get('success'):
                                    logger.error(f"[AUTO_PUBLISH] {site} WordPress ë°œí–‰ ì‹¤íŒ¨: {publish_result.get('error')}")
                                    success = False
                                else:
                                    published_url = publish_result.get('url', '')
                                    logger.info(f"[AUTO_PUBLISH] {site} ë°œí–‰ ì™„ë£Œ: {published_url}")
                                    
                                    # ìŠ¤ì¼€ì¤„ ìƒíƒœë¥¼ 'published'ë¡œ ì—…ë°ì´íŠ¸
                                    if scheduled_topic:
                                        try:
                                            today = datetime.now().date()
                                            week_start = today - timedelta(days=today.weekday())
                                            day_of_week = today.weekday()
                                            schedule_manager.update_schedule_status(
                                                week_start, day_of_week, site, 'published', url=published_url
                                            )
                                            logger.info(f"[SCHEDULE] {site} ìŠ¤ì¼€ì¤„ ìƒíƒœ ì—…ë°ì´íŠ¸: published")
                                        except Exception as e:
                                            logger.error(f"[SCHEDULE] {site} ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                                    
                                    success = True
                
                result_message = f'{site} ë°œí–‰ ì™„ë£Œ'
                result_url = None
                if success and 'published_url' in locals():
                    result_message += f' - URL: {published_url}'
                    result_url = published_url
                elif not success:
                    result_message = f'{site} ë°œí–‰ ì‹¤íŒ¨'
                
                site_result = {
                    'site': site,
                    'success': success,
                    'message': result_message,
                    'topic': topic,
                    'url': result_url
                }
                results.append(site_result)
                
                # ì‹¤ì‹œê°„ ìƒíƒœ ì—…ë°ì´íŠ¸
                publish_status['results'].append(site_result)
                publish_status['progress'] = int(((idx + 1) / len(sites)) * 100)
                
            except Exception as e:
                logger.error(f"ì‚¬ì´íŠ¸ {site} ë°œí–‰ ì˜¤ë¥˜: {e}")
                results.append({
                    'site': site,
                    'success': False,
                    'message': f'{site} ë°œí–‰ ì˜¤ë¥˜: {str(e)}'
                })
        
        success_count = sum(1 for r in results if r['success'])
        
        # ìµœì¢… ìƒíƒœ ì—…ë°ì´íŠ¸
        publish_status.update({
            'in_progress': False,
            'current_site': '',
            'progress': 100,
            'message': f'ë°œí–‰ ì™„ë£Œ! ì´ {len(sites)}ê°œ ì‚¬ì´íŠ¸ ì¤‘ {success_count}ê°œ ì„±ê³µ'
        })
        
        return jsonify({
            'success': success_count > 0,
            'message': f'ì´ {len(sites)}ê°œ ì‚¬ì´íŠ¸ ì¤‘ {success_count}ê°œ ì„±ê³µ',
            'results': results
        })
        
    except Exception as e:
        logger.error(f"ìˆ˜ë™ ìë™ ë°œí–‰ ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/wordpress_files')
def get_wordpress_files():
    """WordPress íŒŒì¼ ëª©ë¡"""
    try:
        database = get_database()
        if not database.is_connected:
            # DB ì—°ê²° ì‹¤íŒ¨ì‹œ ëª©ì—… ë°ì´í„° ë°˜í™˜
            return jsonify(get_mock_wordpress_files())
        
        # DBì—ì„œ WordPress ì½˜í…ì¸  ì¡°íšŒ
        files = database.get_content_files(file_type='wordpress', limit=50)
        
        # í˜•ì‹ ë§ì¶”ê¸°
        formatted_files = []
        for f in files:
            # ì‹œê°„ í¬ë§·íŒ… (í•œêµ­ ì‹œê°„)
            created_at = f.get('created_at')
            if created_at:
                if isinstance(created_at, str):
                    # ISO í˜•ì‹ ë¬¸ìì—´ì„ datetimeìœ¼ë¡œ ë³€í™˜
                    from datetime import datetime
                    try:
                        dt = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                        # UTCë¥¼ í•œêµ­ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
                        kst_dt = dt.astimezone(KST)
                        formatted_date = kst_dt.strftime('%Y-%m-%d %H:%M')
                    except:
                        formatted_date = created_at
                else:
                    formatted_date = created_at.strftime('%Y-%m-%d %H:%M') if hasattr(created_at, 'strftime') else str(created_at)
            else:
                formatted_date = datetime.now(KST).strftime('%Y-%m-%d %H:%M')
            
            formatted_files.append({
                'id': f.get('id'),
                'site': f.get('site', 'unpre'),
                'title': f.get('title'),
                'date': formatted_date,
                'size': f'{f.get("file_size", 0) / 1024:.1f}KB' if f.get('file_size') else '3.0KB',
                'status': f.get('status', 'draft'),
                'url': f.get('url'),
                'actions': ['view', 'publish', 'download', 'delete'] if f.get('status') == 'draft' else ['view', 'download', 'delete']
            })
        
        return jsonify(formatted_files)
    except Exception as e:
        logger.error(f"WordPress íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ë°œìƒì‹œ ëª©ì—… ë°ì´í„° ë°˜í™˜
        return jsonify(get_mock_wordpress_files())

def get_mock_wordpress_files():
    """ëª©ì—… WordPress íŒŒì¼ ë°ì´í„°"""
    now = datetime.now(KST)
    base_files = [
            {
                'id': 'wp_unpre_001',
                'site': 'unpre',
                'title': 'ğŸ¤– AI ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ í™œìš© ê°€ì´ë“œ',
                'date': now.strftime('%Y-%m-%d %H:%M'),
                'size': '3.2KB',
                'status': 'published',
                'url': 'https://unpre.co.kr/ai-coding-assistant-guide',
                'actions': ['view', 'edit', 'download', 'delete']
            },
            {
                'id': 'wp_unpre_002',
                'site': 'unpre', 
                'title': 'âš¡ React 18 Concurrent Features ì™„ì „ ì •ë³µ',
                'date': (now - timedelta(hours=2)).strftime('%Y-%m-%d %H:%M'),
                'size': '4.1KB',
                'status': 'published',
                'url': 'https://unpre.co.kr/react-18-concurrent',
                'actions': ['view', 'edit', 'download', 'delete']
            },
            {
                'id': 'wp_untab_001',
                'site': 'untab',
                'title': 'ğŸ“š í† ìµ 990ì  ë‹¬ì„±í•˜ëŠ” 5ê°€ì§€ ë¹„ë²•',
                'date': (now - timedelta(hours=1)).strftime('%Y-%m-%d %H:%M'),
                'size': '2.8KB',
                'status': 'published',
                'url': 'https://untab.co.kr/toeic-990-tips',
                'actions': ['view', 'edit', 'download', 'delete']
            },
            {
                'id': 'wp_untab_002',
                'site': 'untab',
                'title': 'ğŸ’° ë¶€ë™ì‚° ê²½ë§¤ ì´ˆë³´ì ì™„ë²½ ê°€ì´ë“œ',
                'date': (now - timedelta(hours=3)).strftime('%Y-%m-%d %H:%M'),
                'size': '3.5KB',
                'status': 'draft',
                'url': None,
                'actions': ['edit', 'publish', 'download', 'delete']
            },
            {
                'id': 'wp_skewese_001',
                'site': 'skewese',
                'title': 'ğŸ›ï¸ ì¡°ì„ ì‹œëŒ€ ê³¼í•™ê¸°ìˆ ì˜ ìˆ¨ê²¨ì§„ ì´ì•¼ê¸°',
                'date': (now - timedelta(minutes=30)).strftime('%Y-%m-%d %H:%M'),
                'size': '3.7KB',
                'status': 'published',
                'url': 'https://skewese.com/joseon-science-stories',
                'actions': ['view', 'edit', 'download', 'delete']
            },
            {
                'id': 'wp_skewese_002',
                'site': 'skewese',
                'title': 'âœ¨ ê³ êµ¬ë ¤ ê³ ë¶„ë²½í™” ì† ìš°ì£¼ê´€',
                'date': (now - timedelta(hours=4)).strftime('%Y-%m-%d %H:%M'),
                'size': '2.9KB',
                'status': 'draft',
                'url': None,
                'actions': ['edit', 'publish', 'download', 'delete']
            }
        ]
    return base_files

@app.route('/api/tistory_files')
def get_tistory_files():
    """Tistory íŒŒì¼ ëª©ë¡"""
    try:
        database = get_database()
        if not database.is_connected:
            # DB ì—°ê²° ì‹¤íŒ¨ì‹œ ëª©ì—… ë°ì´í„° ë°˜í™˜
            return jsonify(get_mock_tistory_files())
        
        # DBì—ì„œ Tistory ì½˜í…ì¸  ì¡°íšŒ
        files = database.get_content_files(file_type='tistory', limit=50)
        
        # í˜•ì‹ ë§ì¶”ê¸°
        formatted_files = []
        for f in files:
            # ì‹œê°„ í¬ë§·íŒ… (í•œêµ­ ì‹œê°„)
            created_at = f.get('created_at')
            if created_at:
                if isinstance(created_at, str):
                    # ISO í˜•ì‹ ë¬¸ìì—´ì„ datetimeìœ¼ë¡œ ë³€í™˜
                    from datetime import datetime
                    try:
                        dt = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                        # UTCë¥¼ í•œêµ­ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
                        kst_dt = dt.astimezone(KST)
                        formatted_date = kst_dt.strftime('%Y-%m-%d %H:%M')
                    except:
                        formatted_date = created_at
                else:
                    formatted_date = created_at.strftime('%Y-%m-%d %H:%M') if hasattr(created_at, 'strftime') else str(created_at)
            else:
                formatted_date = datetime.now(KST).strftime('%Y-%m-%d %H:%M')
            
            formatted_files.append({
                'id': f.get('id'),
                'title': f.get('title'),
                'date': formatted_date,
                'size': f'{f.get("file_size", 0) / 1024:.1f}KB' if f.get('file_size') else '3.0KB',
                'status': f.get('status', 'draft'),
                'url': f.get('url'),
                'actions': ['view', 'download', 'delete'],
                'category': f.get('categories', ['ê¸°ë³¸'])[0] if f.get('categories') else 'ê¸°ë³¸',
                'tags': f.get('tags', [])
            })
        
        return jsonify(formatted_files)
    except Exception as e:
        logger.error(f"Tistory íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ë°œìƒì‹œ ëª©ì—… ë°ì´í„° ë°˜í™˜
        return jsonify(get_mock_tistory_files())

def get_mock_tistory_files():
    """ëª©ì—… Tistory íŒŒì¼ ë°ì´í„°"""
    now = datetime.now(KST)
    base_files = [
            {
                'id': 'tistory_001',
                'title': 'ğŸ¯ 2025ë…„ ì–¸ì–´í•™ìŠµ íŠ¸ë Œë“œì™€ ì „ë§',
                'date': now.strftime('%Y-%m-%d %H:%M'),
                'size': '2.7KB',
                'status': 'published',
                'url': 'https://untab.tistory.com/language-trends-2025',
                'actions': ['view', 'download', 'delete'],
                'category': 'ì–¸ì–´í•™ìŠµ',
                'tags': ['ì–¸ì–´í•™ìŠµ', 'íŠ¸ë Œë“œ', '2025ë…„']
            },
            {
                'id': 'tistory_002',
                'title': 'ğŸ’¡ íš¨ê³¼ì ì¸ ì˜¨ë¼ì¸ ê°•ì˜ ì œì‘ ë…¸í•˜ìš°',
                'date': (now - timedelta(hours=1)).strftime('%Y-%m-%d %H:%M'),
                'size': '3.1KB',
                'status': 'published',
                'url': 'https://untab.tistory.com/online-course-creation',
                'actions': ['view', 'download', 'delete'],
                'category': 'êµìœ¡ì½˜í…ì¸ ',
                'tags': ['ì˜¨ë¼ì¸ê°•ì˜', 'ì œì‘', 'ë…¸í•˜ìš°']
            },
            {
                'id': 'tistory_003',
                'title': 'ğŸ“ˆ ì£¼ì‹ íˆ¬ì ì´ˆë³´ìë¥¼ ìœ„í•œ ê¸°ë³¸ ê°€ì´ë“œ',
                'date': (now - timedelta(hours=2)).strftime('%Y-%m-%d %H:%M'),
                'size': '4.2KB',
                'status': 'draft',
                'url': None,
                'actions': ['view', 'download', 'delete'],
                'category': 'íˆ¬ì',
                'tags': ['ì£¼ì‹íˆ¬ì', 'ì´ˆë³´ì', 'ê°€ì´ë“œ']
            },
            {
                'id': 'tistory_004',
                'title': 'ğŸ† AWS ìê²©ì¦ ì·¨ë“ ì™„ë²½ ë¡œë“œë§µ',
                'date': (now - timedelta(hours=3)).strftime('%Y-%m-%d %H:%M'),
                'size': '3.8KB',
                'status': 'published',
                'url': 'https://untab.tistory.com/aws-certification-roadmap',
                'actions': ['view', 'download', 'delete'],
                'category': 'ITìê²©ì¦',
                'tags': ['AWS', 'ìê²©ì¦', 'ë¡œë“œë§µ']
            },
            {
                'id': 'tistory_005',
                'title': 'ğŸ’° ë¶€ë™ì‚° ê²½ë§¤ íˆ¬ì ì‹œì‘í•˜ëŠ” ë²•',
                'date': (now - timedelta(hours=5)).strftime('%Y-%m-%d %H:%M'),
                'size': '3.5KB',
                'status': 'draft',
                'url': None,
                'actions': ['view', 'download', 'delete'],
                'category': 'ë¶€ë™ì‚°',
                'tags': ['ë¶€ë™ì‚°ê²½ë§¤', 'íˆ¬ì', 'ì´ˆë³´ì']
            }
        ]
    return base_files

@app.route('/api/system/time')
def get_system_time():
    """ì‹œìŠ¤í…œ ì‹œê°„ ì¡°íšŒ (í•œêµ­ ì‹œê°„ê³¼ ì„œë²„ ì‹œê°„ ë¹„êµ)"""
    import time
    
    # ì„œë²„ UTC ì‹œê°„
    utc_time = datetime.now(pytz.UTC)
    # í•œêµ­ ì‹œê°„
    kst_time = datetime.now(KST)
    # ì„œë²„ ë¡œì»¬ ì‹œê°„ (ì‹œê°„ëŒ€ ì—†ì´)
    server_local = datetime.now()
    
    # ì‹œê°„ ì°¨ì´ ê³„ì‚°
    time_diff = kst_time.hour - server_local.hour
    if time_diff < -12:
        time_diff += 24
    elif time_diff > 12:
        time_diff -= 24
    
    return jsonify({
        'status': 'success',
        'korea_time': kst_time.strftime('%Y-%m-%d %H:%M:%S KST'),
        'utc_time': utc_time.strftime('%Y-%m-%d %H:%M:%S UTC'),
        'server_local_time': server_local.strftime('%Y-%m-%d %H:%M:%S'),
        'timezone': 'Asia/Seoul',
        'time_difference_hours': time_diff,
        'scheduler_info': {
            'timezone': 'Asia/Seoul',
            'note': 'ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” í•œêµ­ ì‹œê°„(KST) ê¸°ì¤€ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤'
        }
    })

@app.route('/favicon.ico')
def favicon():
    """favicon ì²˜ë¦¬"""
    from flask import Response
    # ê°„ë‹¨í•œ ë¹ˆ favicon ì‘ë‹µ
    return Response('', status=204)

@app.route('/api/test_claude', methods=['GET'])
def test_claude():
    """Claude API í…ŒìŠ¤íŠ¸ ë° ê°•ì œ ì¬ì´ˆê¸°í™”"""
    global content_generator
    
    try:
        # ê°•ì œ ì¬ì´ˆê¸°í™”
        from src.generators.content_generator import ContentGenerator
        test_generator = ContentGenerator()
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì½˜í…ì¸  ìƒì„±
        site_config = {
            'name': 'test',
            'target_audience': 'í…ŒìŠ¤íŠ¸',
            'content_style': 'í…ŒìŠ¤íŠ¸',
            'keywords_focus': ['í…ŒìŠ¤íŠ¸']
        }
        
        test_content = test_generator.generate_content(
            site_config=site_config,
            topic='í…ŒìŠ¤íŠ¸ ì£¼ì œ',
            category='í…ŒìŠ¤íŠ¸',
            content_length='short'
        )
        
        # ì „ì—­ ë³€ìˆ˜ ì—…ë°ì´íŠ¸
        content_generator = test_generator
        
        return jsonify({
            'success': True,
            'message': 'Claude API ì •ìƒ ì‘ë™',
            'title': test_content.get('title', 'ì—†ìŒ')[:50],
            'sections_count': len(test_content.get('sections', [])),
            'content_length': len(str(test_content))
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/health')
def health():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return jsonify({
        'status': 'healthy',
        'message': 'Blog automation system is running',
        'time': datetime.now(KST).strftime('%Y-%m-%d %H:%M:%S KST')
    }), 200

@app.route('/api/status')
def api_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ API"""
    conn = get_db_connection()
    db_status = 'connected' if conn else 'disconnected'
    if conn:
        conn.close()
    
    return jsonify({
        'status': 'operational',
        'version': '1.0.0',
        'database': db_status,
        'features': {
            'content_generation': True,
            'wordpress_publishing': True,
            'tistory_publishing': True,
            'image_generation': True,
            'seo_optimization': True
        },
        'server_time': datetime.now(KST).strftime('%Y-%m-%d %H:%M:%S KST')
    }), 200

def _create_beautiful_html_template(generated_content, site_config):
    """ì•„ë¦„ë‹¤ìš´ HTML í…œí”Œë¦¿ ìƒì„±"""
    return f"""
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{generated_content.get('title', 'ì œëª©')}</title>
    <meta name="description" content="{generated_content.get('meta_description', 'ì„¤ëª…')}"
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}
        
        body {{
            font-family: 'Noto Sans KR', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            line-height: 1.8;
            color: #2c3e50;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }}
        
        .container {{
            max-width: 900px;
            margin: 0 auto;
            background: #ffffff;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.1);
            overflow: hidden;
        }}
        
        .header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 60px 40px;
            text-align: center;
            position: relative;
        }}
        
        .header::before {{
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><defs><pattern id="grain" width="100" height="100" patternUnits="userSpaceOnUse"><circle cx="25" cy="25" r="1" fill="rgba(255,255,255,0.1)"/><circle cx="75" cy="75" r="1" fill="rgba(255,255,255,0.05)"/><circle cx="50" cy="10" r="0.5" fill="rgba(255,255,255,0.1)"/></pattern></defs><rect width="100" height="100" fill="url(%23grain)"/></svg>');
            opacity: 0.1;
        }}
        
        .header h1 {{
            font-size: 2.8em;
            font-weight: 600;
            margin-bottom: 20px;
            text-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            position: relative;
            z-index: 1;
        }}
        
        .meta-info {{
            display: inline-flex;
            align-items: center;
            background: rgba(255, 255, 255, 0.2);
            padding: 12px 24px;
            border-radius: 50px;
            font-size: 0.9em;
            backdrop-filter: blur(10px);
            position: relative;
            z-index: 1;
        }}
        
        .content {{
            padding: 50px 40px;
        }}
        
        .introduction {{
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: 30px;
            border-radius: 15px;
            margin-bottom: 40px;
            border-left: 5px solid #667eea;
            position: relative;
        }}
        
        .introduction::before {{
            content: 'ğŸ’¡';
            position: absolute;
            top: -10px;
            left: 20px;
            background: #667eea;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.2em;
        }}
        
        .section {{
            margin-bottom: 40px;
            padding: 30px;
            background: #ffffff;
            border-radius: 15px;
            box-shadow: 0 5px 20px rgba(0, 0, 0, 0.05);
            border: 1px solid #f1f3f4;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }}
        
        .section:hover {{
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
        }}
        
        .section h2 {{
            color: #667eea;
            font-size: 1.8em;
            font-weight: 600;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 2px solid #f1f3f4;
            position: relative;
        }}
        
        .section h2::before {{
            content: '';
            position: absolute;
            bottom: -2px;
            left: 0;
            width: 50px;
            height: 2px;
            background: #667eea;
        }}
        
        .section-content {{
            font-size: 1.1em;
            line-height: 1.8;
        }}
        
        .section-content p {{
            margin-bottom: 16px;
        }}
        
        .section-content strong {{
            color: #667eea;
            font-weight: 600;
            background: linear-gradient(135deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }}
        
        .section-content em {{
            color: #555;
            font-style: italic;
            background: #f8f9fa;
            padding: 2px 6px;
            border-radius: 4px;
        }}
        
        .content-paragraph {{
            margin-bottom: 18px;
            text-align: justify;
            line-height: 1.8;
        }}
        
        .styled-list {{
            margin: 20px 0;
            padding-left: 0;
            list-style: none;
        }}
        
        .styled-list li {{
            margin-bottom: 12px;
            padding-left: 30px;
            position: relative;
            line-height: 1.6;
        }}
        
        .styled-list li::before {{
            content: 'â–¸';
            position: absolute;
            left: 8px;
            color: #667eea;
            font-weight: bold;
            font-size: 1.1em;
        }}
        
        ol.styled-list li::before {{
            content: counter(item);
            counter-increment: item;
            background: #667eea;
            color: white;
            border-radius: 50%;
            width: 20px;
            height: 20px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 0.8em;
            font-weight: 600;
            left: 0;
        }}
        
        ol.styled-list {{
            counter-reset: item;
        }}
        
        .inline-code {{
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            padding: 3px 8px;
            border-radius: 6px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            font-weight: 500;
            white-space: nowrap;
        }}
        
        .section-divider {{
            margin: 30px 0;
            border: none;
            height: 2px;
            background: linear-gradient(135deg, transparent, #667eea, transparent);
            border-radius: 2px;
        }}
        
        .code-block {{
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
            overflow-x: auto;
        }}
        
        .table-container {{
            overflow-x: auto;
            margin: 20px 0;
        }}
        
        table {{
            width: 100%;
            border-collapse: collapse;
            background: white;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }}
        
        th, td {{
            padding: 15px;
            text-align: left;
            border-bottom: 1px solid #f1f3f4;
        }}
        
        th {{
            background: #667eea;
            color: white;
            font-weight: 600;
        }}
        
        tr:hover {{
            background: #f8f9fa;
        }}
        
        .conclusion {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            border-radius: 15px;
            margin: 40px 0;
            text-align: center;
        }}
        
        .conclusion h2 {{
            font-size: 1.8em;
            margin-bottom: 20px;
            color: white;
        }}
        
        .tags {{
            background: #f8f9fa;
            padding: 25px;
            border-radius: 15px;
            text-align: center;
            margin-top: 30px;
        }}
        
        .tag {{
            display: inline-block;
            background: #667eea;
            color: white;
            padding: 8px 16px;
            border-radius: 20px;
            margin: 5px;
            font-size: 0.9em;
            font-weight: 500;
        }}
        
        @media (max-width: 768px) {{
            .container {{
                margin: 10px;
                border-radius: 10px;
            }}
            
            .header {{
                padding: 40px 20px;
            }}
            
            .header h1 {{
                font-size: 2.2em;
            }}
            
            .content {{
                padding: 30px 20px;
            }}
            
            .section {{
                padding: 20px;
            }}
        }}
    </style>
</head>
<body>
    <div class="container">
        <header class="header">
            <h1>{generated_content['title']}</h1>
            <div class="meta-info">
                <span>ğŸ“… {datetime.now(KST).strftime('%Yë…„ %mì›” %dì¼')}</span>
                <span style="margin: 0 15px;">â€¢</span>
                <span>ğŸ”– {site_config.get('name', 'Blog').upper()}</span>
            </div>
        </header>
        
        <div class="content">
            <section class="introduction">
                <p>{generated_content['introduction']}</p>
            </section>
            
            <main>
{''.join([f'''
                <section class="section">
                    <h2>{section.get('heading', 'ì„¹ì…˜')}</h2>
                    <div class="section-content">
                        {_format_section_content(section.get('content', 'ë‚´ìš©'))}
                    </div>
                </section>
''' for section in generated_content.get('sections', [])])}
            </main>
            
            <footer>
                <section class="conclusion">
                    <h2>ë§ˆë¬´ë¦¬</h2>
                    <p>{generated_content.get('conclusion', generated_content.get('additional_content', 'ì´ìƒìœ¼ë¡œ ë§ˆë¬´ë¦¬í•˜ê² ìŠµë‹ˆë‹¤.'))}</p>
                </section>
                
                <div class="tags">
                    <strong style="display: block; margin-bottom: 15px; color: #667eea; font-size: 1.1em;">ğŸ·ï¸ ê´€ë ¨ íƒœê·¸</strong>
                    {''.join([f'<span class="tag">{tag}</span>' for tag in generated_content.get('tags', [])])}
                </div>
            </footer>
        </div>
    </div>
</body>
</html>
"""

def _format_section_content(content):
    """ì„¹ì…˜ ì½˜í…ì¸  í¬ë§·íŒ… - ì™„ì „ ê°œì„ """
    import re
    
    # 1. ë§ˆí¬ë‹¤ìš´ ë³¼ë“œì²´ ì²˜ë¦¬ (**text** -> <strong>text</strong>)
    content = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', content)
    
    # 2. ì´íƒ¤ë¦­ ì²˜ë¦¬ (*text* -> <em>text</em>)
    content = re.sub(r'\*([^*]+?)\*', r'<em>\1</em>', content)
    
    # 3. ì½”ë“œ ë¸”ë¡ ì²˜ë¦¬ (```ë¡œ ê°ì‹¸ì§„ ë¶€ë¶„)
    content = re.sub(r'```(\w+)?\n(.*?)\n```', r'<div class="code-block"><pre><code>\2</code></pre></div>', content, flags=re.DOTALL)
    content = re.sub(r'```(.*?)```', r'<div class="code-block"><pre><code>\1</code></pre></div>', content, flags=re.DOTALL)
    
    # 4. ì¸ë¼ì¸ ì½”ë“œ ì²˜ë¦¬ (`code` -> <code>code</code>)
    content = re.sub(r'`([^`]+?)`', r'<code class="inline-code">\1</code>', content)
    
    # 5. í…Œì´ë¸” ì²˜ë¦¬ ê°œì„ 
    if '<table>' in content:
        content = content.replace('<table>', '<div class="table-container"><table>')
        content = content.replace('</table>', '</table></div>')
    
    # 6. ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ì„ HTMLë¡œ ë³€í™˜
    lines = content.split('\n')
    in_table = False
    table_html = []
    processed_lines = []
    
    for line in lines:
        if '|' in line and line.strip():
            if not in_table:
                in_table = True
                table_html = ['<div class="table-container"><table>']
            
            # í—¤ë” êµ¬ë¶„ì„  ì²˜ë¦¬ (|---|---|)
            if re.match(r'^(\s*\|?\s*:?-+:?\s*\|)+\s*$', line):
                continue
                
            cells = [cell.strip() for cell in line.split('|') if cell.strip()]
            if cells:
                # ì²« ë²ˆì§¸ í…Œì´ë¸” í–‰ì¸ì§€ í™•ì¸ (ë‹¤ìŒ ì¤„ì´ êµ¬ë¶„ì„ ì¸ì§€ ì²´í¬)
                next_line_idx = lines.index(line) + 1
                is_header = (next_line_idx < len(lines) and 
                           re.match(r'^(\s*\|?\s*:?-+:?\s*\|)+\s*$', lines[next_line_idx]))
                
                if is_header:
                    row_html = '<tr>' + ''.join([f'<th>{cell}</th>' for cell in cells]) + '</tr>'
                else:
                    row_html = '<tr>' + ''.join([f'<td>{cell}</td>' for cell in cells]) + '</tr>'
                table_html.append(row_html)
        else:
            if in_table:
                table_html.append('</table></div>')
                processed_lines.extend(table_html)
                table_html = []
                in_table = False
            processed_lines.append(line)
    
    # í…Œì´ë¸”ì´ ëë‚˜ì§€ ì•Šì€ ê²½ìš° ì²˜ë¦¬
    if in_table:
        table_html.append('</table></div>')
        processed_lines.extend(table_html)
    
    content = '\n'.join(processed_lines)
    
    # 7. ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬ ê°œì„ 
    # ìˆœì„œ ì—†ëŠ” ë¦¬ìŠ¤íŠ¸ (- item)
    content = re.sub(r'^\s*[-*]\s+(.+)$', r'<li>\1</li>', content, flags=re.MULTILINE)
    # ì—°ì†ëœ li íƒœê·¸ë¥¼ ulë¡œ ê°ì‹¸ê¸°
    content = re.sub(r'(<li>.*?</li>\s*)+', lambda m: f'<ul class="styled-list">{m.group(0)}</ul>', content, flags=re.DOTALL)
    
    # ìˆœì„œ ìˆëŠ” ë¦¬ìŠ¤íŠ¸ (1. item)
    content = re.sub(r'^\s*\d+\.\s+(.+)$', r'<li>\1</li>', content, flags=re.MULTILINE)
    content = re.sub(r'(<li>.*?</li>\s*)+', lambda m: f'<ol class="styled-list">{m.group(0)}</ol>', content, flags=re.DOTALL)
    
    # 8. êµ¬ë¶„ì„  ì²˜ë¦¬ (---)
    content = re.sub(r'^---+\s*$', '<hr class="section-divider">', content, flags=re.MULTILINE)
    
    # 9. ë¬¸ë‹¨ êµ¬ë¶„ ê°œì„  - ì´ì¤‘ ì¤„ë°”ê¿ˆì„ ë¬¸ë‹¨ìœ¼ë¡œ ì²˜ë¦¬
    paragraphs = content.split('\n\n')
    formatted_paragraphs = []
    
    for paragraph in paragraphs:
        paragraph = paragraph.strip()
        if not paragraph:
            continue
            
        # HTML íƒœê·¸ë¡œ ì‹œì‘í•˜ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if paragraph.startswith(('<div', '<table', '<ul', '<ol', '<hr', '<h1', '<h2', '<h3', '<h4', '<h5', '<h6')):
            formatted_paragraphs.append(paragraph)
        else:
            # ì¼ë°˜ í…ìŠ¤íŠ¸ëŠ” p íƒœê·¸ë¡œ ê°ì‹¸ê¸°
            # ë‹¨ì¼ ì¤„ë°”ê¿ˆì€ <br>ë¡œ ë³€í™˜
            paragraph_html = paragraph.replace('\n', '<br>')
            formatted_paragraphs.append(f'<p class="content-paragraph">{paragraph_html}</p>')
    
    content = '\n\n'.join(formatted_paragraphs)
    
    # 10. ë¹ˆ íƒœê·¸ ì œê±°
    content = re.sub(r'<p[^>]*>\s*</p>', '', content)
    content = re.sub(r'<li>\s*</li>', '', content)
    
    return content

# Flask ì•± ì¸ìŠ¤í„´ìŠ¤ì— ë©”ì„œë“œ ì¶”ê°€
app._create_beautiful_html_template = _create_beautiful_html_template

# ìë™ ë°œí–‰ ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
scheduler = None

def auto_publish_task():
    """ë§¤ì¼ ìƒˆë²½ 3ì‹œ ìë™ ë°œí–‰ ì‘ì—… - ë‚ ì§œë³„ ìŠ¤ì¼€ì¤„ ê¸°ë°˜"""
    try:
        add_system_log('INFO', 'ğŸš€ ìë™ ë°œí–‰ ì‘ì—… ì‹œì‘ (ìƒˆë²½ 3ì‹œ)', 'SCHEDULER')
        logger.info("ğŸš€ ìƒˆë²½ 3ì‹œ ìë™ ë°œí–‰ ì‘ì—… ì‹œì‘")
        
        # ì‹œê°„ ê¸°ë¡
        from datetime import datetime, timedelta
        import pytz
        from src.scheduler import BlogAutomationScheduler
        kst = pytz.timezone('Asia/Seoul')
        start_time = datetime.now(kst)
        
        # BlogAutomationScheduler ì´ˆê¸°í™”
        blog_scheduler = BlogAutomationScheduler()
        
        # ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ë°˜ ìŠ¤ì¼€ì¤„ ê³„ì‚° (ìˆ˜ë™ ë°œí–‰ê³¼ ë™ì¼í•œ ë¡œì§)
        today = start_time.date()
        day_of_week_raw = today.weekday()  # 0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼
        if day_of_week_raw == 6:  # ì¼ìš”ì¼ì¸ ê²½ìš°
            week_start = today + timedelta(days=1)
            day_of_week = 6
        else:
            week_start = today - timedelta(days=day_of_week_raw)
            day_of_week = day_of_week_raw
        
        add_system_log('INFO', f'ë°œí–‰ ëŒ€ìƒ ë‚ ì§œ: {today} (ì£¼ì°¨: {week_start}, ìš”ì¼: {day_of_week})', 'SCHEDULER')
        
        # WordPress ì‚¬ì´íŠ¸ë“¤ ìë™ ë°œí–‰ (ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ í†µí•´ ê³„íšëœ ì£¼ì œ ì‚¬ìš©)
        wordpress_sites = ['unpre', 'untab', 'skewese']
        
        # ìŠ¤ì¼€ì¤„ ë°ì´í„° ë¡œë“œ
        from src.utils.schedule_manager import schedule_manager
        schedule_data = schedule_manager.get_weekly_schedule(week_start)
        
        # DB ì—°ê²° ì‹¤íŒ¨ì‹œ ëª©ì—… ìŠ¤ì¼€ì¤„ ë°ì´í„° ìƒì„±
        if not schedule_data or not schedule_data.get('schedule'):
            add_system_log('WARNING', 'DB ì—°ê²° ì‹¤íŒ¨ë¡œ ëª©ì—… ìŠ¤ì¼€ì¤„ ë°ì´í„° ì‚¬ìš©', 'SCHEDULER')
            schedule_data = {
                'week_start': week_start,
                'schedule': {}
            }
            
            # ì´ë²ˆ ì£¼ 7ì¼ê°„ ìŠ¤ì¼€ì¤„ ìƒì„±
            for day_idx in range(7):
                day_date = week_start + timedelta(days=day_idx)
                day_names = ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼']
                
                # ë‚ ì§œë³„ ë‹¤ì–‘í•œ ì£¼ì œ ìë™ ìƒì„±
                day_seed = day_date.toordinal()  # ë‚ ì§œë¥¼ ìˆ«ìë¡œ ë³€í™˜ (ì¼ê´€ì„± ìˆëŠ” ëœë¤ ì‹œë“œ)
                import random
                random.seed(day_seed)
                
                # ì‚¬ì´íŠ¸ë³„ ì£¼ì œ í’€
                unpre_topics = [
                    f"Python {day_date.year}ë…„ {day_date.month}ì›” ìµœì‹  ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ í”„ë ˆì„ì›Œí¬",
                    f"JavaScript ES6+ ê³ ê¸‰ ê¸°ëŠ¥ ì™„ë²½ ê°€ì´ë“œ ({day_date.month}/{day_date.day})",
                    f"React vs Vue.js ì„±ëŠ¥ ë¹„êµ ë¶„ì„ - {day_date.year}ë…„ ë²„ì „", 
                    f"Dockerì™€ Kubernetes ì‹¤ì „ í™œìš©ë²• {day_date.month}ì›” ì—…ë°ì´íŠ¸",
                    f"AI/ML ê°œë°œìë¥¼ ìœ„í•œ TensorFlow ìµœì‹  ê¸°ëŠ¥ ({day_date.day}ì¼ íŠ¹ì§‘)",
                    f"ì›¹ ê°œë°œ ë³´ì•ˆ ê°€ì´ë“œ - {day_date.year}.{day_date.month:02d} ë³´ì•ˆ íŒ¨ì¹˜",
                    f"í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ ê°œë°œ ì „ëµê³¼ ë„êµ¬ ({day_date.month}ì›” {day_date.day}ì¼)",
                    f"DevOps ìë™í™” íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ê°€ì´ë“œ - {day_date.year}ë…„ ìµœì‹ íŒ",
                    f"ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ ì„¤ê³„ íŒ¨í„´ ({day_date.month}/{day_date.day} ì—…ë°ì´íŠ¸)",
                    f"GraphQL vs REST API ì„ íƒ ê°€ì´ë“œ - {day_date.year}ë…„ {day_date.month}ì›” ê¸°ì¤€"
                ]
                
                untab_topics = [
                    f"{day_date.year}ë…„ {day_date.month}ì›” ë¶€ë™ì‚° ì‹œì¥ ì „ë§ê³¼ íˆ¬ì ì „ëµ",
                    f"ê²½ë§¤ ë¶€ë™ì‚° íˆ¬ì ê°€ì´ë“œ - {day_date.month}/{day_date.day} ì‹œì¥ ë¶„ì„",
                    f"ì„œìš¸ ì•„íŒŒíŠ¸ ê°€ê²© ë™í–¥ê³¼ ë¯¸ë˜ ì „ë§ ({day_date.year}.{day_date.month:02d})",
                    f"ë¶€ë™ì‚° ì •ì±… ë³€í™”ê°€ íˆ¬ìì— ë¯¸ì¹˜ëŠ” ì˜í–¥ - {day_date.month}ì›” {day_date.day}ì¼",
                    f"ì§€ë°© ë¶€ë™ì‚° íˆ¬ìì˜ ìƒˆë¡œìš´ ê¸°íšŒ ({day_date.year}ë…„ {day_date.month}ì›”)",
                    f"ë¶€ë™ì‚° í€ë“œ vs ì§ì ‘ íˆ¬ì ë¹„êµ ë¶„ì„ - {day_date.day}ì¼ íŠ¹ì§‘",
                    f"ìƒì—…ìš© ë¶€ë™ì‚° íˆ¬ì íŠ¸ë Œë“œì™€ ìˆ˜ìµë¥  ({day_date.month}/{day_date.day})",
                    f"ì¬ê°œë°œÂ·ì¬ê±´ì¶• íˆ¬ì ì „ëµ ê°€ì´ë“œ - {day_date.year}ë…„ ìƒë°˜ê¸°",
                    f"ë¶€ë™ì‚° ì„¸ê¸ˆ ì ˆì•½ ì „ëµê³¼ íŒ ({day_date.month}ì›” {day_date.day}ì¼ ë²„ì „)",
                    f"í•´ì™¸ ë¶€ë™ì‚° íˆ¬ì ê¸°íšŒì™€ ë¦¬ìŠ¤í¬ - {day_date.year}.{day_date.month:02d}"
                ]
                
                skewese_topics = [
                    f"ì¡°ì„ ì™•ì¡° {day_date.month}ì›”ì˜ ì—­ì‚¬ì  ì‚¬ê±´ë“¤ê³¼ ê·¸ ì˜ë¯¸",
                    f"ê³ êµ¬ë ¤ ë¬¸í™”ìœ ì‚° íƒë°©ê¸° - {day_date.year}ë…„ {day_date.month}ì›” {day_date.day}ì¼",
                    f"í•œêµ­ ì „í†µ ìŒì‹ì˜ ì—­ì‚¬ì™€ ìœ ë˜ ({day_date.month}/{day_date.day} íŠ¹ì§‘)",
                    f"ì¡°ì„ ì‹œëŒ€ ê³¼ê±°ì œë„ì™€ êµìœ¡ ì‹œìŠ¤í…œ - {day_date.year}ë…„ ì¬ì¡°ëª…",
                    f"ë°±ì œ ì—­ì‚¬ ì¬ë°œê²¬ - {day_date.month}ì›” {day_date.day}ì¼ ê³ ê³ í•™ ë‰´ìŠ¤",
                    f"í•œêµ­ì‚¬ ì† ì—¬ì„± ì¸ë¬¼ë“¤ì˜ ì‚¶ê³¼ ì—…ì  ({day_date.year}.{day_date.month:02d})",
                    f"ì¡°ì„  í›„ê¸° ë¬¸í™” ë¥´ë„¤ìƒìŠ¤ì™€ ì‹¤í•™ ì‚¬ìƒ - {day_date.month}/{day_date.day}",
                    f"ê³ ë ¤ì‹œëŒ€ ë¶ˆêµ ë¬¸í™”ì™€ ì˜ˆìˆ  ({day_date.year}ë…„ {day_date.month}ì›” ì—°êµ¬)",
                    f"í•œêµ­ ì „í†µ ê±´ì¶•ì˜ ê³¼í•™ì  ì›ë¦¬ - {day_date.day}ì¼ ê±´ì¶•ì‚¬ íƒêµ¬",
                    f"ì¡°ì„ ì™•ì¡°ì‹¤ë¡ì—ì„œ ì°¾ì€ í¥ë¯¸ë¡œìš´ ì´ì•¼ê¸°ë“¤ ({day_date.month}ì›”)"
                ]
                
                tistory_topics = [
                    f"{day_date.year}ë…„ {day_date.month}ì›” IT ì‚°ì—… ì£¼ìš” ë‰´ìŠ¤ì™€ íŠ¸ë Œë“œ",
                    f"AI ê¸°ìˆ  ë°œì „ì´ ì¼ìƒì— ë¯¸ì¹˜ëŠ” ì˜í–¥ - {day_date.month}/{day_date.day}",
                    f"ë©”íƒ€ë²„ìŠ¤ í”Œë«í¼ ìµœì‹  ë™í–¥ê³¼ ë¯¸ë˜ ({day_date.year}.{day_date.month:02d})",
                    f"ë¸”ë¡ì²´ì¸ê³¼ ì•”í˜¸í™”í ì‹œì¥ ë¶„ì„ - {day_date.month}ì›” {day_date.day}ì¼",
                    f"ìŠ¤ë§ˆíŠ¸í° ê¸°ìˆ  í˜ì‹ ê³¼ ì°¨ì„¸ëŒ€ ë””ë°”ì´ìŠ¤ ({day_date.year}ë…„ ì „ë§)",
                    f"5Gì™€ 6G í†µì‹  ê¸°ìˆ  ë°œì „ í˜„í™© - {day_date.day}ì¼ í†µì‹  ë‰´ìŠ¤",
                    f"í´ë¼ìš°ë“œ ì»´í“¨íŒ… ì‹œì¥ ë™í–¥ê³¼ ì „ë§ ({day_date.month}/{day_date.day})",
                    f"ê²Œì„ ì‚°ì—… íŠ¸ë Œë“œì™€ eìŠ¤í¬ì¸  ì„±ì¥ - {day_date.year}ë…„ {day_date.month}ì›”",
                    f"ììœ¨ì£¼í–‰ì°¨ ê¸°ìˆ  ë°œì „ê³¼ ìƒìš©í™” ì „ë§ ({day_date.month}ì›” ì—…ë°ì´íŠ¸)",
                    f"ìŠ¤íƒ€íŠ¸ì—… ìƒíƒœê³„ì™€ íˆ¬ì íŠ¸ë Œë“œ - {day_date.year}.{day_date.month:02d}"
                ]
                
                schedule_data['schedule'][day_idx] = {
                    'day_name': day_names[day_idx],
                    'date': day_date,
                    'sites': {
                        'unpre': {
                            'category': 'programming',
                            'topic': random.choice(unpre_topics),
                            'keywords': ['í”„ë¡œê·¸ë˜ë°', 'ê°œë°œ', 'IT', 'Python', 'JavaScript'],
                            'status': 'planned'
                        },
                        'untab': {
                            'category': 'realestate', 
                            'topic': random.choice(untab_topics),
                            'keywords': ['ë¶€ë™ì‚°', 'íˆ¬ì', 'ì•„íŒŒíŠ¸', 'ê²½ë§¤', 'ì •ì±…'],
                            'status': 'planned'
                        },
                        'skewese': {
                            'category': 'koreanhistory',
                            'topic': random.choice(skewese_topics),
                            'keywords': ['ì¡°ì„ ì‹œëŒ€', 'í•œêµ­ì‚¬', 'ì „í†µë¬¸í™”', 'ì—­ì‚¬', 'ë¬¸í™”ì¬'],
                            'status': 'planned'
                        },
                        'tistory': {
                            'category': 'current',
                            'topic': random.choice(tistory_topics),
                            'keywords': ['IT', 'ê¸°ìˆ ', 'íŠ¸ë Œë“œ', 'AI', 'ë‰´ìŠ¤'],
                            'status': 'planned'
                        }
                    }
                }
        
        add_system_log('INFO', f'ìŠ¤ì¼€ì¤„ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(schedule_data.get("schedule", {}))}ì¼', 'SCHEDULER')
        
        # ëª¨ë“  ì‚¬ì´íŠ¸ ìë™ ë°œí–‰ (WordPress 3ê°œ + tistory)
        sites_to_publish = ['unpre', 'untab', 'skewese', 'tistory']
        success_count = 0
        
        for site in sites_to_publish:
            try:
                add_system_log('INFO', f'{site.upper()} ë°œí–‰ ì‹œì‘...', 'SCHEDULER')
                # ìŠ¤ì¼€ì¤„ëŸ¬ì˜ create_and_publish_postëŠ” ìŠ¤ì¼€ì¤„ ë§¤ë‹ˆì €ë¥¼ í†µí•´ ì˜¤ëŠ˜ ì£¼ì œë¥¼ ê°€ì ¸ì˜´
                success = blog_scheduler.create_and_publish_post(site)
                if success:
                    success_count += 1
                    add_system_log('SUCCESS', f'âœ… {site.upper()} ìë™ ë°œí–‰ ì„±ê³µ', 'SCHEDULER')
                    logger.info(f"âœ… {site.upper()} ìë™ ë°œí–‰ ì„±ê³µ")
                else:
                    add_system_log('WARNING', f'âš ï¸ {site.upper()} ìë™ ë°œí–‰ ì‹¤íŒ¨', 'SCHEDULER')
                    logger.warning(f"âš ï¸ {site.upper()} ìë™ ë°œí–‰ ì‹¤íŒ¨")
                        
            except Exception as e:
                add_system_log('ERROR', f'âŒ {site.upper()} ë°œí–‰ ì˜¤ë¥˜: {str(e)}', 'SCHEDULER')
                logger.error(f"âŒ {site.upper()} ìë™ ë°œí–‰ ì˜¤ë¥˜: {e}")
        
        # ì‘ì—… ì™„ë£Œ í†µê³„
        end_time = datetime.now(kst)
        duration = (end_time - start_time).total_seconds()
        
        add_system_log('INFO', f'ğŸ“Š ìë™ ë°œí–‰ ì™„ë£Œ: {success_count}/{len(sites_to_publish)} ì„±ê³µ, ì†Œìš”ì‹œê°„: {duration:.1f}ì´ˆ', 'SCHEDULER')
        logger.info(f"âœ… ìƒˆë²½ 3ì‹œ ìë™ ë°œí–‰ ì‘ì—… ì™„ë£Œ ({success_count}/{len(sites_to_publish)} ì„±ê³µ)")
        
    except Exception as e:
        add_system_log('ERROR', f'âŒ ìë™ ë°œí–‰ ì‘ì—… ì‹¤íŒ¨: {str(e)}', 'SCHEDULER')
        logger.error(f"âŒ ìë™ ë°œí–‰ ì‘ì—… ì‹¤íŒ¨: {e}")

def init_scheduler():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™” ë° ì‹œì‘"""
    global scheduler
    
    try:
        # íƒ€ì„ì¡´ ëª…ì‹œì  ì„¤ì •
        from datetime import datetime
        import pytz
        kst = pytz.timezone('Asia/Seoul')
        
        scheduler = BackgroundScheduler(
            timezone=kst,
            job_defaults={'misfire_grace_time': 3600}  # 1ì‹œê°„ ì§€ì—°ê¹Œì§€ í—ˆìš©
        )
        
        # ë§¤ì¼ ìƒˆë²½ 3ì‹œì— ìë™ ë°œí–‰ (ì›”-ì¼ ë§¤ì¼)
        scheduler.add_job(
            func=auto_publish_task,
            trigger=CronTrigger(
                hour=3, 
                minute=0, 
                second=0,
                timezone=kst
            ),
            id='daily_auto_publish',
            name='Daily Auto Publishing at 3AM KST',
            replace_existing=True,
            max_instances=1,  # ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
            coalesce=True     # ëˆ„ë½ëœ ì‹¤í–‰ì„ í•˜ë‚˜ë¡œ í•©ì¹¨
        )
        
        # ì¶”ê°€ ì•ˆì „ì¥ì¹˜: ë§¤ì¼ ì˜¤ì „ 9ì‹œì—ë„ ì²´í¬ (ë°œí–‰ ì•ˆ ëœ ê²½ìš°)
        scheduler.add_job(
            func=check_and_retry_publish,
            trigger=CronTrigger(
                hour=9, 
                minute=0, 
                second=0,
                timezone=kst
            ),
            id='daily_check_publish',
            name='Daily Check and Retry at 9AM KST',
            replace_existing=True,
            max_instances=1
        )
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
        scheduler.start()
        
        # í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹œ ìŠ¤ì¼€ì¤„ëŸ¬ ì •ë¦¬
        atexit.register(lambda: scheduler.shutdown() if scheduler else None)
        
        # í˜„ì¬ ì‹œê°„ê³¼ ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ ë¡œê·¸
        now = datetime.now(kst)
        add_system_log('SUCCESS', f'ğŸ¯ ìë™ ë°œí–‰ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì™„ë£Œ! í˜„ì¬: {now.strftime("%Y-%m-%d %H:%M:%S")}', 'SCHEDULER')
        logger.info("âœ… ìë™ ë°œí–‰ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ë¨ (ë§¤ì¼ ìƒˆë²½ 3ì‹œ KST)")
        
        # ë“±ë¡ëœ ì‘ì—… ëª©ë¡ ë¡œê·¸
        jobs = scheduler.get_jobs()
        for job in jobs:
            next_run = job.next_run_time
            add_system_log('INFO', f'â° {job.name}: {next_run.strftime("%Y-%m-%d %H:%M:%S KST")}', 'SCHEDULER')
            logger.info(f"â° {job.name}: {next_run}")
        
        # ğŸ”¥ ë§¤ì£¼ ì¼ìš”ì¼ ë°¤ 11ì‹œ 30ë¶„ì— ë‹¤ìŒì£¼ ìˆ˜ìµì„± ìµœìš°ì„  ê³„íš ìë™ ìƒì„±
        def auto_generate_next_week_profit_plan():
            """ë‹¤ìŒì£¼ ìˆ˜ìµì„± ìµœìš°ì„  ì£¼ê°„ê³„íš ìë™ ìƒì„± - ì² ì €í•œ ì—ëŸ¬ ë°©ì§€"""
            try:
                add_system_log('INFO', 'ğŸ”¥ ë‹¤ìŒì£¼ ìˆ˜ìµì„± ìµœìš°ì„  ì£¼ê°„ê³„íš ìë™ ìƒì„± ì‹œì‘', 'WEEKLY_PLANNER')
                logger.info("ğŸ”¥ ë‹¤ìŒì£¼ ìˆ˜ìµì„± ìµœìš°ì„  ì£¼ê°„ê³„íš ìë™ ìƒì„± ì‹œì‘")
                
                # 1. ë‹¤ìŒì£¼ ì›”ìš”ì¼ ê³„ì‚° (ì—ëŸ¬ ë°©ì§€)
                try:
                    today = datetime.now(kst).date()
                    days_until_next_monday = (7 - today.weekday()) % 7
                    if days_until_next_monday == 0:  # ì˜¤ëŠ˜ì´ ì›”ìš”ì¼ì´ë©´ ë‹¤ë‹¤ìŒì£¼
                        days_until_next_monday = 7
                    next_monday = today + timedelta(days=days_until_next_monday)
                    
                    add_system_log('INFO', f'ë‹¤ìŒì£¼ ê³„íš ê¸°ì¤€ì¼: {next_monday}', 'WEEKLY_PLANNER')
                    logger.info(f"ë‹¤ìŒì£¼ ê³„íš ê¸°ì¤€ì¼: {next_monday}")
                except Exception as date_error:
                    add_system_log('ERROR', f'ë‚ ì§œ ê³„ì‚° ì‹¤íŒ¨: {date_error}', 'WEEKLY_PLANNER')
                    logger.error(f"ë‚ ì§œ ê³„ì‚° ì‹¤íŒ¨: {date_error}")
                    return
                
                # 2. ê¸°ì¡´ ë‹¤ìŒì£¼ ê³„íš ì²´í¬ (ì¤‘ë³µ ë°©ì§€)
                try:
                    from src.utils.postgresql_database import PostgreSQLDatabase
                    db = PostgreSQLDatabase()
                    conn = db.get_connection()
                    
                    with conn.cursor() as cursor:
                        cursor.execute('''
                        SELECT id FROM blog_automation.weekly_plans 
                        WHERE week_start = %s
                        ''', (next_monday,))
                        
                        existing_plan = cursor.fetchone()
                        if existing_plan:
                            add_system_log('INFO', f'ë‹¤ìŒì£¼ ê³„íšì´ ì´ë¯¸ ì¡´ì¬í•¨: {next_monday}', 'WEEKLY_PLANNER')
                            logger.info(f"ë‹¤ìŒì£¼ ê³„íšì´ ì´ë¯¸ ì¡´ì¬í•¨: {next_monday}")
                            return  # ì´ë¯¸ ìˆìœ¼ë©´ ìƒì„±í•˜ì§€ ì•ŠìŒ
                            
                except Exception as db_check_error:
                    add_system_log('WARNING', f'ê¸°ì¡´ ê³„íš ì²´í¬ ì‹¤íŒ¨, ê³„ì† ì§„í–‰: {db_check_error}', 'WEEKLY_PLANNER')
                    logger.warning(f"ê¸°ì¡´ ê³„íš ì²´í¬ ì‹¤íŒ¨, ê³„ì† ì§„í–‰: {db_check_error}")
                
                # 3. ìˆ˜ìµì„± ìµœìš°ì„  ì£¼ê°„ê³„íš ìƒì„± (ì•ˆì „í•œ subprocess ì‹¤í–‰)
                try:
                    import subprocess
                    import sys
                    
                    # subprocessë¡œ ì•ˆì „í•˜ê²Œ ì‹¤í–‰ (timeout ì„¤ì •)
                    result = subprocess.run(
                        [sys.executable, 'auto_weekly_planner.py'],
                        cwd=os.path.dirname(os.path.abspath(__file__)),
                        capture_output=True,
                        text=True,
                        timeout=300,  # 5ë¶„ timeout
                        encoding='utf-8'
                    )
                    
                    if result.returncode == 0:
                        add_system_log('SUCCESS', 'ğŸ‰ ë‹¤ìŒì£¼ ìˆ˜ìµì„± ìµœìš°ì„  ì£¼ê°„ê³„íš ìë™ ìƒì„± ì™„ë£Œ!', 'WEEKLY_PLANNER')
                        logger.info("ğŸ‰ ë‹¤ìŒì£¼ ìˆ˜ìµì„± ìµœìš°ì„  ì£¼ê°„ê³„íš ìë™ ìƒì„± ì™„ë£Œ!")
                        
                        # ì„±ê³µ ë¡œê·¸ì— ê²°ê³¼ ìš”ì•½ í¬í•¨
                        output_lines = result.stdout.split('\n')[-10:]  # ë§ˆì§€ë§‰ 10ì¤„ë§Œ
                        for line in output_lines:
                            if line.strip():
                                add_system_log('INFO', f'ìƒì„±ê²°ê³¼: {line.strip()}', 'WEEKLY_PLANNER')
                    else:
                        add_system_log('ERROR', f'ì£¼ê°„ê³„íš ìƒì„± ì‹¤íŒ¨ (exit code: {result.returncode})', 'WEEKLY_PLANNER')
                        add_system_log('ERROR', f'stderr: {result.stderr}', 'WEEKLY_PLANNER')
                        logger.error(f"ì£¼ê°„ê³„íš ìƒì„± ì‹¤íŒ¨: {result.stderr}")
                        
                except subprocess.TimeoutExpired:
                    add_system_log('ERROR', 'ì£¼ê°„ê³„íš ìƒì„± íƒ€ì„ì•„ì›ƒ (5ë¶„)', 'WEEKLY_PLANNER')
                    logger.error("ì£¼ê°„ê³„íš ìƒì„± íƒ€ì„ì•„ì›ƒ")
                except Exception as subprocess_error:
                    add_system_log('ERROR', f'ì£¼ê°„ê³„íš ìƒì„± í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {subprocess_error}', 'WEEKLY_PLANNER')
                    logger.error(f"ì£¼ê°„ê³„íš ìƒì„± í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {subprocess_error}")
                
                # 4. ìƒì„± ì™„ë£Œ í›„ ê²€ì¦
                try:
                    time.sleep(2)  # ì ê¹ ëŒ€ê¸°
                    with conn.cursor() as cursor:
                        cursor.execute('''
                        SELECT plan_data FROM blog_automation.weekly_plans 
                        WHERE week_start = %s
                        ORDER BY created_at DESC LIMIT 1
                        ''', (next_monday,))
                        
                        new_plan = cursor.fetchone()
                        if new_plan:
                            plan_data = json.loads(new_plan[0])
                            plan_count = len(plan_data.get('plans', []))
                            add_system_log('SUCCESS', f'âœ… ìƒì„± ê²€ì¦ ì™„ë£Œ: {plan_count}ê°œ ê³„íš ì €ì¥ë¨', 'WEEKLY_PLANNER')
                            logger.info(f"âœ… ìƒì„± ê²€ì¦ ì™„ë£Œ: {plan_count}ê°œ ê³„íš")
                        else:
                            add_system_log('WARNING', 'âš ï¸ ê³„íš ìƒì„± í›„ DBì—ì„œ í™•ì¸ë˜ì§€ ì•ŠìŒ', 'WEEKLY_PLANNER')
                            
                except Exception as verify_error:
                    add_system_log('WARNING', f'ìƒì„± ê²€ì¦ ì‹¤íŒ¨: {verify_error}', 'WEEKLY_PLANNER')
                    
            except Exception as main_error:
                add_system_log('ERROR', f'ì£¼ê°„ê³„íš ìë™ìƒì„± ë©”ì¸ ì—ëŸ¬: {main_error}', 'WEEKLY_PLANNER')
                logger.error(f"ì£¼ê°„ê³„íš ìë™ìƒì„± ë©”ì¸ ì—ëŸ¬: {main_error}")
            finally:
                add_system_log('INFO', 'ë‹¤ìŒì£¼ ì£¼ê°„ê³„íš ìë™ìƒì„± ì‘ì—… ì¢…ë£Œ', 'WEEKLY_PLANNER')
        
        # ë§¤ì£¼ ì¼ìš”ì¼ ë°¤ 11ì‹œ 30ë¶„ì— ë‹¤ìŒì£¼ ê³„íš ìƒì„±
        scheduler.add_job(
            func=auto_generate_next_week_profit_plan,
            trigger=CronTrigger(
                day_of_week=6,  # ì¼ìš”ì¼ (0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼)
                hour=23,
                minute=30,
                second=0,
                timezone=kst
            ),
            id='weekly_plan_auto_generate',
            name='Next Week Profit-First Plan Auto Generator',
            replace_existing=True,
            max_instances=1,  # ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
            coalesce=True     # ëˆ„ë½ëœ ì‹¤í–‰ì„ í•˜ë‚˜ë¡œ í•©ì¹¨
        )
        
        # í…ŒìŠ¤íŠ¸ìš© ì¦‰ì‹œ ì‹¤í–‰ (ì²« ì‹œì‘ ì‹œì—ë§Œ)
        from datetime import timedelta
        add_system_log('INFO', 'ğŸ”§ ìŠ¤ì¼€ì¤„ëŸ¬ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 30ì´ˆ í›„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜ˆì•½', 'SCHEDULER')
        scheduler.add_job(
            func=test_scheduler_health,
            trigger='date',
            run_date=datetime.now(kst) + timedelta(seconds=30),
            id='scheduler_test',
            name='Scheduler Health Test'
        )
        
        return True
        
    except Exception as e:
        add_system_log('ERROR', f'âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}', 'SCHEDULER')
        logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def check_and_retry_publish():
    """ì˜¤ì „ 9ì‹œ ì²´í¬: ìƒˆë²½ 3ì‹œì— ë°œí–‰ë˜ì§€ ì•Šì€ ê²½ìš° ì¬ì‹œë„"""
    try:
        from datetime import datetime, timedelta
        import pytz
        kst = pytz.timezone('Asia/Seoul')
        
        today = datetime.now(kst).date()
        today_3am = datetime.combine(today, datetime.min.time().replace(hour=3)).replace(tzinfo=kst)
        
        add_system_log('INFO', 'ğŸ” ì˜¤ì „ 9ì‹œ ë°œí–‰ ìƒíƒœ ì²´í¬ ì‹œì‘', 'SCHEDULER')
        
        # ì˜¤ëŠ˜ ìƒˆë²½ 3ì‹œ ì´í›„ ë°œí–‰ëœ ê²Œì‹œë¬¼ í™•ì¸
        db = get_database()
        sites_to_retry = []
        
        for site in ['unpre', 'untab', 'skewese']:
            recent_posts = db.get_recent_posts(site, 1)
            
            if not recent_posts:
                sites_to_retry.append(site)
                add_system_log('WARNING', f'{site.upper()}: ì˜¤ëŠ˜ ë°œí–‰ëœ ê²Œì‹œë¬¼ ì—†ìŒ', 'SCHEDULER')
            else:
                last_post_time = recent_posts[0].get('created_at')
                if last_post_time:
                    # ë‚ ì§œ ë¬¸ìì—´ì„ datetimeìœ¼ë¡œ ë³€í™˜
                    if isinstance(last_post_time, str):
                        last_post_dt = datetime.fromisoformat(last_post_time.replace('Z', '+00:00'))
                        if last_post_dt.tzinfo is None:
                            last_post_dt = last_post_dt.replace(tzinfo=kst)
                    else:
                        last_post_dt = last_post_time
                    
                    if last_post_dt < today_3am:
                        sites_to_retry.append(site)
                        add_system_log('WARNING', f'{site.upper()}: ë§ˆì§€ë§‰ ë°œí–‰ì´ ìƒˆë²½ 3ì‹œ ì´ì „', 'SCHEDULER')
                    else:
                        add_system_log('SUCCESS', f'{site.upper()}: ì˜¤ëŠ˜ ì •ìƒ ë°œí–‰ë¨', 'SCHEDULER')
        
        # ì¬ì‹œë„ê°€ í•„ìš”í•œ ì‚¬ì´íŠ¸ë“¤ ë°œí–‰
        if sites_to_retry:
            add_system_log('INFO', f'ğŸ”„ ì¬ì‹œë„ ë°œí–‰ ì‹œì‘: {", ".join(sites_to_retry)}', 'SCHEDULER')
            
            from src.scheduler import BlogAutomationScheduler
            blog_scheduler = BlogAutomationScheduler()
            
            for site in sites_to_retry:
                try:
                    success = blog_scheduler.create_and_publish_post(site)
                    if success:
                        add_system_log('SUCCESS', f'âœ… {site.upper()} ì¬ì‹œë„ ë°œí–‰ ì„±ê³µ', 'SCHEDULER')
                    else:
                        add_system_log('ERROR', f'âŒ {site.upper()} ì¬ì‹œë„ ë°œí–‰ ì‹¤íŒ¨', 'SCHEDULER')
                except Exception as e:
                    add_system_log('ERROR', f'âŒ {site.upper()} ì¬ì‹œë„ ì˜¤ë¥˜: {str(e)}', 'SCHEDULER')
        else:
            add_system_log('SUCCESS', 'âœ… ëª¨ë“  ì‚¬ì´íŠ¸ ì •ìƒ ë°œí–‰ í™•ì¸ë¨', 'SCHEDULER')
            
    except Exception as e:
        add_system_log('ERROR', f'âŒ ë°œí–‰ ìƒíƒœ ì²´í¬ ì‹¤íŒ¨: {str(e)}', 'SCHEDULER')

def test_scheduler_health():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ í…ŒìŠ¤íŠ¸"""
    try:
        from datetime import datetime
        import pytz
        kst = pytz.timezone('Asia/Seoul')
        now = datetime.now(kst)
        
        add_system_log('SUCCESS', f'âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ì •ìƒ ì‘ë™ ì¤‘! í…ŒìŠ¤íŠ¸ ì‹œê°„: {now.strftime("%H:%M:%S")}', 'SCHEDULER')
        logger.info(f"âœ… ìŠ¤ì¼€ì¤„ëŸ¬ í—¬ìŠ¤ ì²´í¬ ì„±ê³µ: {now}")
        
        # ë‹¤ìŒ ì˜ˆì • ì‘ì—…ë“¤ í™•ì¸
        global scheduler
        if scheduler:
            jobs = scheduler.get_jobs()
            add_system_log('INFO', f'ğŸ“‹ ë“±ë¡ëœ ì‘ì—… ìˆ˜: {len(jobs)}ê°œ', 'SCHEDULER')
            for job in jobs:
                if job.next_run_time:
                    add_system_log('INFO', f'  - {job.name}: {job.next_run_time.strftime("%m/%d %H:%M")}', 'SCHEDULER')
        
    except Exception as e:
        add_system_log('ERROR', f'âŒ ìŠ¤ì¼€ì¤„ëŸ¬ í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨: {str(e)}', 'SCHEDULER')


def generate_dynamic_schedule(start_date):
    """ì£¼ì°¨ë³„ë¡œ ë™ì  ìŠ¤ì¼€ì¤„ ìƒì„± (ì£¼ì°¨ë³„ ë‹¤ë¥¸ ì‹œë“œ ì‚¬ìš©)"""
    import random
    from datetime import timedelta
    
    # ì£¼ì°¨ë³„ ê³ ìœ  ì‹œë“œ ìƒì„± (start_date ê¸°ì¤€)
    week_seed = start_date.toordinal()
    random.seed(week_seed)
    
    # ì‚¬ì´íŠ¸ë³„ ì£¼ì œ í’€
    unpre_topics = [
        "JWT í† í° ê¸°ë°˜ ì‹œíë¦¬í‹° êµ¬í˜„", "DDD(ë„ë©”ì¸ ì£¼ë„ ì„¤ê³„) ì‹¤ì „ ì ìš©", "C++ ìµœì‹  í”„ë¡œê·¸ë˜ë° ê¸°ë²•",
        "Kotlinìœ¼ë¡œ Android ì•± ê°œë°œ", "Python ë°ì´í„° ë¶„ì„ ë§ˆìŠ¤í„°", "React Hook ê³ ê¸‰ í™œìš©ë²•",
        "Docker ì»¨í…Œì´ë„ˆ ìµœì í™”", "Spring Boot ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤", "GraphQL API ì„¤ê³„ ì›ì¹™"
    ]
    
    untab_topics = [
        "ì¹œí™˜ê²½ ë¶€ë™ì‚° ê·¸ë¦° ë¦¬ëª¨ë¸ë§ íŠ¸ë Œë“œ", "ê³ ë ¹í™” ì‚¬íšŒì™€ ì‹¤ë²„íƒ€ìš´ íˆ¬ì", "ì¸í”Œë ˆì´ì…˜ ì‹œëŒ€ì˜ íˆ¬ì ê°€ì´ë“œ",
        "ê³µëª¨ì£¼ íˆ¬ì ì „ëµ ë¶„ì„", "ë©”íƒ€ë²„ìŠ¤ ë¶€ë™ì‚° íˆ¬ì", "ESG íˆ¬ìì˜ ë¯¸ë˜ ì „ë§",
        "ë¶€ë™ì‚° ê²½ë§¤ íˆ¬ìì˜ ìƒˆë¡œìš´ ê¸°íšŒ", "ì•”í˜¸í™”íì™€ ì „í†µ ìì‚° í¬íŠ¸í´ë¦¬ì˜¤"
    ]
    
    skewese_topics = [
        "ì¡°ì„ ì‹œëŒ€ ê³¼í•™ê¸°ìˆ ì˜ ë°œì „ê³¼ ì—­ì‚¬", "ìˆ˜ë©´ì˜ ê³¼í•™ê³¼ ì§ˆ ì¢‹ì€ ì ìë¦¬", "ì‹ ë¼ í†µì¼ì˜ ê³¼ì •ê³¼ ì—­ì‚¬ì  ì˜ë¯¸",
        "ê³ ë ¤ ëª½ê³¨ ì¹¨ì…ê³¼ ê°•í™”ë„ í•­ìŸ", "4.19í˜ëª…ê³¼ ë¯¼ì£¼ì£¼ì˜ ë°œì „", "ì„ì§„ì™œë€ê³¼ ì´ìˆœì‹ ì˜ í™œì•½",
        "í•œêµ­ ì „í†µ ê±´ì¶•ì˜ ì•„ë¦„ë‹¤ì›€ê³¼ ê³¼í•™", "ì •ì¡°ì˜ ê°œí˜ ì •ì¹˜ì™€ í™”ì„± ê±´ì„¤"
    ]
    
    tistory_topics = [
        "2025ë…„ ChatGPT-5ì™€ ì°¨ì„¸ëŒ€ AI í˜ì‹ ", "ì¬ê±´ì¶• ê·œì œ ì™„í™”, ì‹œì¥ ë³€í™” ì˜ˆìƒ", "MZì„¸ëŒ€ íˆ¬ì íŒ¨í„´ ë¶„ì„, ë¶€ì‘ìš©ì€?",
        "ì¸í”Œë ˆì´ì…˜ ì¬ë¶€ìƒ? 2025ë…„ ì „ë§", "2026 ì›”ë“œì»µ ê³µë™ê°œìµœ, í•œêµ­ ì¶•êµ¬ ì¬ë„ì•½", "K-ë¬¸í™” ê¸€ë¡œë²Œ í™•ì‚° í˜„í™©",
        "ë¹„íŠ¸ì½”ì¸ 10ë§Œë‹¬ëŸ¬ ëŒíŒŒ í›„ ì „ë§", "ì €ì¶œì‚° ëŒ€ì±… ì‹¤íš¨ì„± ë…¼ë€"
    ]
    
    site_topics = {
        'unpre': unpre_topics,
        'untab': untab_topics, 
        'skewese': skewese_topics,
        'tistory': tistory_topics
    }
    
    schedule = {}
    day_names = ['ì¼ìš”ì¼', 'ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼']
    
    for day in range(7):
        schedule[day] = {
            'day_name': day_names[day],
            'date': start_date + timedelta(days=day),
            'sites': {}
        }
        
        for site, topics in site_topics.items():
            # ì£¼ì°¨+ìš”ì¼+ì‚¬ì´íŠ¸ë³„ ê³ ìœ  ì¸ë±ìŠ¤ ê³„ì‚°
            topic_index = (week_seed + day * 10 + hash(site)) % len(topics)
            topic = topics[topic_index]
            
            schedule[day]['sites'][site] = {
                'category': 'programming' if site == 'unpre' else 
                           'realestate' if site == 'untab' else
                           'koreanhistory' if site == 'skewese' else 'current',
                'topic': topic,
                'keywords': [site, topic.split()[0]],
                'length': 'long' if len(topic) > 20 else 'medium',
                'status': 'planned',
                'url': None
            }
    
    return {
        'week_start': start_date,
        'schedule': schedule
    }


# ëˆ„ë½ëœ API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€

@app.route('/api/weekly-plan/current')
def get_current_weekly_plan():
    """í˜„ì¬ ì£¼ê°„ ê³„íší‘œ ì¡°íšŒ"""
    try:
        from datetime import datetime, timedelta
        import json
        
        # í˜„ì¬ ì£¼ì˜ ì›”ìš”ì¼ êµ¬í•˜ê¸°
        today = datetime.now().date()
        days_since_monday = today.weekday()
        week_start = today - timedelta(days=days_since_monday)
        
        database = get_database()
        conn = database.get_connection()
        
        with conn.cursor() as cursor:
            cursor.execute('''
            SELECT plan_data FROM blog_automation.weekly_plans 
            WHERE week_start = %s
            ORDER BY created_at DESC
            LIMIT 1
            ''', (week_start,))
            
            result = cursor.fetchone()
            
            if result:
                plan_data = result[0]  # JSONB ë°ì´í„°
                return jsonify({
                    'success': True,
                    'data': plan_data
                })
            else:
                # ì£¼ê°„ê³„íšì´ ì—†ìœ¼ë©´ ë¹ˆ ë°ì´í„° ë°˜í™˜
                return jsonify({
                    'success': True,
                    'data': {
                        'week_start': week_start.strftime('%Y-%m-%d'),
                        'week_end': (week_start + timedelta(days=6)).strftime('%Y-%m-%d'),
                        'plans': [],
                        'message': 'ì£¼ê°„ê³„íšì´ ì—†ìŠµë‹ˆë‹¤. ìë™ ìƒì„±ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.'
                    }
                })
                
    except Exception as e:
        logger.error(f"ì£¼ê°„ê³„íš ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/manual-publish/preview')
def get_manual_publish_preview():
    """ìˆ˜ë™ ë°œí–‰ ë¯¸ë¦¬ë³´ê¸° - ì˜¤ëŠ˜ ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” ì£¼ê°„ê³„íš ì£¼ì œ í‘œì‹œ"""
    try:
        from datetime import datetime, date, timedelta
        import json
        
        today = date.today()
        today_str = today.strftime('%Y-%m-%d')
        
        # ì˜¤ëŠ˜ ë‚ ì§œì˜ ì£¼ê°„ê³„íš ì¡°íšŒ
        database = get_database()
        conn = database.get_connection()
        
        with conn.cursor() as cursor:
            # í˜„ì¬ ì£¼ì˜ ì›”ìš”ì¼ ê³„ì‚°
            days_since_monday = today.weekday()
            week_start = today - timedelta(days=days_since_monday)
            
            cursor.execute('''
            SELECT plan_data FROM blog_automation.weekly_plans 
            WHERE week_start = %s
            ORDER BY created_at DESC
            LIMIT 1
            ''', (week_start,))
            
            result = cursor.fetchone()
            today_contents = []
            
            if result:
                plan_data = result[0]  # JSONB ë°ì´í„°
                plans = plan_data.get('plans', [])
                
                # ì˜¤ëŠ˜ ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” ê³„íšë“¤ í•„í„°ë§
                today_plans = [plan for plan in plans if plan.get('date') == today_str]
                
                for plan in today_plans:
                    today_contents.append({
                        'site': plan.get('site'),
                        'title': plan.get('title'),
                        'category': plan.get('category'),
                        'priority': plan.get('priority'),
                        'trend_score': plan.get('trend_score'),
                        'keywords': plan.get('keywords', []),
                        'source': plan.get('source'),
                        'original_topic': plan.get('original_topic'),
                        'status': 'ready_to_publish'
                    })
            
            # ê¸°ë³¸ ì‚¬ì´íŠ¸ ëª©ë¡
            available_sites = ['unpre', 'untab', 'skewese', 'tistory']
            
            # ì˜¤ëŠ˜ ê³„íšì´ ì—†ëŠ” ì‚¬ì´íŠ¸ë“¤ì„ ìœ„í•œ ëŒ€ì²´ ì£¼ì œ
            planned_sites = [content['site'] for content in today_contents]
            for site in available_sites:
                if site not in planned_sites:
                    # ëŒ€ì²´ ì£¼ì œ ì¶”ê°€
                    today_contents.append({
                        'site': site,
                        'title': f'ì˜¤ëŠ˜ì˜ {site.upper()} ì¶”ì²œ ì£¼ì œ',
                        'category': 'ì¼ë°˜',
                        'priority': 'medium',
                        'trend_score': 50,
                        'keywords': ['ì˜¤ëŠ˜', 'ì¶”ì²œ', 'ì£¼ì œ'],
                        'source': 'ìë™ìƒì„±',
                        'original_topic': 'ì¼ë°˜ ì£¼ì œ',
                        'status': 'fallback'
                    })
            
            return jsonify({
                'success': True,
                'data': {
                    'date': today_str,
                    'available_sites': available_sites,
                    'contents': today_contents,
                    'total_plans': len(today_contents)
                }
            })
                
    except Exception as e:
        logger.error(f"ìˆ˜ë™ ë°œí–‰ ë¯¸ë¦¬ë³´ê¸° ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False, 
            'error': str(e),
            'data': {
                'available_sites': ['unpre', 'untab', 'skewese', 'tistory'],
                'contents': []
            }
        }), 500

@app.route('/api/trends/realtime')
def get_realtime_trends():
    """ì‹¤ì‹œê°„ íŠ¸ë Œë“œ"""
    try:
        return jsonify({
            'success': True,
            'data': {
                'trends': [],
                'last_updated': '2025-09-08 11:19:49'
            }
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/weekly-plan/generate', methods=['POST'])
def generate_weekly_plan():
    """ì£¼ê°„ê³„íš ìë™ ìƒì„±"""
    try:
        import subprocess
        import sys
        
        # ìë™ ì£¼ê°„ê³„íš ìƒì„±ê¸° ì‹¤í–‰
        result = subprocess.run(
            [sys.executable, 'auto_weekly_planner.py'],
            capture_output=True,
            text=True,
            encoding='utf-8',
            errors='ignore'
        )
        
        if result.returncode == 0:
            return jsonify({
                'success': True,
                'message': 'ì£¼ê°„ê³„íšì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.',
                'output': result.stdout
            })
        else:
            return jsonify({
                'success': False,
                'error': f'ì£¼ê°„ê³„íš ìƒì„± ì‹¤íŒ¨: {result.stderr}',
                'output': result.stdout
            }), 500
            
    except Exception as e:
        logger.error(f"ì£¼ê°„ê³„íš ìƒì„± ì˜¤ë¥˜: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

# ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™” (ì•± ì‹œì‘ ì‹œ)
scheduler_initialized = init_scheduler()

if __name__ == "__main__":
    # ì‹œì‘ ë¡œê·¸
    add_system_log('INFO', 'ë¸”ë¡œê·¸ ìë™í™” ì‹œìŠ¤í…œ ì‹œì‘', 'STARTUP')
    add_system_log('INFO', 'ìƒˆë²½ 3ì‹œ ìë™ë°œí–‰ ìŠ¤ì¼€ì¤„ í™œì„±í™”ë¨', 'STARTUP')
    add_system_log('INFO', f'ì›¹ ëŒ€ì‹œë³´ë“œ ì„œë²„ ì‹œì‘ - http://localhost:8000', 'STARTUP')
    
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port, debug=False)