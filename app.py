"""
Koyeb ë°°í¬ìš© ì›¹ ì„œë²„ ì•±
"""

import os
import sys
from pathlib import Path
from flask import Flask, render_template, jsonify, request, send_file, make_response
from flask_cors import CORS
from datetime import datetime, timedelta
import pytz
import json
import logging
from dotenv import load_dotenv
import psycopg2
from psycopg2.extras import RealDictCursor

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Flask ì•± ìƒì„±
app = Flask(__name__, 
            template_folder='templates',
            static_folder='static',
            static_url_path='/static')  # ì •ì  íŒŒì¼ ê²½ë¡œ ëª…ì‹œ
CORS(app)

# í…œí”Œë¦¿ ìºì‹± ë¹„í™œì„±í™”
app.config['TEMPLATES_AUTO_RELOAD'] = True
app.jinja_env.auto_reload = True

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
KST = pytz.timezone('Asia/Seoul')

# ëª©ì—… ë°ì´í„° ì €ì¥ìš© ë³€ìˆ˜
mock_wordpress_files = []
mock_tistory_files = []

# PostgreSQL ì—°ê²° í•¨ìˆ˜
def get_db_connection():
    """PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
    try:
        conn = psycopg2.connect(
            host=os.getenv('PG_HOST'),
            port=os.getenv('PG_PORT', 5432),
            database=os.getenv('PG_DATABASE'),
            user=os.getenv('PG_USER'),
            password=os.getenv('PG_PASSWORD'),
            options=f"-c search_path={os.getenv('PG_SCHEMA', 'unble')}"
        )
        return conn
    except Exception as e:
        logger.error(f"Database connection failed: {e}")
        return None

def get_mock_data():
    """DB ì—°ê²° ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ëª©ì—… ë°ì´í„°"""
    now = datetime.now(KST)
    today_3am = now.replace(hour=3, minute=0, second=0, microsecond=0)
    
    # ì˜¤ëŠ˜ ìƒˆë²½ 3ì‹œì— ìë™ë°œí–‰ëœ í¬ìŠ¤íŠ¸ë“¤ ìƒì„±
    posts = []
    
    # ì˜¤ëŠ˜ ìë™ë°œí–‰ëœ í¬ìŠ¤íŠ¸ë“¤ (ìƒˆë²½ 3ì‹œ ì´í›„ë¼ë©´)
    if now >= today_3am:
        posts.extend([
            {
                'id': 1,
                'title': 'ğŸ¤– AI ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ìµœì‹  ë™í–¥',
                'site': 'unpre',
                'category': 'AI/í”„ë¡œê·¸ë˜ë°',
                'url': 'https://unpre.co.kr/ai-coding-assistant-2025',
                'created_at': today_3am.strftime('%Y-%m-%d %H:%M:%S'),
                'published': True
            },
            {
                'id': 2,
                'title': 'ğŸ“š íš¨ìœ¨ì ì¸ ì–¸ì–´í•™ìŠµì„ ìœ„í•œ 5ê°€ì§€ ë°©ë²•',
                'site': 'untab',
                'category': 'êµìœ¡/ì–¸ì–´í•™ìŠµ',
                'url': 'https://untab.co.kr/language-learning-tips-2025',
                'created_at': today_3am.strftime('%Y-%m-%d %H:%M:%S'),
                'published': True
            },
            {
                'id': 3,
                'title': 'ğŸ›ï¸ ì¡°ì„ ì‹œëŒ€ ê³¼í•™ê¸°ìˆ ì˜ ë†€ë¼ìš´ ë°œì „',
                'site': 'skewese',
                'category': 'ì—­ì‚¬/ë¬¸í™”',
                'url': 'https://skewese.com/joseon-science-technology',
                'created_at': today_3am.strftime('%Y-%m-%d %H:%M:%S'),
                'published': True
            }
        ])
    
    # ì–´ì œ ë°œí–‰ëœ í¬ìŠ¤íŠ¸ë“¤
    yesterday_3am = today_3am - timedelta(days=1)
    posts.extend([
        {
            'id': 4,
            'title': 'React 18ì˜ ìƒˆë¡œìš´ ê¸°ëŠ¥ë“¤',
            'site': 'unpre',
            'category': 'í”„ë¡œê·¸ë˜ë°',
            'url': 'https://unpre.co.kr/react-18-features',
            'created_at': yesterday_3am.strftime('%Y-%m-%d %H:%M:%S'),
            'published': True
        },
        {
            'id': 5,
            'title': 'ë¶€ë™ì‚° íˆ¬ì ì „ëµ ê°€ì´ë“œ',
            'site': 'untab',
            'category': 'ë¶€ë™ì‚°',
            'url': 'https://untab.co.kr/real-estate-investment',
            'created_at': yesterday_3am.strftime('%Y-%m-%d %H:%M:%S'),
            'published': True
        }
    ])
    
    today_posts = len([p for p in posts if p['created_at'].startswith(now.strftime('%Y-%m-%d'))])
    
    return {
        'posts': posts,
        'stats': {
            'total_posts': len(posts),
            'published': len(posts),
            'scheduled': 0,
            'today_posts': today_posts
        }
    }

@app.route('/')
def dashboard():
    """ë©”ì¸ ëŒ€ì‹œë³´ë“œ í˜ì´ì§€"""
    response = make_response(render_template('dashboard.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/api/recent_posts')
def get_recent_posts():
    """ìµœê·¼ í¬ìŠ¤íŠ¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        conn = get_db_connection()
        if conn:
            cursor = conn.cursor(cursor_factory=RealDictCursor)
            
            # ê° ì‚¬ì´íŠ¸ì—ì„œ ìµœê·¼ í¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            posts = []
            for site in ['unpre', 'untab', 'skewese']:
                cursor.execute("""
                    SELECT id, title, site, category, url, 
                           created_at::text, published
                    FROM posts 
                    WHERE site = %s
                    ORDER BY created_at DESC 
                    LIMIT 5
                """, (site,))
                site_posts = cursor.fetchall()
                posts.extend(site_posts if site_posts else [])
            
            cursor.close()
            conn.close()
            
            # ì‹œê°„ìˆœ ì •ë ¬
            posts.sort(key=lambda x: x.get('created_at', ''), reverse=True)
            return jsonify(posts[:20])
        else:
            mock = get_mock_data()
            return jsonify(mock['posts'])
    except Exception as e:
        logger.error(f"ìµœê·¼ í¬ìŠ¤íŠ¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        mock = get_mock_data()
        return jsonify(mock['posts'])

@app.route('/api/posts')
def get_posts():
    """ë°œí–‰ëœ í¬ìŠ¤íŠ¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        conn = get_db_connection()
        if conn:
            cursor = conn.cursor(cursor_factory=RealDictCursor)
            site_filter = request.args.get('site', 'all')
            date_filter = request.args.get('date', '')
            
            posts = []
            for site in ['unpre', 'untab', 'skewese']:
                if site_filter == 'all' or site_filter == site:
                    query = """
                        SELECT id, title, site, category, url, 
                               created_at::text, published
                        FROM posts 
                        WHERE site = %s
                    """
                    params = [site]
                    
                    if date_filter:
                        query += " AND DATE(created_at) = %s"
                        params.append(date_filter)
                    
                    query += " ORDER BY created_at DESC LIMIT 10"
                    
                    cursor.execute(query, params)
                    site_posts = cursor.fetchall()
                    posts.extend(site_posts if site_posts else [])
            
            cursor.close()
            conn.close()
            
            posts.sort(key=lambda x: x.get('created_at', ''), reverse=True)
            return jsonify({'status': 'success', 'posts': posts})
        else:
            mock = get_mock_data()
            return jsonify({'status': 'success', 'posts': mock['posts']})
            
    except Exception as e:
        logger.error(f"í¬ìŠ¤íŠ¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        mock = get_mock_data()
        return jsonify({'status': 'success', 'posts': mock['posts']})

@app.route('/api/stats')
def get_stats():
    """í†µê³„ ì •ë³´ ì¡°íšŒ"""
    try:
        conn = get_db_connection()
        if conn:
            cursor = conn.cursor(cursor_factory=RealDictCursor)
            
            # ì „ì²´ í†µê³„ ì¡°íšŒ
            cursor.execute("""
                SELECT 
                    COUNT(*) as total_posts,
                    COUNT(CASE WHEN published = true THEN 1 END) as published,
                    COUNT(CASE WHEN published = false THEN 1 END) as scheduled,
                    COUNT(CASE WHEN DATE(created_at) = CURRENT_DATE THEN 1 END) as today_posts
                FROM posts
            """)
            
            stats = cursor.fetchone()
            cursor.close()
            conn.close()
            
            if stats:
                stats['revenue'] = {
                    'total_views': 0,
                    'total_revenue': 0
                }
                return jsonify(stats)
            else:
                mock = get_mock_data()
                stats = mock['stats']
                stats['revenue'] = {
                    'total_views': 0,
                    'total_revenue': 0
                }
                return jsonify(stats)
        else:
            mock = get_mock_data()
            stats = mock['stats']
            stats['revenue'] = {
                'total_views': 0,
                'total_revenue': 0
            }
            return jsonify(stats)
        
    except Exception as e:
        logger.error(f"í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        mock = get_mock_data()
        stats = mock['stats']
        stats['revenue'] = {
            'total_views': 0,
            'total_revenue': 0
        }
        return jsonify(stats)

@app.route('/api/topic_stats')
def get_topic_stats():
    """ì£¼ì œ í’€ í†µê³„ ì¡°íšŒ"""
    return jsonify({
        'unpre': {
            'total': 50,
            'used': 25,
            'available': 25
        },
        'untab': {
            'total': 50,
            'used': 20,
            'available': 30
        },
        'skewese': {
            'total': 50,
            'used': 15,
            'available': 35
        }
    })

@app.route('/api/system_status')
def get_system_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
    conn = get_db_connection()
    db_status = 'online' if conn else 'offline'
    if conn:
        conn.close()
    
    return jsonify({
        'api': {
            'openai': {'status': 'online', 'response_time': 150},
            'claude': {'status': 'online', 'response_time': 120},
            'pexels': {'status': 'online', 'response_time': 200}
        },
        'sites': {
            'unpre': {'status': 'online', 'last_post': datetime.now(KST).strftime('%Y-%m-%d')},
            'untab': {'status': 'online', 'last_post': datetime.now(KST).strftime('%Y-%m-%d')},
            'skewese': {'status': 'online', 'last_post': datetime.now(KST).strftime('%Y-%m-%d')}
        },
        'database': {'status': db_status},
        'scheduler': {'status': 'online', 'next_run': '03:00 KST'}
    })

@app.route('/trending')
def trending_page():
    """íŠ¸ë Œë”© í˜ì´ì§€"""
    return render_template('trending.html')

@app.route('/api/trending')
@app.route('/api/trending/<period>')
def get_trending(period='current'):
    """íŠ¸ë Œë”© í† í”½ ì¡°íšŒ"""
    try:
        # ëª©ì—… íŠ¸ë Œë”© ë°ì´í„°
        mock_trends = {
            'current': {
                'period': 'ì´ë²ˆì£¼ íŠ¸ë Œë“œ',
                'week_start': '2025-08-11',
                'cross_category_issues': [
                    {
                        'title': 'AI ê¸°ìˆ  í˜ì‹ ',
                        'category': 'Technology',
                        'trend_type': 'hot',
                        'priority': 9,
                        'description': 'ChatGPTì™€ Claude ë“± AI ê¸°ìˆ ì´ ê¸‰ì†ë„ë¡œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤.',
                        'keywords': ['AI', 'ChatGPT', 'Claude', 'ì¸ê³µì§€ëŠ¥']
                    },
                    {
                        'title': 'ë¶€ë™ì‚° ì •ì±… ë³€í™”',
                        'category': 'Real Estate',
                        'trend_type': 'rising',
                        'priority': 8,
                        'description': 'ìƒˆë¡œìš´ ë¶€ë™ì‚° ì •ì±…ì´ ë°œí‘œë˜ì–´ ì‹œì¥ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìŠµë‹ˆë‹¤.',
                        'keywords': ['ë¶€ë™ì‚°', 'ì •ì±…', 'ì‹œì¥ë³€í™”']
                    }
                ],
                'site_trends': {
                    'unpre': [
                        {
                            'title': 'React 18 ìƒˆ ê¸°ëŠ¥',
                            'category': 'Frontend',
                            'trend_type': 'rising',
                            'priority': 7,
                            'description': 'React 18ì˜ ìƒˆë¡œìš´ ê¸°ëŠ¥ë“¤ì´ ê°œë°œìë“¤ ì‚¬ì´ì—ì„œ í™”ì œê°€ ë˜ê³  ìˆìŠµë‹ˆë‹¤.',
                            'keywords': ['React', 'Frontend', 'ì›¹ê°œë°œ']
                        },
                        {
                            'title': 'Python ì„±ëŠ¥ ìµœì í™”',
                            'category': 'Backend',
                            'trend_type': 'hot',
                            'priority': 8,
                            'description': 'Python ì„±ëŠ¥ ìµœì í™” ê¸°ë²•ë“¤ì´ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤.',
                            'keywords': ['Python', 'ì„±ëŠ¥', 'ìµœì í™”']
                        }
                    ],
                    'untab': [
                        {
                            'title': 'ì–¸ì–´í•™ìŠµ ì•± íŠ¸ë Œë“œ',
                            'category': 'Education',
                            'trend_type': 'rising',
                            'priority': 6,
                            'description': 'ìƒˆë¡œìš´ ì–¸ì–´í•™ìŠµ ë°©ë²•ë¡ ì´ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤.',
                            'keywords': ['ì–¸ì–´í•™ìŠµ', 'êµìœ¡', 'ì•±']
                        }
                    ],
                    'skewese': [
                        {
                            'title': 'ì¡°ì„ ì‹œëŒ€ ë¬¸í™” ì¬ì¡°ëª…',
                            'category': 'History',
                            'trend_type': 'predicted',
                            'priority': 5,
                            'description': 'ì¡°ì„ ì‹œëŒ€ ë¬¸í™”ì— ëŒ€í•œ ìƒˆë¡œìš´ ì—°êµ¬ ê²°ê³¼ê°€ ë°œí‘œë˜ì—ˆìŠµë‹ˆë‹¤.',
                            'keywords': ['ì¡°ì„ ì‹œëŒ€', 'ì—­ì‚¬', 'ë¬¸í™”']
                        }
                    ]
                }
            }
        }
        
        trends = mock_trends.get(period, mock_trends['current'])
        
        return jsonify({
            'status': 'success',
            'success': True,
            'data': trends
        })
    except Exception as e:
        logger.error(f"íŠ¸ë Œë”© ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({
            'status': 'success',
            'success': True,
            'data': {
                'period': 'ê¸°ë³¸ íŠ¸ë Œë“œ',
                'cross_category_issues': [],
                'site_trends': {}
            }
        })

@app.route('/api/chart_data')
def get_chart_data():
    """ì°¨íŠ¸ ë°ì´í„° ì¡°íšŒ"""
    now = datetime.now(KST)
    daily_data = []
    site_data = {
        'unpre': 0,
        'untab': 0,
        'skewese': 0
    }
    
    try:
        conn = get_db_connection()
        if conn:
            cursor = conn.cursor(cursor_factory=RealDictCursor)
            
            for i in range(7):
                date = (now - timedelta(days=i)).strftime('%Y-%m-%d')
                
                cursor.execute("""
                    SELECT site, COUNT(*) as count
                    FROM posts
                    WHERE DATE(created_at) = %s
                    GROUP BY site
                """, (date,))
                
                day_results = cursor.fetchall()
                day_count = sum(r['count'] for r in day_results) if day_results else 0
                daily_data.append({'date': date, 'count': day_count})
                
                for r in day_results:
                    site_data[r['site']] = site_data.get(r['site'], 0) + r['count']
            
            cursor.close()
            conn.close()
        else:
            # ëª©ì—… ë°ì´í„°
            for i in range(7):
                date = (now - timedelta(days=i)).strftime('%Y-%m-%d')
                daily_data.append({'date': date, 'count': 3 - i % 2})
            site_data = {'unpre': 7, 'untab': 5, 'skewese': 3}
    except Exception as e:
        logger.error(f"ì°¨íŠ¸ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
        # ëª©ì—… ë°ì´í„°
        for i in range(7):
            date = (now - timedelta(days=i)).strftime('%Y-%m-%d')
            daily_data.append({'date': date, 'count': 3 - i % 2})
        site_data = {'unpre': 7, 'untab': 5, 'skewese': 3}
    
    return jsonify({
        'daily': daily_data,
        'bySite': site_data
    })

@app.route('/api/logs')
def get_logs():
    """ìµœê·¼ ë¡œê·¸ ì¡°íšŒ"""
    logs = [
        {
            'time': datetime.now(KST).strftime('%H:%M:%S'),
            'level': 'info',
            'message': 'ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™ ì¤‘'
        }
    ]
    return jsonify(logs)

@app.route('/api/schedule/weekly')
def get_weekly_schedule():
    """ì£¼ê°„ ìŠ¤ì¼€ì¤„ ì¡°íšŒ"""
    week_start = request.args.get('week_start', datetime.now(KST).strftime('%Y-%m-%d'))
    
    # ì‚¬ì´íŠ¸ë³„ ì£¼ì œ í’€ (ë” ë§ì€ ë‹¤ì–‘ì„±)
    topic_pools = {
        'unpre': [
            # í”„ë¡ íŠ¸ì—”ë“œ ì£¼ê°„
            ['React 18 ì‹ ê¸°ëŠ¥', 'Next.js 13 App Router'],
            ['Vue.js 3 Composition API', 'Angular 16 Standalone'],
            ['TypeScript 5.0 í™œìš©', 'JavaScript ES2024'],
            ['Webpack vs Vite', 'ëª¨ë˜ ë¹Œë“œ ë„êµ¬'],
            ['CSS Grid vs Flexbox', 'Tailwind CSS ì‹¤ì „'],
            
            # ë°±ì—”ë“œ ì£¼ê°„  
            ['Node.js ì„±ëŠ¥ ìµœì í™”', 'Express vs Fastify'],
            ['Python FastAPI', 'Django 4.0 ë¹„ë™ê¸°'],
            ['PostgreSQL ê³ ê¸‰ ì¿¼ë¦¬', 'MongoDB ì§‘ê³„ íŒŒì´í”„ë¼ì¸'],
            ['Redis ìºì‹± ì „ëµ', 'ElasticSearch ê²€ìƒ‰'],
            ['GraphQL vs REST API', 'gRPC ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤'],
            
            # í´ë¼ìš°ë“œ/DevOps ì£¼ê°„
            ['AWS Lambda ì„œë²„ë¦¬ìŠ¤', 'Docker ì»¨í…Œì´ë„ˆ ìµœì í™”'],
            ['Kubernetes ê¸°ì´ˆ', 'Terraform IaC'],
            ['GitHub Actions CI/CD', 'Jenkins vs GitLab CI'],
            ['ëª¨ë‹ˆí„°ë§ ë„êµ¬ ë¹„êµ', 'Prometheus & Grafana'],
            
            # AI/ML ì£¼ê°„
            ['ChatGPT API í™œìš©', 'GitHub Copilot ì‹¤ì „'],
            ['TensorFlow vs PyTorch', 'LangChain ê°œë°œ'],
            ['OpenAI ì„ë² ë”©', 'Vector DB í™œìš©'],
            ['AI ì½”ë“œ ë¦¬ë·°', 'ìë™í™” í…ŒìŠ¤íŠ¸ ë„êµ¬']
        ],
        'untab': [
            # ì–´í•™ ì£¼ê°„
            ['í† ìµ 990ì  ì „ëµ', 'OPIc AL ë‹¬ì„±ë²•'],
            ['í† í”Œ 110+ ê³µëµ', 'IELTS 8.0 ë¹„ë²•'],
            ['ì¼ë³¸ì–´ JLPT N1', 'ì¤‘êµ­ì–´ HSK 6ê¸‰'],
            ['ë…ì¼ì–´ TestDaF', 'ìŠ¤í˜ì¸ì–´ DELE'],
            ['í”„ë‘ìŠ¤ì–´ DELF', 'ì´íƒˆë¦¬ì•„ì–´ CILS'],
            
            # IT ìê²©ì¦ ì£¼ê°„
            ['ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ì‹¤ê¸°', 'SQLD ë°ì´í„°ë¶„ì„'],
            ['AWS SAA ìê²©ì¦', 'Azure Fundamentals'],
            ['êµ¬ê¸€ í´ë¼ìš°ë“œ ACE', 'CISSP ë³´ì•ˆ'],
            ['PMP í”„ë¡œì íŠ¸ ê´€ë¦¬', 'ITIL ì„œë¹„ìŠ¤ ê´€ë¦¬'],
            
            # íˆ¬ì/ì¬í…Œí¬ ì£¼ê°„  
            ['ì£¼ì‹ ê¸°ìˆ ë¶„ì„', 'ë¶€ë™ì‚° ê²½ë§¤ ì‹¤ì „'],
            ['ì½”ì¸ íˆ¬ì ê°€ì´ë“œ', 'ETF í¬íŠ¸í´ë¦¬ì˜¤'],
            ['P2P íˆ¬ì ì „ëµ', 'í•´ì™¸ ì£¼ì‹ íˆ¬ì'],
            ['ì„¸ê¸ˆ ì ˆì•½ ê¿€íŒ', 'ì—°ê¸ˆ ì €ì¶• í™œìš©'],
            
            # ë¶€ì—…/ì°½ì—… ì£¼ê°„
            ['ë¸”ë¡œê·¸ ìˆ˜ìµí™”', 'ìœ íŠœë¸Œ ì±„ë„ ìš´ì˜'],
            ['ì˜¨ë¼ì¸ ê°•ì˜ ì œì‘', 'ì´ì»¤ë¨¸ìŠ¤ ì°½ì—…'],
            ['í”„ë¦¬ëœì„œ ë§ˆì¼€íŒ…', 'ê°œì¸ ë¸Œëœë”©'],
            ['ì‚¬ì´ë“œ í”„ë¡œì íŠ¸', 'ìŠ¤íƒ€íŠ¸ì—… ì°½ì—…']
        ],
        'skewese': [
            # í•œêµ­ì‚¬ ì£¼ê°„
            ['ì¡°ì„  ê³¼í•™ê¸°ìˆ ì‚¬', 'ê³ ë ¤ ëª½ê³¨ ì¹¨ì…'],
            ['ì‚¼êµ­í†µì¼ ê³¼ì •', 'ì¼ì œê°•ì ê¸° ì €í•­'],
            ['í•œêµ­ì „ìŸ ì¬ì¡°ëª…', 'ê°œí™”ê¸° ê·¼ëŒ€í™”'],
            ['ë°±ì œ ë¬¸í™”ìœ ì‚°', 'ì‹ ë¼ í™©ê¸ˆ ë¬¸ëª…'],
            
            # ì„¸ê³„ì‚¬ ì£¼ê°„
            ['ë¡œë§ˆì œêµ­ í¥ë§ì‚¬', 'ì¤‘êµ­ 4ëŒ€ ë°œëª…í’ˆ'],
            ['ì´ì§‘íŠ¸ íŒŒë¼ì˜¤', 'ë©”ì†Œí¬íƒ€ë¯¸ì•„ ë¬¸ëª…'],
            ['ë¥´ë„¤ìƒìŠ¤ ì˜ˆìˆ ê°€', 'í”„ë‘ìŠ¤ ëŒ€í˜ëª…'],
            ['ì‚°ì—…í˜ëª… ì˜í–¥', 'ì•„ë©”ë¦¬ì¹´ ëŒ€ë°œê²¬'],
            
            # ì² í•™/ì‚¬ìƒ ì£¼ê°„
            ['ê³µì ë…¼ì–´ í•´ì„', 'ë…¸ì ë„ë•ê²½'],
            ['í”Œë¼í†¤ ì´ë°ì•„ë¡ ', 'ì•„ë¦¬ìŠ¤í† í…”ë ˆìŠ¤ ìœ¤ë¦¬í•™'],
            ['ì¹¸íŠ¸ ìˆœìˆ˜ì´ì„±ë¹„íŒ', 'ë‹ˆì²´ ê¶Œë ¥ì˜ì§€'],
            ['ë¶ˆêµ ì‚¬ìƒ ì´í•´', 'ê¸°ë…êµ ì‹ í•™'],
            
            # ë¬¸í™”/ì˜ˆìˆ  ì£¼ê°„  
            ['ê³ êµ¬ë ¤ ê³ ë¶„ë²½í™”', 'ë°±ì œ ê¸ˆë™ëŒ€í–¥ë¡œ'],
            ['ê²½ë³µê¶ ê±´ì¶•ë¯¸', 'ë¶ˆêµ­ì‚¬ ì„ê°€íƒ‘'],
            ['ê³ ë ¤ì²­ì ì˜ˆìˆ ', 'ì¡°ì„ ë°±ì ì•„ë¦„ë‹¤ì›€'],
            ['ì „í†µ í•œë³µ ë³€ì²œì‚¬', 'ê¶ì¤‘ìŒì‹ ë¬¸í™”'],
            
            # í˜„ëŒ€ ë¬¸í™”/ë¼ì´í”„
            ['ë¯¸ë‹ˆë©€ ë¼ì´í”„', 'ë¶ìœ ëŸ½ íœ˜ê²Œ'],
            ['ì¼ë³¸ ì™€ë¹„ì‚¬ë¹„', 'ë´ë§ˆí¬ ë¼ê³°'],
            ['ëª…ìƒê³¼ ë§ˆìŒì±™ê¹€', 'ë””ì§€í„¸ ë””í†¡ìŠ¤'],
            ['ì œë¡œì›¨ì´ìŠ¤íŠ¸', 'ë¹„ê±´ ë¼ì´í”„ìŠ¤íƒ€ì¼']
        ]
    }
    
    # ì£¼ê°„ ìŠ¤ì¼€ì¤„ ë°ì´í„° ìƒì„±
    schedule = {}
    start_date = datetime.strptime(week_start, '%Y-%m-%d')
    
    # ì£¼ì°¨ ê³„ì‚° (ë…„ë„ ê¸°ì¤€ ì£¼ì°¨)
    week_number = start_date.isocalendar()[1]
    
    for i in range(7):
        date = (start_date + timedelta(days=i)).strftime('%Y-%m-%d')
        day_of_week = (start_date + timedelta(days=i)).weekday()  # 0=ì›”ìš”ì¼
        
        # ì£¼ì°¨ì™€ ìš”ì¼ì„ ì¡°í•©í•˜ì—¬ ë‹¤ì–‘í•œ ì£¼ì œ ì„ íƒ
        # ê° ì‚¬ì´íŠ¸ë³„ë¡œ ë‹¤ë¥¸ ë¡œí…Œì´ì…˜ íŒ¨í„´ ì ìš©
        unpre_index = (week_number * 3 + day_of_week) % len(topic_pools['unpre'])
        untab_index = (week_number * 2 + day_of_week + 1) % len(topic_pools['untab'])  
        skewese_index = (week_number * 4 + day_of_week + 2) % len(topic_pools['skewese'])
        
        schedule[date] = {
            'unpre': {
                'time': '03:00',  # ìƒˆë²½ 3ì‹œ ìë™ë°œí–‰
                'topics': topic_pools['unpre'][unpre_index],
                'status': 'scheduled'
            },
            'untab': {
                'time': '03:00',
                'topics': topic_pools['untab'][untab_index],
                'status': 'scheduled'
            },
            'skewese': {
                'time': '03:00',
                'topics': topic_pools['skewese'][skewese_index],
                'status': 'scheduled'
            }
        }
        
        # ê³¼ê±° ë‚ ì§œëŠ” ë°œí–‰ ì™„ë£Œë¡œ í‘œì‹œ
        current_date = datetime.now(KST).date()
        target_date = (start_date + timedelta(days=i)).date()
        
        if target_date < current_date:
            for site in schedule[date]:
                schedule[date][site]['status'] = 'published'
        elif target_date == current_date:
            # ì˜¤ëŠ˜ì€ ìƒˆë²½ 3ì‹œ ì´í›„ë©´ ë°œí–‰ ì™„ë£Œ
            current_time = datetime.now(KST).time()
            if current_time >= datetime.strptime('03:00', '%H:%M').time():
                for site in schedule[date]:
                    schedule[date][site]['status'] = 'published'
    
    return jsonify(schedule)

@app.route('/api/generate_wordpress', methods=['POST'])
def generate_wordpress():
    """WordPress ì½˜í…ì¸  ìƒì„±"""
    try:
        data = request.json
        site = data.get('site', 'unpre')
        topic = data.get('topic', 'í”„ë¡œê·¸ë˜ë°')
        
        # ëª©ì—… ì‘ë‹µ (ì‹¤ì œ ìƒì„± ë¡œì§ìœ¼ë¡œ ëŒ€ì²´ ì˜ˆì •)
        import time
        current_time = int(time.time())
        
        # WordPress íŒŒì¼ ëª©ë¡ì— ìƒˆ í•­ëª© ì¶”ê°€ (ì‹¤ì œ íŒŒì¼ ìƒì„± ì‹œë®¬ë ˆì´ì…˜)
        new_file = {
            'title': f'{topic} ì™„ì „ ê°€ì´ë“œ',
            'file_path': f'wordpress_posts/{site}_{topic.replace(" ", "_")}_{current_time}.html',
            'url': f'https://{site}.co.kr/posts/{current_time}',
            'status': 'draft',
            'category': data.get('category', 'ê¸°ë³¸'),
            'tags': data.get('keywords', [topic]),
            'created_at': time.strftime('%Y-%m-%d %H:%M:%S'),
            'actions': ['view', 'edit', 'publish', 'download', 'delete'],
            'id': current_time
        }
        
        # ê¸€ë¡œë²Œ mock_wordpress_filesì— ì¶”ê°€
        global mock_wordpress_files
        mock_wordpress_files.append(new_file)
        
        return jsonify({
            'success': True,
            'message': f'{site} ì‚¬ì´íŠ¸ì— {topic} ì£¼ì œë¡œ ì½˜í…ì¸ ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.',
            'title': new_file['title'],
            'file_path': new_file['file_path'],
            'url': new_file['url'],
            'id': new_file['id'],
            'post': new_file
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/generate_tistory', methods=['POST'])
def generate_tistory():
    """Tistory ì½˜í…ì¸  ìƒì„±"""
    try:
        data = request.json
        topic = data.get('topic', 'í”„ë¡œê·¸ë˜ë°')
        
        # ëª©ì—… ì‘ë‹µ (ì‹¤ì œ ìƒì„± ë¡œì§ìœ¼ë¡œ ëŒ€ì²´ ì˜ˆì •)
        import time
        current_time = int(time.time())
        
        # Tistory íŒŒì¼ ëª©ë¡ì— ìƒˆ í•­ëª© ì¶”ê°€ (ì‹¤ì œ íŒŒì¼ ìƒì„± ì‹œë®¬ë ˆì´ì…˜)
        new_file = {
            'title': f'{topic} ì‹¬í™” ë¶„ì„',
            'file_path': f'tistory_posts/{topic.replace(" ", "_")}_{current_time}.html',
            'url': f'https://untab.tistory.com/posts/{current_time}',
            'status': 'draft',
            'category': data.get('category', 'ê¸°ë³¸'),
            'tags': data.get('keywords', [topic]),
            'created_at': time.strftime('%Y-%m-%d %H:%M:%S'),
            'actions': ['view', 'edit', 'publish', 'download', 'delete'],
            'id': current_time
        }
        
        # ê¸€ë¡œë²Œ mock_tistory_filesì— ì¶”ê°€
        global mock_tistory_files
        mock_tistory_files.append(new_file)
        
        return jsonify({
            'success': True,
            'message': f'Tistoryì— {topic} ì£¼ì œë¡œ ì½˜í…ì¸ ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.',
            'title': new_file['title'],
            'file_path': new_file['file_path'],
            'url': new_file['url'],
            'id': new_file['id'],
            'post': new_file
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/delete_posts', methods=['POST'])
def delete_posts():
    """í¬ìŠ¤íŠ¸ ì‚­ì œ"""
    try:
        data = request.json
        post_ids = data.get('post_ids', [])
        
        # ì‹¤ì œ ì‚­ì œ ë¡œì§ ëŒ€ì‹  ëª©ì—… ì‘ë‹µ
        return jsonify({
            'success': True,
            'message': f'{len(post_ids)}ê°œì˜ í¬ìŠ¤íŠ¸ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.',
            'deleted': post_ids
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/schedule')
def get_schedule():
    """ë°œí–‰ ì¼ì • ì¡°íšŒ"""
    try:
        now = datetime.now(KST)
        schedule = []
        
        # ë‹¤ìŒ 7ì¼ê°„ì˜ ì˜ˆì •
        for i in range(7):
            date = (now + timedelta(days=i)).strftime('%Y-%m-%d')
            schedule.append({
                'date': date,
                'time': '03:00',
                'status': 'scheduled',
                'sites': ['unpre', 'untab', 'skewese']
            })
        
        return jsonify(schedule)
    except Exception as e:
        return jsonify([]), 500

@app.route('/api/wordpress_files')
def get_wordpress_files():
    """WordPress íŒŒì¼ ëª©ë¡"""
    try:
        files = []
        now = datetime.now(KST)
        
        # ìµœê·¼ ìƒì„±ëœ ì½˜í…ì¸  (ëª©ì—… + ë™ì  ìƒì„±)
        base_files = [
            {
                'id': 'wp_unpre_001',
                'site': 'unpre',
                'title': 'ğŸ¤– AI ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ í™œìš© ê°€ì´ë“œ',
                'date': now.strftime('%Y-%m-%d %H:%M'),
                'size': '3.2KB',
                'status': 'published',
                'url': 'https://unpre.co.kr/ai-coding-assistant-guide',
                'actions': ['view', 'edit', 'download', 'delete']
            },
            {
                'id': 'wp_unpre_002',
                'site': 'unpre', 
                'title': 'âš¡ React 18 Concurrent Features ì™„ì „ ì •ë³µ',
                'date': (now - timedelta(hours=2)).strftime('%Y-%m-%d %H:%M'),
                'size': '4.1KB',
                'status': 'published',
                'url': 'https://unpre.co.kr/react-18-concurrent',
                'actions': ['view', 'edit', 'download', 'delete']
            },
            {
                'id': 'wp_untab_001',
                'site': 'untab',
                'title': 'ğŸ“š í† ìµ 990ì  ë‹¬ì„±í•˜ëŠ” 5ê°€ì§€ ë¹„ë²•',
                'date': (now - timedelta(hours=1)).strftime('%Y-%m-%d %H:%M'),
                'size': '2.8KB',
                'status': 'published',
                'url': 'https://untab.co.kr/toeic-990-tips',
                'actions': ['view', 'edit', 'download', 'delete']
            },
            {
                'id': 'wp_untab_002',
                'site': 'untab',
                'title': 'ğŸ’° ë¶€ë™ì‚° ê²½ë§¤ ì´ˆë³´ì ì™„ë²½ ê°€ì´ë“œ',
                'date': (now - timedelta(hours=3)).strftime('%Y-%m-%d %H:%M'),
                'size': '3.5KB',
                'status': 'draft',
                'url': None,
                'actions': ['edit', 'publish', 'download', 'delete']
            },
            {
                'id': 'wp_skewese_001',
                'site': 'skewese',
                'title': 'ğŸ›ï¸ ì¡°ì„ ì‹œëŒ€ ê³¼í•™ê¸°ìˆ ì˜ ìˆ¨ê²¨ì§„ ì´ì•¼ê¸°',
                'date': (now - timedelta(minutes=30)).strftime('%Y-%m-%d %H:%M'),
                'size': '3.7KB',
                'status': 'published',
                'url': 'https://skewese.com/joseon-science-stories',
                'actions': ['view', 'edit', 'download', 'delete']
            },
            {
                'id': 'wp_skewese_002',
                'site': 'skewese',
                'title': 'âœ¨ ê³ êµ¬ë ¤ ê³ ë¶„ë²½í™” ì† ìš°ì£¼ê´€',
                'date': (now - timedelta(hours=4)).strftime('%Y-%m-%d %H:%M'),
                'size': '2.9KB',
                'status': 'draft',
                'url': None,
                'actions': ['edit', 'publish', 'download', 'delete']
            }
        ]
        
        files.extend(base_files)
        
        # ìƒˆë¡œ ìƒì„±ëœ WordPress íŒŒì¼ë“¤ ì¶”ê°€
        for wp_file in mock_wordpress_files:
            files.append({
                'id': wp_file.get('id'),
                'site': wp_file.get('site', 'unpre'),
                'title': wp_file.get('title'),
                'date': wp_file.get('created_at'),
                'size': '3.0KB',
                'status': wp_file.get('status', 'draft'),
                'url': wp_file.get('url'),
                'actions': wp_file.get('actions', ['view', 'edit', 'publish', 'download', 'delete'])
            })
        
        # ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬
        files.sort(key=lambda x: x['date'], reverse=True)
        
        return jsonify(files)
    except Exception as e:
        logger.error(f"WordPress íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify([]), 500

@app.route('/api/tistory_files')
def get_tistory_files():
    """Tistory íŒŒì¼ ëª©ë¡"""
    try:
        files = []
        now = datetime.now(KST)
        
        # ìµœê·¼ ìƒì„±ëœ Tistory ì½˜í…ì¸ 
        base_files = [
            {
                'id': 'tistory_001',
                'title': 'ğŸ¯ 2025ë…„ ì–¸ì–´í•™ìŠµ íŠ¸ë Œë“œì™€ ì „ë§',
                'date': now.strftime('%Y-%m-%d %H:%M'),
                'size': '2.7KB',
                'status': 'published',
                'url': 'https://untab.tistory.com/language-trends-2025',
                'actions': ['view', 'edit', 'download', 'delete'],
                'category': 'ì–¸ì–´í•™ìŠµ',
                'tags': ['ì–¸ì–´í•™ìŠµ', 'íŠ¸ë Œë“œ', '2025ë…„']
            },
            {
                'id': 'tistory_002',
                'title': 'ğŸ’¡ íš¨ê³¼ì ì¸ ì˜¨ë¼ì¸ ê°•ì˜ ì œì‘ ë…¸í•˜ìš°',
                'date': (now - timedelta(hours=1)).strftime('%Y-%m-%d %H:%M'),
                'size': '3.1KB',
                'status': 'published',
                'url': 'https://untab.tistory.com/online-course-creation',
                'actions': ['view', 'edit', 'download', 'delete'],
                'category': 'êµìœ¡ì½˜í…ì¸ ',
                'tags': ['ì˜¨ë¼ì¸ê°•ì˜', 'ì œì‘', 'ë…¸í•˜ìš°']
            },
            {
                'id': 'tistory_003',
                'title': 'ğŸ“ˆ ì£¼ì‹ íˆ¬ì ì´ˆë³´ìë¥¼ ìœ„í•œ ê¸°ë³¸ ê°€ì´ë“œ',
                'date': (now - timedelta(hours=2)).strftime('%Y-%m-%d %H:%M'),
                'size': '4.2KB',
                'status': 'draft',
                'url': None,
                'actions': ['edit', 'publish', 'download', 'delete'],
                'category': 'íˆ¬ì',
                'tags': ['ì£¼ì‹íˆ¬ì', 'ì´ˆë³´ì', 'ê°€ì´ë“œ']
            },
            {
                'id': 'tistory_004',
                'title': 'ğŸ† AWS ìê²©ì¦ ì·¨ë“ ì™„ë²½ ë¡œë“œë§µ',
                'date': (now - timedelta(hours=3)).strftime('%Y-%m-%d %H:%M'),
                'size': '3.8KB',
                'status': 'published',
                'url': 'https://untab.tistory.com/aws-certification-roadmap',
                'actions': ['view', 'edit', 'download', 'delete'],
                'category': 'ITìê²©ì¦',
                'tags': ['AWS', 'ìê²©ì¦', 'ë¡œë“œë§µ']
            },
            {
                'id': 'tistory_005',
                'title': 'ğŸ’° ë¶€ë™ì‚° ê²½ë§¤ íˆ¬ì ì‹œì‘í•˜ëŠ” ë²•',
                'date': (now - timedelta(hours=5)).strftime('%Y-%m-%d %H:%M'),
                'size': '3.5KB',
                'status': 'draft',
                'url': None,
                'actions': ['edit', 'publish', 'download', 'delete'],
                'category': 'ë¶€ë™ì‚°',
                'tags': ['ë¶€ë™ì‚°ê²½ë§¤', 'íˆ¬ì', 'ì´ˆë³´ì']
            }
        ]
        
        files.extend(base_files)
        
        # ìƒˆë¡œ ìƒì„±ëœ Tistory íŒŒì¼ë“¤ ì¶”ê°€
        for tistory_file in mock_tistory_files:
            files.append({
                'id': tistory_file.get('id'),
                'title': tistory_file.get('title'),
                'date': tistory_file.get('created_at'),
                'size': '3.0KB',
                'status': tistory_file.get('status', 'draft'),
                'url': tistory_file.get('url'),
                'actions': tistory_file.get('actions', ['view', 'edit', 'publish', 'download', 'delete']),
                'category': tistory_file.get('category', 'ê¸°ë³¸'),
                'tags': tistory_file.get('tags', [])
            })
        
        # ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬
        files.sort(key=lambda x: x['date'], reverse=True)
        
        return jsonify(files)
    except Exception as e:
        logger.error(f"Tistory íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify([]), 500

@app.route('/api/system/time')
def get_system_time():
    """ì‹œìŠ¤í…œ ì‹œê°„ ì¡°íšŒ (í•œêµ­ ì‹œê°„ê³¼ ì„œë²„ ì‹œê°„ ë¹„êµ)"""
    import time
    
    # ì„œë²„ UTC ì‹œê°„
    utc_time = datetime.now(pytz.UTC)
    # í•œêµ­ ì‹œê°„
    kst_time = datetime.now(KST)
    # ì„œë²„ ë¡œì»¬ ì‹œê°„ (ì‹œê°„ëŒ€ ì—†ì´)
    server_local = datetime.now()
    
    # ì‹œê°„ ì°¨ì´ ê³„ì‚°
    time_diff = kst_time.hour - server_local.hour
    if time_diff < -12:
        time_diff += 24
    elif time_diff > 12:
        time_diff -= 24
    
    return jsonify({
        'status': 'success',
        'korea_time': kst_time.strftime('%Y-%m-%d %H:%M:%S KST'),
        'utc_time': utc_time.strftime('%Y-%m-%d %H:%M:%S UTC'),
        'server_local_time': server_local.strftime('%Y-%m-%d %H:%M:%S'),
        'timezone': 'Asia/Seoul',
        'time_difference_hours': time_diff,
        'scheduler_info': {
            'timezone': 'Asia/Seoul',
            'note': 'ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” í•œêµ­ ì‹œê°„(KST) ê¸°ì¤€ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤'
        }
    })

@app.route('/favicon.ico')
def favicon():
    """favicon ì²˜ë¦¬"""
    from flask import Response
    # ê°„ë‹¨í•œ ë¹ˆ favicon ì‘ë‹µ
    return Response('', status=204)

@app.route('/health')
def health():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return jsonify({
        'status': 'healthy',
        'message': 'Blog automation system is running',
        'time': datetime.now(KST).strftime('%Y-%m-%d %H:%M:%S KST')
    }), 200

@app.route('/api/status')
def api_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ API"""
    conn = get_db_connection()
    db_status = 'connected' if conn else 'disconnected'
    if conn:
        conn.close()
    
    return jsonify({
        'status': 'operational',
        'version': '1.0.0',
        'database': db_status,
        'features': {
            'content_generation': True,
            'wordpress_publishing': True,
            'tistory_publishing': True,
            'image_generation': True,
            'seo_optimization': True
        },
        'server_time': datetime.now(KST).strftime('%Y-%m-%d %H:%M:%S KST')
    }), 200

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    app.run(host="0.0.0.0", port=port, debug=False)