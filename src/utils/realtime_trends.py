#!/usr/bin/env python3
"""
ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„
- êµ¬ê¸€ íŠ¸ë Œë“œ API
- ë„¤ì´ë²„ ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´
- íŠ¸ë Œë“œë¥¼ ë¸”ë¡œê·¸ ì£¼ì œë¡œ ë³€í™˜
"""

import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime, timedelta
from typing import List, Dict
import random
import time
import re
import logging

try:
    from pytrends.request import TrendReq
    PYTRENDS_AVAILABLE = True
except ImportError:
    PYTRENDS_AVAILABLE = False
    print("âš ï¸ pytrends ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install pytrends")

class RealtimeTrends:
    """ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ìˆ˜ì§‘ ë° ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        if PYTRENDS_AVAILABLE:
            self.pytrends = TrendReq(hl='ko-KR', tz=540)  # í•œêµ­ ì‹œê°„ëŒ€
        
    def get_google_trends(self, timeframe='now 1-d') -> List[Dict]:
        """êµ¬ê¸€ íŠ¸ë Œë“œ ë°ì´í„° ìˆ˜ì§‘"""
        if not PYTRENDS_AVAILABLE:
            return self._fallback_google_trends()
            
        try:
            # ì‹¤ì‹œê°„ íŠ¸ë Œë“œ (í•œêµ­)
            trending_searches = self.pytrends.trending_searches(pn='south_korea')
            
            trends = []
            if not trending_searches.empty:
                for i, trend in enumerate(trending_searches[0][:20]):  # ìƒìœ„ 20ê°œ
                    trends.append({
                        'keyword': trend,
                        'rank': i + 1,
                        'source': 'google',
                        'category': self._categorize_keyword(trend)
                    })
            
            self.logger.info(f"êµ¬ê¸€ íŠ¸ë Œë“œ {len(trends)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
            return trends
            
        except Exception as e:
            self.logger.error(f"êµ¬ê¸€ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return self._fallback_google_trends()
    
    def get_naver_realtime_keywords(self) -> List[Dict]:
        """ë„¤ì´ë²„ ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ ìˆ˜ì§‘ (ëŒ€ì•ˆ ë°©ë²•)"""
        try:
            # ë„¤ì´ë²„ ë°ì´í„°ë© API ëŒ€ì‹  ê³µê°œ ë°ì´í„° í™œìš©
            # ì‹¤ì œë¡œëŠ” ë„¤ì´ë²„ ê²€ìƒ‰ íŠ¸ë Œë“œë‚˜ ë‰´ìŠ¤ í‚¤ì›Œë“œ ìˆ˜ì§‘
            keywords = self._get_naver_news_keywords()
            
            trends = []
            for i, keyword in enumerate(keywords[:15]):  # ìƒìœ„ 15ê°œ
                trends.append({
                    'keyword': keyword,
                    'rank': i + 1,
                    'source': 'naver',
                    'category': self._categorize_keyword(keyword)
                })
            
            self.logger.info(f"ë„¤ì´ë²„ í‚¤ì›Œë“œ {len(trends)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
            return trends
            
        except Exception as e:
            self.logger.error(f"ë„¤ì´ë²„ í‚¤ì›Œë“œ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return self._fallback_naver_trends()
    
    def _get_naver_news_keywords(self) -> List[str]:
        """ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ ì¸ê¸° í‚¤ì›Œë“œ ì¶”ì¶œ"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            # ë„¤ì´ë²„ ë‰´ìŠ¤ ë­í‚¹ í˜ì´ì§€
            url = 'https://news.naver.com/main/ranking/popularDay.naver'
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ë‰´ìŠ¤ ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            headlines = soup.select('.list_title')
            keywords = []
            
            for headline in headlines[:20]:
                title = headline.get_text().strip()
                # ì œëª©ì—ì„œ ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œ ì¶”ì¶œ
                extracted = self._extract_keywords_from_title(title)
                keywords.extend(extracted)
            
            # ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
            unique_keywords = list(dict.fromkeys(keywords))
            return unique_keywords[:15]
            
        except Exception as e:
            self.logger.error(f"ë„¤ì´ë²„ ë‰´ìŠ¤ í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []
    
    def _extract_keywords_from_title(self, title: str) -> List[str]:
        """ë‰´ìŠ¤ ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
        title = re.sub(r'[^\w\sê°€-í£]', ' ', title)
        
        # ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œ íŒ¨í„´ ë§¤ì¹­
        keywords = []
        
        # ì¸ëª…, ì§€ëª…, ê¸°ê´€ëª…, ë¸Œëœë“œëª… ë“± ì¶”ì¶œ
        patterns = [
            r'\b[A-Z][a-zA-Z]{2,}\b',  # ì˜ë¬¸ ê³ ìœ ëª…ì‚¬
            r'\b[ê°€-í£]{2,4}(?:ëŒ€í†µë ¹|ì¥ê´€|ì˜ì›|ëŒ€í‘œ|íšŒì¥)\b',  # ì§ì±…
            r'\b[ê°€-í£]{2,6}(?:ê¸°ì—…|íšŒì‚¬|ê·¸ë£¹|ì¬ë‹¨)\b',  # ê¸°ì—…
            r'\b(?:ì‚¼ì„±|í˜„ëŒ€|LG|SK|ë„¤ì´ë²„|ì¹´ì¹´ì˜¤|ì¿ íŒ¡)\b',  # ì£¼ìš” ê¸°ì—…
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, title)
            keywords.extend([m.strip() for m in matches if len(m.strip()) > 1])
        
        return keywords[:3]  # ì œëª©ë‹¹ ìµœëŒ€ 3ê°œ
    
    def _categorize_keyword(self, keyword: str) -> str:
        """í‚¤ì›Œë“œë¥¼ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜"""
        keyword_lower = keyword.lower()
        
        # ê¸°ìˆ /IT
        tech_keywords = ['ai', 'ì¸ê³µì§€ëŠ¥', 'gpt', 'ë¡œë´‡', 'ìŠ¤ë§ˆíŠ¸í°', 'ì• í”Œ', 'ì‚¼ì„±', 'êµ¬ê¸€', 
                        'ë©”íƒ€ë²„ìŠ¤', 'ì•”í˜¸í™”í', 'ë¹„íŠ¸ì½”ì¸', 'ë¸”ë¡ì²´ì¸', 'vr', 'ar']
        
        # ì •ì¹˜/ì‚¬íšŒ
        politics_keywords = ['ëŒ€í†µë ¹', 'ì •ë¶€', 'êµ­íšŒ', 'ì„ ê±°', 'ì •ì±…', 'ë²•ì•ˆ', 'ì‹œìœ„', 'ì§‘íšŒ']
        
        # ê²½ì œ/íˆ¬ì
        economy_keywords = ['ì£¼ì‹', 'íˆ¬ì', 'ë¶€ë™ì‚°', 'ê¸ˆë¦¬', 'ì¸í”Œë ˆì´ì…˜', 'ê²½ì œ', 'ì‹œì¥', 
                           'ì½”ìŠ¤í”¼', 'ë‹¬ëŸ¬', 'ì›í™”', 'ì¦ì‹œ']
        
        # ì—°ì˜ˆ/ë¬¸í™”
        entertainment_keywords = ['ì•„ì´ëŒ', 'k-pop', 'ë“œë¼ë§ˆ', 'ì˜í™”', 'ì—°ì˜ˆì¸', 'ë°©íƒ„ì†Œë…„ë‹¨', 
                                 'bts', 'ë¸”ë™í•‘í¬', 'ë°°ìš°', 'ê°€ìˆ˜']
        
        # ìŠ¤í¬ì¸ 
        sports_keywords = ['ì¶•êµ¬', 'ì•¼êµ¬', 'ë†êµ¬', 'ì˜¬ë¦¼í”½', 'ì›”ë“œì»µ', 'ì†í¥ë¯¼', 'ê¹€ì—°ì•„', 
                          'í”„ë¡œì•¼êµ¬', 'kë¦¬ê·¸']
        
        if any(word in keyword_lower for word in tech_keywords):
            return 'tech'
        elif any(word in keyword_lower for word in politics_keywords):
            return 'politics'
        elif any(word in keyword_lower for word in economy_keywords):
            return 'economy'
        elif any(word in keyword_lower for word in entertainment_keywords):
            return 'entertainment'
        elif any(word in keyword_lower for word in sports_keywords):
            return 'sports'
        else:
            return 'social'
    
    def convert_trends_to_blog_topics(self, trends: List[Dict]) -> Dict[str, List[str]]:
        """íŠ¸ë Œë“œ í‚¤ì›Œë“œë¥¼ ë¸”ë¡œê·¸ ì£¼ì œë¡œ ë³€í™˜"""
        
        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
        categorized = {}
        for trend in trends:
            category = trend['category']
            if category not in categorized:
                categorized[category] = []
            categorized[category].append(trend['keyword'])
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë¸”ë¡œê·¸ ì£¼ì œ ìƒì„±
        blog_topics = {}
        
        for category, keywords in categorized.items():
            topics = []
            for keyword in keywords[:5]:  # ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ 5ê°œ
                topic = self._generate_blog_topic(keyword, category)
                if topic:
                    topics.append(topic)
            
            if topics:
                blog_topics[category] = topics
        
        return blog_topics
    
    def _generate_blog_topic(self, keyword: str, category: str) -> str:
        """í‚¤ì›Œë“œì™€ ì¹´í…Œê³ ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¸”ë¡œê·¸ ì£¼ì œ ìƒì„±"""
        
        templates = {
            'tech': [
                f'{keyword}ì˜ ê¸°ìˆ ì  í˜ì‹ ê³¼ ë¯¸ë˜ ì „ë§',
                f'{keyword}ê°€ ë°”ê¾¸ëŠ” ìš°ë¦¬ì˜ ì¼ìƒ',
                f'{keyword} ì™„ë²½ ê°€ì´ë“œì™€ í™œìš©ë²•',
                f'{keyword}ì˜ ì¥ë‹¨ì  ë¶„ì„',
            ],
            'politics': [
                f'{keyword} ì •ì±… ë³€í™”ì™€ ìš°ë¦¬ ìƒí™œ ì˜í–¥',
                f'{keyword} ì´ìŠˆ ì™„ì „ ë¶„ì„',
                f'{keyword}ì„ ë‘˜ëŸ¬ì‹¼ ì°¬ë°˜ ë…¼ë€',
                f'{keyword} ê´€ë ¨ ìµœì‹  ë™í–¥',
            ],
            'economy': [
                f'{keyword} íˆ¬ì ì „ëµê³¼ ì‹œì¥ ë¶„ì„',
                f'{keyword}ì´ ê²½ì œì— ë¯¸ì¹˜ëŠ” ì˜í–¥',
                f'{keyword} ê´€ë ¨ íˆ¬ì ê¸°íšŒ í¬ì°©',
                f'{keyword} ì‹œì¥ ë™í–¥ê³¼ ì „ë§',
            ],
            'entertainment': [
                f'{keyword}ì˜ ê¸€ë¡œë²Œ ì„±ê³µ ë¹„ê²°',
                f'{keyword} ì—´í’ ë¶„ì„ê³¼ ë¬¸í™”ì  ì˜ë¯¸',
                f'{keyword}ê°€ ë§Œë“  ìƒˆë¡œìš´ íŠ¸ë Œë“œ',
                f'{keyword}ì˜ íŒ¬ë¤ ë¬¸í™”ì™€ ì˜í–¥ë ¥',
            ],
            'sports': [
                f'{keyword} ê²½ê¸° í•˜ì´ë¼ì´íŠ¸ì™€ ë¶„ì„',
                f'{keyword}ì˜ ì„±ê³¼ì™€ ì˜ë¯¸',
                f'{keyword} ê´€ë ¨ ìŠ¤í¬ì¸  íŠ¸ë Œë“œ',
                f'{keyword}ì´ ìŠ¤í¬ì¸ ê³„ì— ë¯¸ì¹œ ì˜í–¥',
            ],
            'social': [
                f'{keyword} í˜„ìƒ ë¶„ì„ê³¼ ì‚¬íšŒì  ì˜ë¯¸',
                f'{keyword}ì„ í†µí•´ ë³¸ í˜„ëŒ€ ì‚¬íšŒ',
                f'{keyword} ì´ìŠˆì˜ ëª¨ë“  ê²ƒ',
                f'{keyword} íŠ¸ë Œë“œì™€ ìš°ë¦¬ ì‚¶ì˜ ë³€í™”',
            ]
        }
        
        if category in templates:
            template = random.choice(templates[category])
            return template
        
        return f'{keyword} ê´€ë ¨ ìµœì‹  íŠ¸ë Œë“œ ë¶„ì„'
    
    def _fallback_google_trends(self) -> List[Dict]:
        """êµ¬ê¸€ íŠ¸ë Œë“œ API ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ë°ì´í„°"""
        fallback_data = [
            {'keyword': 'ChatGPT', 'rank': 1, 'source': 'google_fallback', 'category': 'tech'},
            {'keyword': 'ë¹„íŠ¸ì½”ì¸', 'rank': 2, 'source': 'google_fallback', 'category': 'economy'},
            {'keyword': 'ë¶€ë™ì‚°', 'rank': 3, 'source': 'google_fallback', 'category': 'economy'},
            {'keyword': 'í…ŒìŠ¬ë¼', 'rank': 4, 'source': 'google_fallback', 'category': 'tech'},
            {'keyword': 'K-POP', 'rank': 5, 'source': 'google_fallback', 'category': 'entertainment'},
        ]
        return fallback_data
    
    def _fallback_naver_trends(self) -> List[Dict]:
        """ë„¤ì´ë²„ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ë°ì´í„°"""
        fallback_data = [
            {'keyword': 'ì •ë¶€ ì •ì±…', 'rank': 1, 'source': 'naver_fallback', 'category': 'politics'},
            {'keyword': 'ì£¼ì‹ ì‹œì¥', 'rank': 2, 'source': 'naver_fallback', 'category': 'economy'},
            {'keyword': 'ë“œë¼ë§ˆ', 'rank': 3, 'source': 'naver_fallback', 'category': 'entertainment'},
            {'keyword': 'ì•„ì´í°', 'rank': 4, 'source': 'naver_fallback', 'category': 'tech'},
            {'keyword': 'ì¶•êµ¬', 'rank': 5, 'source': 'naver_fallback', 'category': 'sports'},
        ]
        return fallback_data
    
    def get_combined_trends(self) -> Dict[str, List[str]]:
        """êµ¬ê¸€ê³¼ ë„¤ì´ë²„ íŠ¸ë Œë“œë¥¼ ê²°í•©í•˜ì—¬ ë¸”ë¡œê·¸ ì£¼ì œ ìƒì„±"""
        
        print("ğŸ” ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        
        # êµ¬ê¸€ íŠ¸ë Œë“œ ìˆ˜ì§‘
        google_trends = self.get_google_trends()
        time.sleep(1)  # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ
        
        # ë„¤ì´ë²„ íŠ¸ë Œë“œ ìˆ˜ì§‘
        naver_trends = self.get_naver_realtime_keywords()
        
        # íŠ¸ë Œë“œ ê²°í•©
        all_trends = google_trends + naver_trends
        
        # ë¸”ë¡œê·¸ ì£¼ì œë¡œ ë³€í™˜
        blog_topics = self.convert_trends_to_blog_topics(all_trends)
        
        print(f"âœ… ì´ {len(all_trends)}ê°œ íŠ¸ë Œë“œì—ì„œ {sum(len(topics) for topics in blog_topics.values())}ê°œ ë¸”ë¡œê·¸ ì£¼ì œ ìƒì„±")
        
        return blog_topics

def test_realtime_trends():
    """ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸"""
    
    trends_collector = RealtimeTrends()
    
    print("=" * 60)
    print("ğŸŒ ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # íŠ¸ë Œë“œ ìˆ˜ì§‘ ë° ì£¼ì œ ìƒì„±
    blog_topics = trends_collector.get_combined_trends()
    
    print("\nğŸ“ ìƒì„±ëœ ë¸”ë¡œê·¸ ì£¼ì œ:")
    print("-" * 40)
    
    for category, topics in blog_topics.items():
        print(f"\nğŸ“ {category.upper()} ì¹´í…Œê³ ë¦¬:")
        for i, topic in enumerate(topics, 1):
            print(f"  {i}. {topic}")
    
    # í‹°ìŠ¤í† ë¦¬ìš© ì£¼ì œ ì„ ë³„
    tech_topics = blog_topics.get('tech', [])
    social_topics = blog_topics.get('social', []) + blog_topics.get('politics', [])
    
    print(f"\nğŸ¯ í‹°ìŠ¤í† ë¦¬ ì¶”ì²œ ì£¼ì œ:")
    print(f"  [tech] {tech_topics[0] if tech_topics else 'í…ŒìŠ¬ë¼ ììœ¨ì£¼í–‰ ê¸°ìˆ  ë°œì „'}")
    print(f"  [social] {social_topics[0] if social_topics else 'MZì„¸ëŒ€ ì†Œë¹„ íŠ¸ë Œë“œ ë³€í™”'}")

if __name__ == '__main__':
    test_realtime_trends()